import glob
import json
import os
import re
import shutil
import stat
import subprocess
import sys
import time
import traceback
import typing
from dataclasses import asdict, dataclass, fields, is_dataclass
from enum import Enum
from itertools import chain, repeat
from pathlib import Path
from subprocess import CalledProcessError
from typing import Dict, List, NamedTuple

from flytekit.extras.persistence import LatchPersistence
from latch_cli.extras.nextflow.file_persistence import download_files, upload_files
from latch_cli.extras.nextflow.channel import get_mapper_inputs, get_boolean_value, get_mapper_outputs
from latch_cli.utils import check_exists_and_rename, get_parameter_json_value, urljoins
from latch_cli.utils.workflow import _override_task_status

from latch.resources.tasks import custom_task
from latch.types.directory import LatchDir, LatchOutputDir
from latch.types.file import LatchFile

sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

task = custom_task(cpu=-1, memory=-1) # these limits are a lie and are ignored when generating the task spec



class Resparams_bbsplit_fasta_list_3584(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bbsplit_fasta_list_3584(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_bbsplit_fasta_list_3584:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bbsplit_fasta_list"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bbsplit_fasta_list_3584(
        res=out_channels.get("res")
    )


class Resparams_skip_alignment_3867(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_3867(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_3867:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_3867(
        res=out_channels.get("res")
    )


class Resparams_bam_csi_index_3868(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_3868(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_bam_csi_index_3868:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_3868(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_bam_csi_index__3869(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_bam_csi_index__3869(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3867: typing.Union[str, None],
    channel_3868: typing.Union[str, None]
) -> Res_params_skip_alignment____params_bam_csi_index__3869:
    cond = ((channel_3867 is not None) and (channel_3868 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3867), json.loads(channel_3868)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_bam_csi_index__3869(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_bam_csi_index__3870(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_bam_csi_index__3870(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3869: typing.Union[str, None]
) -> Res_params_skip_alignment____params_bam_csi_index__3870:
    cond = ((channel_3869 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3869)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_bam_csi_index__3870(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment____params_bam_csi_index__3871(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment____params_bam_csi_index__3871(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3870: typing.Union[str, None]
) -> Resconditional__params_skip_alignment____params_bam_csi_index__3871:
    cond = ((channel_3870 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3870)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment____params_bam_csi_index__3871(condition=res)


class Resparams_additional_fasta_3580(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_additional_fasta_3580(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_additional_fasta_3580:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"additional_fasta"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_additional_fasta_3580(
        res=out_channels.get("res")
    )


class Resadditional_fasta_3642(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def additional_fasta_3642(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3580: typing.Union[str, None]
) -> Resadditional_fasta_3642:
    cond = ((channel_3580 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3580)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resadditional_fasta_3642(
        res=out_channels.get("res")
    )


class Resconditional_additional_fasta_3643(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_additional_fasta_3643(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3642: typing.Union[str, None]
) -> Resconditional_additional_fasta_3643:
    cond = ((channel_3642 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3642)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_additional_fasta_3643(condition=res)


class Resparams_fasta_3577(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_fasta_3577(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_fasta_3577:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"fasta"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_fasta_3577(
        res=out_channels.get("res")
    )


class Resfasta_endsWith__gz__3593(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def fasta_endsWith__gz__3593(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3577: typing.Union[str, None]
) -> Resfasta_endsWith__gz__3593:
    cond = ((channel_3577 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3577)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fasta"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfasta_endsWith__gz__3593(
        res=out_channels.get("res")
    )


class Resfasta_endsWith__gz__3594(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def fasta_endsWith__gz__3594(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3593: typing.Union[str, None]
) -> Resfasta_endsWith__gz__3594:
    cond = ((channel_3593 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3593)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfasta_endsWith__gz__3594(
        res=out_channels.get("res")
    )


class Resconditional_fasta_endsWith__gz__3595(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_fasta_endsWith__gz__3595(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3594: typing.Union[str, None]
) -> Resconditional_fasta_endsWith__gz__3595:
    cond = ((channel_3594 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3594)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_fasta_endsWith__gz__3595(condition=res)


class Res______fasta__3596(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______fasta__3596(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3595: typing.Union[bool, None],
    channel_3577: typing.Union[str, None]
) -> Res______fasta__3596:
    cond = ((condition_3595 == True) and (channel_3577 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3577)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______fasta__3596(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3597_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3596: str


class Res_3597_pre(NamedTuple):
    default: typing.List[Dataclass_3597_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GUNZIP_FASTA_3597_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3595: typing.Union[bool, None],
    channel_3596: typing.Union[str, None]
) -> Res_3597_pre:
    cond = ((condition_3595 == True) and (channel_3596 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3597_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3596': channel_3596})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3597_pre(default=result, is_skipped = not cond)

class Respost_adapter_GUNZIP_FASTA_3597_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3597_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_FASTA_3597_post(
    default: List[Dataclass_3597_post],
    is_skipped: bool,
) -> Respost_adapter_GUNZIP_FASTA_3597_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_FASTA_3597_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3597_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3597_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3597_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3597_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3596)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GUNZIP_FASTA_3597(
    default: Dataclass_3597_pre
) -> Dataclass_3597_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3596)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3597_post(
        gunzip=out_channels.get(f"gunzip"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3598(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3598(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3595: typing.Union[bool, None],
    channel_3597_0: typing.Union[str, None]
) -> Resmap_3598:
    cond = ((condition_3595 == True) and (channel_3597_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3597_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3598(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_fasta___3600(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_fasta___3600(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3595: typing.Union[bool, None]
) -> ResChannel_value_this_file_fasta___3600:
    cond = ((condition_3595 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"fasta"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_fasta___3600(
        res=out_channels.get("res")
    )


class ResMerge_ch_fasta_3601(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fasta_3601(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3598: typing.Union[str, None],
    channel_3600: typing.Union[str, None]
) -> ResMerge_ch_fasta_3601:
    cond = True

    if cond:
        res = { 'res': channel_3598 or channel_3600 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fasta_3601(
        res=res.get('res')
    )


class Resparams_gtf_3578(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_gtf_3578(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_gtf_3578:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"gtf"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_gtf_3578(
        res=out_channels.get("res")
    )


class Resparams_gff_3579(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_gff_3579(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_gff_3579:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"gff"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_gff_3579(
        res=out_channels.get("res")
    )


class Res_gtf____gff__3603(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _gtf____gff__3603(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3578: typing.Union[str, None],
    channel_3579: typing.Union[str, None]
) -> Res_gtf____gff__3603:
    cond = ((channel_3578 is not None) and (channel_3579 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3578), json.loads(channel_3579)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"||"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_gtf____gff__3603(
        res=out_channels.get("res")
    )


class Res_gtf____gff__3604(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _gtf____gff__3604(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3603: typing.Union[str, None]
) -> Res_gtf____gff__3604:
    cond = ((channel_3603 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3603)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_gtf____gff__3604(
        res=out_channels.get("res")
    )


class Resconditional__gtf____gff__3605(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__gtf____gff__3605(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3604: typing.Union[str, None]
) -> Resconditional__gtf____gff__3605:
    cond = ((channel_3604 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3604)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__gtf____gff__3605(condition=res)


class Resfilter_gtf_3635(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_gtf_3635(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None]
) -> Resfilter_gtf_3635:
    cond = ((condition_3605 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfilter_gtf_3635(
        res=out_channels.get("res")
    )


class Resconditional_filter_gtf_3636(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_filter_gtf_3636(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3635: typing.Union[str, None]
) -> Resconditional_filter_gtf_3636:
    cond = ((condition_3605 == True) and (channel_3635 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3635)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_filter_gtf_3636(condition=res)


class Resgtf_3606(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gtf_3606(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3578: typing.Union[str, None]
) -> Resgtf_3606:
    cond = ((condition_3605 == True) and (channel_3578 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3578)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgtf_3606(
        res=out_channels.get("res")
    )


class Resconditional_gtf_3607(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gtf_3607(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3606: typing.Union[str, None]
) -> Resconditional_gtf_3607:
    cond = ((condition_3605 == True) and (channel_3606 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3606)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gtf_3607(condition=res)


class Resgtf_endsWith__gz__3608(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gtf_endsWith__gz__3608(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3578: typing.Union[str, None]
) -> Resgtf_endsWith__gz__3608:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (channel_3578 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3578)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"gtf"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgtf_endsWith__gz__3608(
        res=out_channels.get("res")
    )


class Resgtf_endsWith__gz__3609(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gtf_endsWith__gz__3609(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3608: typing.Union[str, None]
) -> Resgtf_endsWith__gz__3609:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (channel_3608 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3608)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgtf_endsWith__gz__3609(
        res=out_channels.get("res")
    )


class Resconditional_gtf_endsWith__gz__3610(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gtf_endsWith__gz__3610(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3609: typing.Union[str, None]
) -> Resconditional_gtf_endsWith__gz__3610:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (channel_3609 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3609)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gtf_endsWith__gz__3610(condition=res)


class Res______gtf__3611(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______gtf__3611(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3610: typing.Union[bool, None],
    channel_3578: typing.Union[str, None]
) -> Res______gtf__3611:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (condition_3610 == True) and (channel_3578 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3578)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______gtf__3611(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3612_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3611: str


class Res_3612_pre(NamedTuple):
    default: typing.List[Dataclass_3612_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GUNZIP_GTF_3612_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3610: typing.Union[bool, None],
    channel_3611: typing.Union[str, None]
) -> Res_3612_pre:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (condition_3610 == True) and (channel_3611 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3612_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3611': channel_3611})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3612_pre(default=result, is_skipped = not cond)

class Respost_adapter_GUNZIP_GTF_3612_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3612_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_GTF_3612_post(
    default: List[Dataclass_3612_post],
    is_skipped: bool,
) -> Respost_adapter_GUNZIP_GTF_3612_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_GTF_3612_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3612_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3612_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3612_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3612_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3611)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_GTF","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GTF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GTF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GUNZIP_GTF_3612(
    default: Dataclass_3612_pre
) -> Dataclass_3612_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3611)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_GTF","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GTF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GTF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3612_post(
        gunzip=out_channels.get(f"gunzip"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3613(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3613(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3610: typing.Union[bool, None],
    channel_3612_0: typing.Union[str, None]
) -> Resmap_3613:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (condition_3610 == True) and (channel_3612_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3612_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3613(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_gtf___3615(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_gtf___3615(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3610: typing.Union[bool, None]
) -> ResChannel_value_this_file_gtf___3615:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (condition_3610 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"gtf"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_gtf___3615(
        res=out_channels.get("res")
    )


class ResMerge_ch_gtf_3616(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gtf_3616(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3613: typing.Union[str, None],
    channel_3615: typing.Union[str, None]
) -> ResMerge_ch_gtf_3616:
    cond = ((condition_3605 == True) and (condition_3607 == True))

    if cond:
        res = { 'res': channel_3613 or channel_3615 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gtf_3616(
        res=res.get('res')
    )


class Resgff_3618(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gff_3618(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3579: typing.Union[str, None]
) -> Resgff_3618:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (channel_3579 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3579)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgff_3618(
        res=out_channels.get("res")
    )


class Resconditional_gff_3619(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gff_3619(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3618: typing.Union[str, None]
) -> Resconditional_gff_3619:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (channel_3618 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3618)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gff_3619(condition=res)


class Resgff_endsWith__gz__3620(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gff_endsWith__gz__3620(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3579: typing.Union[str, None]
) -> Resgff_endsWith__gz__3620:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (channel_3579 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3579)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"gff"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgff_endsWith__gz__3620(
        res=out_channels.get("res")
    )


class Resgff_endsWith__gz__3621(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gff_endsWith__gz__3621(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3620: typing.Union[str, None]
) -> Resgff_endsWith__gz__3621:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (channel_3620 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3620)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgff_endsWith__gz__3621(
        res=out_channels.get("res")
    )


class Resconditional_gff_endsWith__gz__3622(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gff_endsWith__gz__3622(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3621: typing.Union[str, None]
) -> Resconditional_gff_endsWith__gz__3622:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (channel_3621 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3621)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gff_endsWith__gz__3622(condition=res)


class Res______gff__3623(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______gff__3623(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    condition_3622: typing.Union[bool, None],
    channel_3579: typing.Union[str, None]
) -> Res______gff__3623:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (condition_3622 == True) and (channel_3579 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3579)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______gff__3623(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3624_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3623: str


class Res_3624_pre(NamedTuple):
    default: typing.List[Dataclass_3624_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GUNZIP_GFF_3624_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    condition_3622: typing.Union[bool, None],
    channel_3623: typing.Union[str, None]
) -> Res_3624_pre:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (condition_3622 == True) and (channel_3623 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3624_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3623': channel_3623})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3624_pre(default=result, is_skipped = not cond)

class Respost_adapter_GUNZIP_GFF_3624_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3624_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_GFF_3624_post(
    default: List[Dataclass_3624_post],
    is_skipped: bool,
) -> Respost_adapter_GUNZIP_GFF_3624_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_GFF_3624_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3624_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3624_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3624_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3624_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3623)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_GFF","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GUNZIP_GFF_3624(
    default: Dataclass_3624_pre
) -> Dataclass_3624_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3623)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_GFF","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GFF\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3624_post(
        gunzip=out_channels.get(f"gunzip"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3625(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3625(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    condition_3622: typing.Union[bool, None],
    channel_3624_0: typing.Union[str, None]
) -> Resmap_3625:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (condition_3622 == True) and (channel_3624_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3624_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3625(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_gff___3627(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_gff___3627(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    condition_3622: typing.Union[bool, None]
) -> ResChannel_value_this_file_gff___3627:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (condition_3622 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"gff"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_gff___3627(
        res=out_channels.get("res")
    )


class ResMerge_ch_gff_3628(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gff_3628(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3625: typing.Union[str, None],
    channel_3627: typing.Union[str, None]
) -> ResMerge_ch_gff_3628:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True))

    if cond:
        res = { 'res': channel_3625 or channel_3627 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gff_3628(
        res=res.get('res')
    )


@dataclass
class Dataclass_3630_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3628: str


class Res_3630_pre(NamedTuple):
    default: typing.List[Dataclass_3630_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GFFREAD_3630_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3628: typing.Union[str, None]
) -> Res_3630_pre:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (channel_3628 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3630_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3628': channel_3628})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3630_pre(default=result, is_skipped = not cond)

class Respost_adapter_GFFREAD_3630_post(NamedTuple):
    gtf: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3630_post:
    gtf: str
    versions: str

@task(cache=True)
def post_adapter_GFFREAD_3630_post(
    default: List[Dataclass_3630_post],
    is_skipped: bool,
) -> Respost_adapter_GFFREAD_3630_post:
    return get_mapper_outputs(Respost_adapter_GFFREAD_3630_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3630_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3630_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3630_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3630_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3628)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GFFREAD","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GFFREAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GFFREAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GFFREAD_3630(
    default: Dataclass_3630_pre
) -> Dataclass_3630_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3628)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GFFREAD","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GFFREAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GFFREAD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3630_post(
        gtf=out_channels.get(f"gtf"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_gtf_3633(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gtf_3633(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3616: typing.Union[str, None],
    channel_3630_0: typing.Union[str, None]
) -> ResMerge_ch_gtf_3633:
    cond = ((condition_3605 == True))

    if cond:
        res = { 'res': channel_3616 or channel_3630_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gtf_3633(
        res=res.get('res')
    )


@dataclass
class Dataclass_3637_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3601: str
    channel_3633: str


class Res_3637_pre(NamedTuple):
    default: typing.List[Dataclass_3637_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GTF_FILTER_3637_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3636: typing.Union[bool, None],
    channel_3601: typing.Union[str, None],
    channel_3633: typing.Union[str, None]
) -> Res_3637_pre:
    cond = ((condition_3605 == True) and (condition_3636 == True) and (channel_3601 is not None) and (channel_3633 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3637_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3601': channel_3601, 'channel_3633': channel_3633})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3637_pre(default=result, is_skipped = not cond)

class Respost_adapter_GTF_FILTER_3637_post(NamedTuple):
    genome_gtf: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3637_post:
    genome_gtf: str
    versions: str

@task(cache=True)
def post_adapter_GTF_FILTER_3637_post(
    default: List[Dataclass_3637_post],
    is_skipped: bool,
) -> Respost_adapter_GTF_FILTER_3637_post:
    return get_mapper_outputs(Respost_adapter_GTF_FILTER_3637_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3637_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3637_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3637_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3637_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3601),json.loads(default.channel_3633)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GTF_FILTER","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"genome_gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF_FILTER\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF_FILTER\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GTF_FILTER_3637(
    default: Dataclass_3637_pre
) -> Dataclass_3637_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3601),json.loads(default.channel_3633)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GTF_FILTER","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"genome_gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF_FILTER\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF_FILTER\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3637_post(
        genome_gtf=out_channels.get(f"genome_gtf"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_gtf_3639(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gtf_3639(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3637_0: typing.Union[str, None],
    channel_3633: typing.Union[str, None]
) -> ResMerge_ch_gtf_3639:
    cond = ((condition_3605 == True))

    if cond:
        res = { 'res': channel_3637_0 or channel_3633 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gtf_3639(
        res=res.get('res')
    )


class Resadditional_fasta_endsWith__gz__3644(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def additional_fasta_endsWith__gz__3644(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3580: typing.Union[str, None]
) -> Resadditional_fasta_endsWith__gz__3644:
    cond = ((condition_3643 == True) and (channel_3580 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3580)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"additional_fasta"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resadditional_fasta_endsWith__gz__3644(
        res=out_channels.get("res")
    )


class Resadditional_fasta_endsWith__gz__3645(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def additional_fasta_endsWith__gz__3645(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3644: typing.Union[str, None]
) -> Resadditional_fasta_endsWith__gz__3645:
    cond = ((condition_3643 == True) and (channel_3644 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3644)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resadditional_fasta_endsWith__gz__3645(
        res=out_channels.get("res")
    )


class Resconditional_additional_fasta_endsWith__gz__3646(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_additional_fasta_endsWith__gz__3646(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3645: typing.Union[str, None]
) -> Resconditional_additional_fasta_endsWith__gz__3646:
    cond = ((condition_3643 == True) and (channel_3645 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3645)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_additional_fasta_endsWith__gz__3646(condition=res)


class Res______additional_fasta__3647(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______additional_fasta__3647(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    condition_3646: typing.Union[bool, None],
    channel_3580: typing.Union[str, None]
) -> Res______additional_fasta__3647:
    cond = ((condition_3643 == True) and (condition_3646 == True) and (channel_3580 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3580)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______additional_fasta__3647(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3648_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3647: str


class Res_3648_pre(NamedTuple):
    default: typing.List[Dataclass_3648_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GUNZIP_ADDITIONAL_FASTA_3648_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    condition_3646: typing.Union[bool, None],
    channel_3647: typing.Union[str, None]
) -> Res_3648_pre:
    cond = ((condition_3643 == True) and (condition_3646 == True) and (channel_3647 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3648_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3647': channel_3647})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3648_pre(default=result, is_skipped = not cond)

class Respost_adapter_GUNZIP_ADDITIONAL_FASTA_3648_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3648_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_ADDITIONAL_FASTA_3648_post(
    default: List[Dataclass_3648_post],
    is_skipped: bool,
) -> Respost_adapter_GUNZIP_ADDITIONAL_FASTA_3648_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_ADDITIONAL_FASTA_3648_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3648_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3648_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3648_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3648_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3647)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_ADDITIONAL_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GUNZIP_ADDITIONAL_FASTA_3648(
    default: Dataclass_3648_pre
) -> Dataclass_3648_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3647)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_ADDITIONAL_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3648_post(
        gunzip=out_channels.get(f"gunzip"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3649(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3649(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    condition_3646: typing.Union[bool, None],
    channel_3648_0: typing.Union[str, None]
) -> Resmap_3649:
    cond = ((condition_3643 == True) and (condition_3646 == True) and (channel_3648_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3648_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3649(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_additional_fasta___3651(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_additional_fasta___3651(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    condition_3646: typing.Union[bool, None]
) -> ResChannel_value_this_file_additional_fasta___3651:
    cond = ((condition_3643 == True) and (condition_3646 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"additional_fasta"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_additional_fasta___3651(
        res=out_channels.get("res")
    )


class ResMerge_ch_add_fasta_3652(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_add_fasta_3652(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3649: typing.Union[str, None],
    channel_3651: typing.Union[str, None]
) -> ResMerge_ch_add_fasta_3652:
    cond = ((condition_3643 == True))

    if cond:
        res = { 'res': channel_3649 or channel_3651 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_add_fasta_3652(
        res=res.get('res')
    )


@dataclass
class Dataclass_3654_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3601: str
    channel_3639: str
    channel_3652: str


class Res_3654_pre(NamedTuple):
    default: typing.List[Dataclass_3654_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_CAT_ADDITIONAL_FASTA_3654_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3601: typing.Union[str, None],
    channel_3639: typing.Union[str, None],
    channel_3652: typing.Union[str, None]
) -> Res_3654_pre:
    cond = ((condition_3643 == True) and (channel_3601 is not None) and (channel_3639 is not None) and (channel_3652 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3654_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3601': channel_3601, 'channel_3639': channel_3639, 'channel_3652': channel_3652})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3654_pre(default=result, is_skipped = not cond)

class Respost_adapter_CAT_ADDITIONAL_FASTA_3654_post(NamedTuple):
    fasta: typing.Union[str, None]
    gtf: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3654_post:
    fasta: str
    gtf: str
    versions: str

@task(cache=True)
def post_adapter_CAT_ADDITIONAL_FASTA_3654_post(
    default: List[Dataclass_3654_post],
    is_skipped: bool,
) -> Respost_adapter_CAT_ADDITIONAL_FASTA_3654_post:
    return get_mapper_outputs(Respost_adapter_CAT_ADDITIONAL_FASTA_3654_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3654_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3654_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3654_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3654_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3601),json.loads(default.channel_3639),json.loads(default.channel_3652)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CAT_ADDITIONAL_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def CAT_ADDITIONAL_FASTA_3654(
    default: Dataclass_3654_pre
) -> Dataclass_3654_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3601),json.loads(default.channel_3639),json.loads(default.channel_3652)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CAT_ADDITIONAL_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_ADDITIONAL_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3654_post(
        fasta=out_channels.get(f"fasta"),
        gtf=out_channels.get(f"gtf"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_fasta_3658(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fasta_3658(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3654_0: typing.Union[str, None],
    channel_3601: typing.Union[str, None]
) -> ResMerge_ch_fasta_3658:
    cond = True

    if cond:
        res = { 'res': channel_3654_0 or channel_3601 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fasta_3658(
        res=res.get('res')
    )


class Resmap_3697(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3697(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_3697:
    cond = ((channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3697(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3698_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3697: str


class Res_3698_pre(NamedTuple):
    default: typing.List[Dataclass_3698_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_CUSTOM_GETCHROMSIZES_3698_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3697: typing.Union[str, None]
) -> Res_3698_pre:
    cond = ((channel_3697 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3698_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3697': channel_3697})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3698_pre(default=result, is_skipped = not cond)

class Respost_adapter_CUSTOM_GETCHROMSIZES_3698_post(NamedTuple):
    sizes: typing.Union[str, None]
    fai: typing.Union[str, None]
    gzi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3698_post:
    sizes: str
    fai: str
    gzi: str
    versions: str

@task(cache=True)
def post_adapter_CUSTOM_GETCHROMSIZES_3698_post(
    default: List[Dataclass_3698_post],
    is_skipped: bool,
) -> Respost_adapter_CUSTOM_GETCHROMSIZES_3698_post:
    return get_mapper_outputs(Respost_adapter_CUSTOM_GETCHROMSIZES_3698_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3698_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3698_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3698_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3698_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3697)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_GETCHROMSIZES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sizes\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gzi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def CUSTOM_GETCHROMSIZES_3698(
    default: Dataclass_3698_pre
) -> Dataclass_3698_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3697)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_GETCHROMSIZES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sizes\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gzi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_GETCHROMSIZES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3698_post(
        sizes=out_channels.get(f"sizes"),
        fai=out_channels.get(f"fai"),
        gzi=out_channels.get(f"gzi"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3699(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3699(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3698_1: typing.Union[str, None]
) -> Resmap_3699:
    cond = ((channel_3698_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3698_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3699(
        res=out_channels.get("res")
    )


class Resmap_3872(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3872(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3871: typing.Union[bool, None],
    channel_3699: typing.Union[str, None]
) -> Resmap_3872:
    cond = ((condition_3871 == True) and (channel_3699 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3699)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"checkMaxContigSize","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"it"},{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3872(
        res=out_channels.get("res")
    )


class Res_params_trimmer____trimgalore__3888(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_trimmer____trimgalore__3888(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_params_trimmer____trimgalore__3888:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"trimmer"}},"operation":"==","rightExpression":{"ConstantExpression":"trimgalore"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_trimmer____trimgalore__3888(
        res=out_channels.get("res")
    )


class Res_params_trimmer____trimgalore__3889(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_trimmer____trimgalore__3889(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3888: typing.Union[str, None]
) -> Res_params_trimmer____trimgalore__3889:
    cond = ((channel_3888 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3888)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_trimmer____trimgalore__3889(
        res=out_channels.get("res")
    )


class Resconditional__params_trimmer____trimgalore__3890(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_trimmer____trimgalore__3890(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3889: typing.Union[str, None]
) -> Resconditional__params_trimmer____trimgalore__3890:
    cond = ((channel_3889 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3889)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_trimmer____trimgalore__3890(condition=res)


class Resparams_min_trimmed_reads_3896(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_min_trimmed_reads_3896(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> Resparams_min_trimmed_reads_3896:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"min_trimmed_reads"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_min_trimmed_reads_3896(
        res=out_channels.get("res")
    )


class Res_params_skip_fastqc____params_skip_qc__3891(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_fastqc____params_skip_qc__3891(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> Res_params_skip_fastqc____params_skip_qc__3891:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_fastqc"}},"operation":"||","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_fastqc____params_skip_qc__3891(
        res=out_channels.get("res")
    )


class Resskip_fastqc_3900(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_fastqc_3900(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3891: typing.Union[str, None]
) -> Resskip_fastqc_3900:
    cond = ((condition_3890 == True) and (channel_3891 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3891)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_fastqc_3900(
        res=out_channels.get("res")
    )


class Resskip_fastqc_3901(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_fastqc_3901(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3900: typing.Union[str, None]
) -> Resskip_fastqc_3901:
    cond = ((condition_3890 == True) and (channel_3900 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3900)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_fastqc_3901(
        res=out_channels.get("res")
    )


class Resconditional_skip_fastqc_3902(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_fastqc_3902(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3901: typing.Union[str, None]
) -> Resconditional_skip_fastqc_3902:
    cond = ((condition_3890 == True) and (channel_3901 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3901)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_fastqc_3902(condition=res)


class ResChannel_fromSamplesheet_input__3873(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_fromSamplesheet_input__3873(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_fromSamplesheet_input__3873:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"fromSamplesheet","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"input"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_fromSamplesheet_input__3873(
        res=out_channels.get("res")
    )


class Resmap_3874(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3874(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3873: typing.Union[str, None]
) -> Resmap_3874:
    cond = ((channel_3873 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3873)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"NotExpression":{"VariableExpression":"fastq_2"}}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"single_end"},"valueExpression":{"ConstantExpression":true}}}]}}},{"ListExpression":[{"VariableExpression":"fastq_1"}]}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"single_end"},"valueExpression":{"ConstantExpression":false}}}]}}},{"ListExpression":[{"VariableExpression":"fastq_1"},{"VariableExpression":"fastq_2"}]}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fastq_1","fastq_2"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3874(
        res=out_channels.get("res")
    )


class ResgroupTuple_3875(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_3875(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3874: typing.Union[str, None]
) -> ResgroupTuple_3875:
    cond = ((channel_3874 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3874)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResgroupTuple_3875(
        res=out_channels.get("res")
    )


class Resmap_3876(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3876(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3875: typing.Union[str, None]
) -> Resmap_3876:
    cond = ((channel_3875 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3875)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"validateInput","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"it"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3876(
        res=out_channels.get("res")
    )


class Resbranch_3877(NamedTuple):
    single: typing.Union[str, None]
    multiple: typing.Union[str, None]

@task(cache=True)
def branch_3877(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3876: typing.Union[str, None]
) -> Resbranch_3877:
    cond = ((channel_3876 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3876)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"branch","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastqs"},"method":"size","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":1}]}}}},"labels":["single"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastqs"},"method":"flatten","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]},{"ConstantExpression":"single"}]}}}}},{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareGreaterThan","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastqs"},"method":"size","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":1}]}}}},"labels":["multiple"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"fastqs"},"method":"flatten","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]},{"ConstantExpression":"multiple"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fastqs"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"single\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"single\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"multiple\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"multiple\\"}}}},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'single': None, 'multiple': None}

    return Resbranch_3877(
        single=out_channels.get("single"),
        multiple=out_channels.get("multiple")
    )


@dataclass
class Dataclass_3878_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3877_1: str


class Res_3878_pre(NamedTuple):
    default: typing.List[Dataclass_3878_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_CAT_FASTQ_3878_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3877_1: typing.Union[str, None]
) -> Res_3878_pre:
    cond = ((channel_3877_1 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3878_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3877_1': channel_3877_1})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3878_pre(default=result, is_skipped = not cond)

class Respost_adapter_CAT_FASTQ_3878_post(NamedTuple):
    reads: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3878_post:
    reads: str
    versions: str

@task(cache=True)
def post_adapter_CAT_FASTQ_3878_post(
    default: List[Dataclass_3878_post],
    is_skipped: bool,
) -> Respost_adapter_CAT_FASTQ_3878_post:
    return get_mapper_outputs(Respost_adapter_CAT_FASTQ_3878_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3878_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3878_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3878_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3878_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3877_1)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CAT_FASTQ","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def CAT_FASTQ_3878(
    default: Dataclass_3878_pre
) -> Dataclass_3878_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3877_1)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CAT_FASTQ","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CAT_FASTQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3878_post(
        reads=out_channels.get(f"reads"),
        versions=out_channels.get(f"versions")
    )


class Resmix_3879(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3879(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3878_0: typing.Union[str, None],
    channel_3877_0: typing.Union[str, None]
) -> Resmix_3879:
    cond = ((channel_3878_0 is not None) and (channel_3877_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3878_0), json.loads(channel_3877_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3879(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3903_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3879: str


class Res_3903_pre(NamedTuple):
    default: typing.List[Dataclass_3903_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_FASTQC_3903_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3902: typing.Union[bool, None],
    channel_3879: typing.Union[str, None]
) -> Res_3903_pre:
    cond = ((condition_3890 == True) and (condition_3902 == True) and (channel_3879 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3903_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3879': channel_3879})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3903_pre(default=result, is_skipped = not cond)

class Respost_adapter_FASTQC_3903_post(NamedTuple):
    html: typing.Union[str, None]
    zip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3903_post:
    html: str
    zip: str
    versions: str

@task(cache=True)
def post_adapter_FASTQC_3903_post(
    default: List[Dataclass_3903_post],
    is_skipped: bool,
) -> Respost_adapter_FASTQC_3903_post:
    return get_mapper_outputs(Respost_adapter_FASTQC_3903_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3903_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3903_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3903_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3903_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def FASTQC_3903(
    default: Dataclass_3903_pre
) -> Dataclass_3903_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3903_post(
        html=out_channels.get(f"html"),
        zip=out_channels.get(f"zip"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3898(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3898(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3898:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3898(
        res=out_channels.get("res")
    )


class ResMerge_fastqc_html_3906(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_html_3906(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3903_0: typing.Union[str, None],
    channel_3898: typing.Union[str, None]
) -> ResMerge_fastqc_html_3906:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3903_0 or channel_3898 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_html_3906(
        res=res.get('res')
    )


class Resparams_with_umi_3892(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_with_umi_3892(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> Resparams_with_umi_3892:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"with_umi"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_with_umi_3892(
        res=out_channels.get("res")
    )


class Resparams_skip_umi_extract_3893(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_umi_extract_3893(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> Resparams_skip_umi_extract_3893:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_umi_extract"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_umi_extract_3893(
        res=out_channels.get("res")
    )


class Resskip_umi_extract_3910(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_umi_extract_3910(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3893: typing.Union[str, None]
) -> Resskip_umi_extract_3910:
    cond = ((condition_3890 == True) and (channel_3893 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3893)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_umi_extract_3910(
        res=out_channels.get("res")
    )


class Res_with_umi____skip_umi_extract__3911(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _with_umi____skip_umi_extract__3911(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3892: typing.Union[str, None],
    channel_3910: typing.Union[str, None]
) -> Res_with_umi____skip_umi_extract__3911:
    cond = ((condition_3890 == True) and (channel_3892 is not None) and (channel_3910 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3892), json.loads(channel_3910)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_with_umi____skip_umi_extract__3911(
        res=out_channels.get("res")
    )


class Res_with_umi____skip_umi_extract__3912(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _with_umi____skip_umi_extract__3912(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3911: typing.Union[str, None]
) -> Res_with_umi____skip_umi_extract__3912:
    cond = ((condition_3890 == True) and (channel_3911 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3911)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_with_umi____skip_umi_extract__3912(
        res=out_channels.get("res")
    )


class Resconditional__with_umi____skip_umi_extract__3913(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__with_umi____skip_umi_extract__3913(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3912: typing.Union[str, None]
) -> Resconditional__with_umi____skip_umi_extract__3913:
    cond = ((condition_3890 == True) and (channel_3912 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3912)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__with_umi____skip_umi_extract__3913(condition=res)


@dataclass
class Dataclass_3914_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3879: str


class Res_3914_pre(NamedTuple):
    default: typing.List[Dataclass_3914_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UMITOOLS_EXTRACT_3914_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3879: typing.Union[str, None]
) -> Res_3914_pre:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (channel_3879 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3914_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3879': channel_3879})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3914_pre(default=result, is_skipped = not cond)

class Respost_adapter_UMITOOLS_EXTRACT_3914_post(NamedTuple):
    reads: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3914_post:
    reads: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_UMITOOLS_EXTRACT_3914_post(
    default: List[Dataclass_3914_post],
    is_skipped: bool,
) -> Respost_adapter_UMITOOLS_EXTRACT_3914_post:
    return get_mapper_outputs(Respost_adapter_UMITOOLS_EXTRACT_3914_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3914_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3914_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3914_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3914_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_EXTRACT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UMITOOLS_EXTRACT_3914(
    default: Dataclass_3914_pre
) -> Dataclass_3914_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_EXTRACT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3914_post(
        reads=out_channels.get(f"reads"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3909(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3909(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3909:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3909(
        res=out_channels.get("res")
    )


class ResMerge_umi_log_3923(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_umi_log_3923(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3914_1: typing.Union[str, None],
    channel_3909: typing.Union[str, None]
) -> ResMerge_umi_log_3923:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3914_1 or channel_3909 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_umi_log_3923(
        res=res.get('res')
    )


class Resparams_skip_trimming_3894(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_trimming_3894(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> Resparams_skip_trimming_3894:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_trimming"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_trimming_3894(
        res=out_channels.get("res")
    )


class Resskip_trimming_3930(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_trimming_3930(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3894: typing.Union[str, None]
) -> Resskip_trimming_3930:
    cond = ((condition_3890 == True) and (channel_3894 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3894)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_trimming_3930(
        res=out_channels.get("res")
    )


class Resskip_trimming_3931(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_trimming_3931(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3930: typing.Union[str, None]
) -> Resskip_trimming_3931:
    cond = ((condition_3890 == True) and (channel_3930 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3930)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_trimming_3931(
        res=out_channels.get("res")
    )


class Resconditional_skip_trimming_3932(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_trimming_3932(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3931: typing.Union[str, None]
) -> Resconditional_skip_trimming_3932:
    cond = ((condition_3890 == True) and (channel_3931 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3931)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_trimming_3932(condition=res)


class Resparams_umi_discard_read_3895(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_umi_discard_read_3895(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> Resparams_umi_discard_read_3895:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"umi_discard_read"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_umi_discard_read_3895(
        res=out_channels.get("res")
    )


class Res_umi_discard_read_in__1__2___3917(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _umi_discard_read_in__1__2___3917(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3895: typing.Union[str, None]
) -> Res_umi_discard_read_in__1__2___3917:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (channel_3895 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3895)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"ConstantExpression":1},{"ConstantExpression":2}]},{"ConstantExpression":"in"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_umi_discard_read_in__1__2___3917(
        res=out_channels.get("res")
    )


class Res_umi_discard_read_in__1__2___3918(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _umi_discard_read_in__1__2___3918(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3917: typing.Union[str, None]
) -> Res_umi_discard_read_in__1__2___3918:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (channel_3917 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3917)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_umi_discard_read_in__1__2___3918(
        res=out_channels.get("res")
    )


class Resconditional__umi_discard_read_in__1__2___3919(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__umi_discard_read_in__1__2___3919(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3918: typing.Union[str, None]
) -> Resconditional__umi_discard_read_in__1__2___3919:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (channel_3918 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3918)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__umi_discard_read_in__1__2___3919(condition=res)


class Resmap_3920(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3920(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    condition_3919: typing.Union[bool, None],
    channel_3914_0: typing.Union[str, None]
) -> Resmap_3920:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (condition_3919 == True) and (channel_3914_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3914_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"single_end"}}},"trueExpression":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"}]},"falseExpression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"single_end"},"valueExpression":{"ConstantExpression":true}}}]}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"reads"},"operation":"[","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"umi_discard_read"},"operation":"%","rightExpression":{"ConstantExpression":2}}}}}]}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["umi_discard_read"]},"labels":[]}},"parameters":["meta","reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3920(
        res=out_channels.get("res")
    )


class ResMerge_umi_reads_3921(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_umi_reads_3921(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3920: typing.Union[str, None],
    channel_3914_0: typing.Union[str, None]
) -> ResMerge_umi_reads_3921:
    cond = ((condition_3890 == True) and (condition_3913 == True))

    if cond:
        res = { 'res': channel_3920 or channel_3914_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_umi_reads_3921(
        res=res.get('res')
    )


class ResMerge_umi_reads_3922(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_umi_reads_3922(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3921: typing.Union[str, None],
    channel_3879: typing.Union[str, None]
) -> ResMerge_umi_reads_3922:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3921 or channel_3879 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_umi_reads_3922(
        res=res.get('res')
    )


@dataclass
class Dataclass_3933_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3922: str


class Res_3933_pre(NamedTuple):
    default: typing.List[Dataclass_3933_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_TRIMGALORE_3933_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3922: typing.Union[str, None]
) -> Res_3933_pre:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3922 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3933_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3922': channel_3922})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3933_pre(default=result, is_skipped = not cond)

class Respost_adapter_TRIMGALORE_3933_post(NamedTuple):
    reads: typing.Union[str, None]
    log: typing.Union[str, None]
    unpaired: typing.Union[str, None]
    html: typing.Union[str, None]
    zip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3933_post:
    reads: str
    log: str
    unpaired: str
    html: str
    zip: str
    versions: str

@task(cache=True)
def post_adapter_TRIMGALORE_3933_post(
    default: List[Dataclass_3933_post],
    is_skipped: bool,
) -> Respost_adapter_TRIMGALORE_3933_post:
    return get_mapper_outputs(Respost_adapter_TRIMGALORE_3933_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3933_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3933_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3933_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3933_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3922)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TRIMGALORE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"unpaired\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def TRIMGALORE_3933(
    default: Dataclass_3933_pre
) -> Dataclass_3933_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3922)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TRIMGALORE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"unpaired\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TRIMGALORE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3933_post(
        reads=out_channels.get(f"reads"),
        log=out_channels.get(f"log"),
        unpaired=out_channels.get(f"unpaired"),
        html=out_channels.get(f"html"),
        zip=out_channels.get(f"zip"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3926(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3926(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3926:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3926(
        res=out_channels.get("res")
    )


class ResMerge_trim_html_3942(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_html_3942(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3933_3: typing.Union[str, None],
    channel_3926: typing.Union[str, None]
) -> ResMerge_trim_html_3942:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3933_3 or channel_3926 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_html_3942(
        res=res.get('res')
    )


class ResChannel_empty___3925(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3925(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3925:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3925(
        res=out_channels.get("res")
    )


class ResMerge_trim_unpaired_3945(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_unpaired_3945(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3933_2: typing.Union[str, None],
    channel_3925: typing.Union[str, None]
) -> ResMerge_trim_unpaired_3945:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3933_2 or channel_3925 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_unpaired_3945(
        res=res.get('res')
    )


class Res_params_trimmer____fastp__3956(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_trimmer____fastp__3956(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_params_trimmer____fastp__3956:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"trimmer"}},"operation":"==","rightExpression":{"ConstantExpression":"fastp"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_trimmer____fastp__3956(
        res=out_channels.get("res")
    )


class Res_params_trimmer____fastp__3957(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_trimmer____fastp__3957(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3956: typing.Union[str, None]
) -> Res_params_trimmer____fastp__3957:
    cond = ((channel_3956 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3956)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_trimmer____fastp__3957(
        res=out_channels.get("res")
    )


class Resconditional__params_trimmer____fastp__3958(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_trimmer____fastp__3958(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3957: typing.Union[str, None]
) -> Resconditional__params_trimmer____fastp__3958:
    cond = ((channel_3957 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3957)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_trimmer____fastp__3958(condition=res)


class Resparams_min_trimmed_reads_3967(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_min_trimmed_reads_3967(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_min_trimmed_reads_3967:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"min_trimmed_reads"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_min_trimmed_reads_3967(
        res=out_channels.get("res")
    )


class Res_params_skip_fastqc____params_skip_qc__3959(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_fastqc____params_skip_qc__3959(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Res_params_skip_fastqc____params_skip_qc__3959:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_fastqc"}},"operation":"||","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_fastqc____params_skip_qc__3959(
        res=out_channels.get("res")
    )


class Resskip_fastqc_3971(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_fastqc_3971(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3959: typing.Union[str, None]
) -> Resskip_fastqc_3971:
    cond = ((condition_3958 == True) and (channel_3959 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3959)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_fastqc_3971(
        res=out_channels.get("res")
    )


class Resskip_fastqc_3972(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_fastqc_3972(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3971: typing.Union[str, None]
) -> Resskip_fastqc_3972:
    cond = ((condition_3958 == True) and (channel_3971 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3971)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_fastqc_3972(
        res=out_channels.get("res")
    )


class Resconditional_skip_fastqc_3973(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_fastqc_3973(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3972: typing.Union[str, None]
) -> Resconditional_skip_fastqc_3973:
    cond = ((condition_3958 == True) and (channel_3972 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3972)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_fastqc_3973(condition=res)


@dataclass
class Dataclass_3974_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3879: str


class Res_3974_pre(NamedTuple):
    default: typing.List[Dataclass_3974_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_FASTQC_RAW_3974_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3973: typing.Union[bool, None],
    channel_3879: typing.Union[str, None]
) -> Res_3974_pre:
    cond = ((condition_3958 == True) and (condition_3973 == True) and (channel_3879 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3974_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3879': channel_3879})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3974_pre(default=result, is_skipped = not cond)

class Respost_adapter_FASTQC_RAW_3974_post(NamedTuple):
    html: typing.Union[str, None]
    zip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3974_post:
    html: str
    zip: str
    versions: str

@task(cache=True)
def post_adapter_FASTQC_RAW_3974_post(
    default: List[Dataclass_3974_post],
    is_skipped: bool,
) -> Respost_adapter_FASTQC_RAW_3974_post:
    return get_mapper_outputs(Respost_adapter_FASTQC_RAW_3974_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3974_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3974_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3974_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3974_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC_RAW","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_RAW\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_RAW\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_RAW\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def FASTQC_RAW_3974(
    default: Dataclass_3974_pre
) -> Dataclass_3974_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC_RAW","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_RAW\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_RAW\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_RAW\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3974_post(
        html=out_channels.get(f"html"),
        zip=out_channels.get(f"zip"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3969(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3969(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3969:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3969(
        res=out_channels.get("res")
    )


class ResMerge_fastqc_raw_html_3978(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_raw_html_3978(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3974_0: typing.Union[str, None],
    channel_3969: typing.Union[str, None]
) -> ResMerge_fastqc_raw_html_3978:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_3974_0 or channel_3969 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_raw_html_3978(
        res=res.get('res')
    )


class Resparams_with_umi_3960(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_with_umi_3960(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_with_umi_3960:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"with_umi"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_with_umi_3960(
        res=out_channels.get("res")
    )


class Resparams_skip_umi_extract_3961(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_umi_extract_3961(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_skip_umi_extract_3961:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_umi_extract"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_umi_extract_3961(
        res=out_channels.get("res")
    )


class Resskip_umi_extract_3981(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_umi_extract_3981(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3961: typing.Union[str, None]
) -> Resskip_umi_extract_3981:
    cond = ((condition_3958 == True) and (channel_3961 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3961)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_umi_extract_3981(
        res=out_channels.get("res")
    )


class Res_with_umi____skip_umi_extract__3982(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _with_umi____skip_umi_extract__3982(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3960: typing.Union[str, None],
    channel_3981: typing.Union[str, None]
) -> Res_with_umi____skip_umi_extract__3982:
    cond = ((condition_3958 == True) and (channel_3960 is not None) and (channel_3981 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3960), json.loads(channel_3981)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_with_umi____skip_umi_extract__3982(
        res=out_channels.get("res")
    )


class Res_with_umi____skip_umi_extract__3983(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _with_umi____skip_umi_extract__3983(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3982: typing.Union[str, None]
) -> Res_with_umi____skip_umi_extract__3983:
    cond = ((condition_3958 == True) and (channel_3982 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3982)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_with_umi____skip_umi_extract__3983(
        res=out_channels.get("res")
    )


class Resconditional__with_umi____skip_umi_extract__3984(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__with_umi____skip_umi_extract__3984(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3983: typing.Union[str, None]
) -> Resconditional__with_umi____skip_umi_extract__3984:
    cond = ((condition_3958 == True) and (channel_3983 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3983)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__with_umi____skip_umi_extract__3984(condition=res)


@dataclass
class Dataclass_3985_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3879: str


class Res_3985_pre(NamedTuple):
    default: typing.List[Dataclass_3985_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UMITOOLS_EXTRACT_3985_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3879: typing.Union[str, None]
) -> Res_3985_pre:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (channel_3879 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3985_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3879': channel_3879})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3985_pre(default=result, is_skipped = not cond)

class Respost_adapter_UMITOOLS_EXTRACT_3985_post(NamedTuple):
    reads: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3985_post:
    reads: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_UMITOOLS_EXTRACT_3985_post(
    default: List[Dataclass_3985_post],
    is_skipped: bool,
) -> Respost_adapter_UMITOOLS_EXTRACT_3985_post:
    return get_mapper_outputs(Respost_adapter_UMITOOLS_EXTRACT_3985_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3985_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3985_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3985_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3985_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_EXTRACT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UMITOOLS_EXTRACT_3985(
    default: Dataclass_3985_pre
) -> Dataclass_3985_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3879)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_EXTRACT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_EXTRACT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3985_post(
        reads=out_channels.get(f"reads"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3980(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3980(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3980:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3980(
        res=out_channels.get("res")
    )


class ResMerge_umi_log_3994(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_umi_log_3994(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3985_1: typing.Union[str, None],
    channel_3980: typing.Union[str, None]
) -> ResMerge_umi_log_3994:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_3985_1 or channel_3980 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_umi_log_3994(
        res=res.get('res')
    )


class Resparams_skip_trimming_3963(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_trimming_3963(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_skip_trimming_3963:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_trimming"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_trimming_3963(
        res=out_channels.get("res")
    )


class Resskip_trimming_4004(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_trimming_4004(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3963: typing.Union[str, None]
) -> Resskip_trimming_4004:
    cond = ((condition_3958 == True) and (channel_3963 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3963)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_trimming_4004(
        res=out_channels.get("res")
    )


class Resskip_trimming_4005(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_trimming_4005(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4004: typing.Union[str, None]
) -> Resskip_trimming_4005:
    cond = ((condition_3958 == True) and (channel_4004 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4004)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_trimming_4005(
        res=out_channels.get("res")
    )


class Resconditional_skip_trimming_4006(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_trimming_4006(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4005: typing.Union[str, None]
) -> Resconditional_skip_trimming_4006:
    cond = ((condition_3958 == True) and (channel_4005 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4005)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_trimming_4006(condition=res)


class Resparams_umi_discard_read_3962(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_umi_discard_read_3962(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_umi_discard_read_3962:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"umi_discard_read"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_umi_discard_read_3962(
        res=out_channels.get("res")
    )


class Res_umi_discard_read_in__1__2___3988(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _umi_discard_read_in__1__2___3988(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3962: typing.Union[str, None]
) -> Res_umi_discard_read_in__1__2___3988:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (channel_3962 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3962)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"ConstantExpression":1},{"ConstantExpression":2}]},{"ConstantExpression":"in"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_umi_discard_read_in__1__2___3988(
        res=out_channels.get("res")
    )


class Res_umi_discard_read_in__1__2___3989(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _umi_discard_read_in__1__2___3989(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3988: typing.Union[str, None]
) -> Res_umi_discard_read_in__1__2___3989:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (channel_3988 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3988)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_umi_discard_read_in__1__2___3989(
        res=out_channels.get("res")
    )


class Resconditional__umi_discard_read_in__1__2___3990(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__umi_discard_read_in__1__2___3990(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3989: typing.Union[str, None]
) -> Resconditional__umi_discard_read_in__1__2___3990:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (channel_3989 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3989)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__umi_discard_read_in__1__2___3990(condition=res)


class Resmap_3991(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3991(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    condition_3990: typing.Union[bool, None],
    channel_3985_0: typing.Union[str, None]
) -> Resmap_3991:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (condition_3990 == True) and (channel_3985_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3985_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"single_end"}}},"trueExpression":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"}]},"falseExpression":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"single_end"},"valueExpression":{"ConstantExpression":true}}}]}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"reads"},"operation":"[","rightExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"umi_discard_read"},"operation":"%","rightExpression":{"ConstantExpression":2}}}}}]}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["umi_discard_read"]},"labels":[]}},"parameters":["meta","reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3991(
        res=out_channels.get("res")
    )


class ResMerge_umi_reads_3992(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_umi_reads_3992(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3991: typing.Union[str, None],
    channel_3985_0: typing.Union[str, None]
) -> ResMerge_umi_reads_3992:
    cond = ((condition_3958 == True) and (condition_3984 == True))

    if cond:
        res = { 'res': channel_3991 or channel_3985_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_umi_reads_3992(
        res=res.get('res')
    )


class ResMerge_umi_reads_3993(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_umi_reads_3993(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3992: typing.Union[str, None],
    channel_3879: typing.Union[str, None]
) -> ResMerge_umi_reads_3993:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_3992 or channel_3879 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_umi_reads_3993(
        res=res.get('res')
    )


class Res___3964(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___3964(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Res___3964:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res___3964(
        res=out_channels.get("res")
    )


class Resparams_save_trimmed_3965(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_save_trimmed_3965(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_save_trimmed_3965:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"save_trimmed"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_save_trimmed_3965(
        res=out_channels.get("res")
    )


class Resparams_save_trimmed_3966(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_save_trimmed_3966(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> Resparams_save_trimmed_3966:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"save_trimmed"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_save_trimmed_3966(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4007_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3993: str
    channel_3964: str
    channel_3965: str
    channel_3966: str


class Res_4007_pre(NamedTuple):
    default: typing.List[Dataclass_4007_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_FASTP_4007_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_3993: typing.Union[str, None],
    channel_3964: typing.Union[str, None],
    channel_3965: typing.Union[str, None],
    channel_3966: typing.Union[str, None]
) -> Res_4007_pre:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_3993 is not None) and (channel_3964 is not None) and (channel_3965 is not None) and (channel_3966 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4007_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3993': channel_3993, 'channel_3964': channel_3964, 'channel_3965': channel_3965, 'channel_3966': channel_3966})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4007_pre(default=result, is_skipped = not cond)

class Respost_adapter_FASTP_4007_post(NamedTuple):
    reads: typing.Union[str, None]
    json: typing.Union[str, None]
    html: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]
    reads_fail: typing.Union[str, None]
    reads_merged: typing.Union[str, None]

@dataclass
class Dataclass_4007_post:
    reads: str
    json: str
    html: str
    log: str
    versions: str
    reads_fail: str
    reads_merged: str

@task(cache=True)
def post_adapter_FASTP_4007_post(
    default: List[Dataclass_4007_post],
    is_skipped: bool,
) -> Respost_adapter_FASTP_4007_post:
    return get_mapper_outputs(Respost_adapter_FASTP_4007_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4007_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4007_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4007_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4007_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3993),json.loads(default.channel_3964),json.loads(default.channel_3965),json.loads(default.channel_3966)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads_fail\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads_merged\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def FASTP_4007(
    default: Dataclass_4007_pre
) -> Dataclass_4007_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3993),json.loads(default.channel_3964),json.loads(default.channel_3965),json.loads(default.channel_3966)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads_fail\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads_merged\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4007_post(
        reads=out_channels.get(f"reads"),
        json=out_channels.get(f"json"),
        html=out_channels.get(f"html"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions"),
        reads_fail=out_channels.get(f"reads_fail"),
        reads_merged=out_channels.get(f"reads_merged")
    )


class ResChannel_empty___3997(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3997(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3997:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3997(
        res=out_channels.get("res")
    )


class ResMerge_trim_html_4025(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_html_4025(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4007_2: typing.Union[str, None],
    channel_3997: typing.Union[str, None]
) -> ResMerge_trim_html_4025:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4007_2 or channel_3997 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_html_4025(
        res=res.get('res')
    )


class ResChannel_empty___3998(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3998(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3998:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3998(
        res=out_channels.get("res")
    )


class ResMerge_trim_log_4028(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_log_4028(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4007_3: typing.Union[str, None],
    channel_3998: typing.Union[str, None]
) -> ResMerge_trim_log_4028:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4007_3 or channel_3998 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_log_4028(
        res=res.get('res')
    )


class ResChannel_empty___4000(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4000(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___4000:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4000(
        res=out_channels.get("res")
    )


class ResMerge_trim_reads_merged_4030(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_reads_merged_4030(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4007_6: typing.Union[str, None],
    channel_4000: typing.Union[str, None]
) -> ResMerge_trim_reads_merged_4030:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4007_6 or channel_4000 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_reads_merged_4030(
        res=res.get('res')
    )


class ResChannel_empty___3999(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3999(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3999:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3999(
        res=out_channels.get("res")
    )


class ResMerge_trim_reads_fail_4031(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_reads_fail_4031(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4007_5: typing.Union[str, None],
    channel_3999: typing.Union[str, None]
) -> ResMerge_trim_reads_fail_4031:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4007_5 or channel_3999 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_reads_fail_4031(
        res=res.get('res')
    )


class Resskip_fastqc_4015(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_fastqc_4015(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_3959: typing.Union[str, None]
) -> Resskip_fastqc_4015:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_3959 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3959)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_fastqc_4015(
        res=out_channels.get("res")
    )


class Resskip_fastqc_4016(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def skip_fastqc_4016(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4015: typing.Union[str, None]
) -> Resskip_fastqc_4016:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4015 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4015)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resskip_fastqc_4016(
        res=out_channels.get("res")
    )


class Resconditional_skip_fastqc_4017(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_skip_fastqc_4017(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4016: typing.Union[str, None]
) -> Resconditional_skip_fastqc_4017:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4016 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4016)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_skip_fastqc_4017(condition=res)


class Resjoin_4010(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4010(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4007_0: typing.Union[str, None],
    channel_4007_1: typing.Union[str, None]
) -> Resjoin_4010:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4007_0 is not None) and (channel_4007_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4007_0), json.loads(channel_4007_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4010(
        res=out_channels.get("res")
    )


class Resmap_4011(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4011(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4010: typing.Union[str, None]
) -> Resmap_4011:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4010 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4010)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"getFastpReadsAfterFiltering","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"json"}]}}}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":["getFastpReadsAfterFiltering"]},"labels":[]}},"parameters":["meta","reads","json"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4011(
        res=out_channels.get("res")
    )


class Resfilter_4012(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_4012(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4011: typing.Union[str, None]
) -> Resfilter_4012:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4011 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4011)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareGreaterThanEqual","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"num_reads"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"min_trimmed_reads"},"method":"toLong","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["compareGreaterThanEqual","min_trimmed_reads"]},"labels":[]}},"parameters":["meta","reads","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfilter_4012(
        res=out_channels.get("res")
    )


class Resmap_4013(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4013(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4012: typing.Union[str, None]
) -> Resmap_4013:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4012 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4012)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","reads","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4013(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4018_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4013: str


class Res_4018_pre(NamedTuple):
    default: typing.List[Dataclass_4018_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_FASTQC_TRIM_4018_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    condition_4017: typing.Union[bool, None],
    channel_4013: typing.Union[str, None]
) -> Res_4018_pre:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (condition_4017 == True) and (channel_4013 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4018_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4013': channel_4013})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4018_pre(default=result, is_skipped = not cond)

class Respost_adapter_FASTQC_TRIM_4018_post(NamedTuple):
    html: typing.Union[str, None]
    zip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4018_post:
    html: str
    zip: str
    versions: str

@task(cache=True)
def post_adapter_FASTQC_TRIM_4018_post(
    default: List[Dataclass_4018_post],
    is_skipped: bool,
) -> Respost_adapter_FASTQC_TRIM_4018_post:
    return get_mapper_outputs(Respost_adapter_FASTQC_TRIM_4018_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4018_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4018_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4018_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4018_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4013)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC_TRIM","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_TRIM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_TRIM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_TRIM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def FASTQC_TRIM_4018(
    default: Dataclass_4018_pre
) -> Dataclass_4018_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4013)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_FASTQC_UMITOOLS_FASTP'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FASTQC_TRIM","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"html\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_TRIM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"zip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_TRIM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FASTQC_TRIM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4018_post(
        html=out_channels.get(f"html"),
        zip=out_channels.get(f"zip"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4001(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4001(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___4001:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4001(
        res=out_channels.get("res")
    )


class ResMerge_fastqc_trim_html_4021(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_trim_html_4021(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4018_0: typing.Union[str, None],
    channel_4001: typing.Union[str, None]
) -> ResMerge_fastqc_trim_html_4021:
    cond = ((condition_3958 == True) and (condition_4006 == True))

    if cond:
        res = { 'res': channel_4018_0 or channel_4001 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_trim_html_4021(
        res=res.get('res')
    )


class ResMerge_fastqc_trim_html_4033(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_trim_html_4033(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4021: typing.Union[str, None],
    channel_4001: typing.Union[str, None]
) -> ResMerge_fastqc_trim_html_4033:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4021 or channel_4001 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_trim_html_4033(
        res=res.get('res')
    )


class Resparams_skip_alignment_4100(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4100(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4100:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4100(
        res=out_channels.get("res")
    )


class Res_params_aligner____star_salmon__4101(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____star_salmon__4101(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_params_aligner____star_salmon__4101:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"star_salmon"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____star_salmon__4101(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment_____params_aligner____star_salmon___4102(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment_____params_aligner____star_salmon___4102(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4100: typing.Union[str, None],
    channel_4101: typing.Union[str, None]
) -> Res_params_skip_alignment_____params_aligner____star_salmon___4102:
    cond = ((channel_4100 is not None) and (channel_4101 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4100), json.loads(channel_4101)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment_____params_aligner____star_salmon___4102(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment_____params_aligner____star_salmon___4103(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment_____params_aligner____star_salmon___4103(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4102: typing.Union[str, None]
) -> Res_params_skip_alignment_____params_aligner____star_salmon___4103:
    cond = ((channel_4102 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4102)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment_____params_aligner____star_salmon___4103(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment_____params_aligner____star_salmon___4104(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment_____params_aligner____star_salmon___4104(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4103: typing.Union[str, None]
) -> Resconditional__params_skip_alignment_____params_aligner____star_salmon___4104:
    cond = ((channel_4103 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4103)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment_____params_aligner____star_salmon___4104(condition=res)


class ResChannel_empty___4112(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4112(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4112:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4112(
        res=out_channels.get("res")
    )


class ResChannel_empty___4113(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4113(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4113:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4113(
        res=out_channels.get("res")
    )


class ResChannel_empty___4114(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4114(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4114:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4114(
        res=out_channels.get("res")
    )


class ResChannel_empty___4115(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4115(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4115:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4115(
        res=out_channels.get("res")
    )


class ResChannel_empty___4116(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4116(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4116:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4116(
        res=out_channels.get("res")
    )


class ResChannel_empty___4117(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4117(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4117:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4117(
        res=out_channels.get("res")
    )


class ResChannel_empty___4118(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4118(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4118:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4118(
        res=out_channels.get("res")
    )


class ResChannel_empty___4119(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4119(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4119:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4119(
        res=out_channels.get("res")
    )


class Resmap_4110(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4110(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_4110:
    cond = ((condition_4104 == True) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4110(
        res=out_channels.get("res")
    )


class Resis_aws_igenome_4120(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def is_aws_igenome_4120(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4110: typing.Union[str, None]
) -> Resis_aws_igenome_4120:
    cond = ((condition_4104 == True) and (channel_4110 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4110)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resis_aws_igenome_4120(
        res=out_channels.get("res")
    )


class Resconditional_is_aws_igenome_4121(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_is_aws_igenome_4121(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4120: typing.Union[str, None]
) -> Resconditional_is_aws_igenome_4121:
    cond = ((condition_4104 == True) and (channel_4120 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4120)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_is_aws_igenome_4121(condition=res)


class Resparams_remove_ribo_rna_4054(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_remove_ribo_rna_4054(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_remove_ribo_rna_4054:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"remove_ribo_rna"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_remove_ribo_rna_4054(
        res=out_channels.get("res")
    )


class Resconditional_params_remove_ribo_rna_4055(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_remove_ribo_rna_4055(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4054: typing.Union[str, None]
) -> Resconditional_params_remove_ribo_rna_4055:
    cond = ((channel_4054 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4054)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_remove_ribo_rna_4055(condition=res)


class Resparams_skip_bbsplit_4045(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_bbsplit_4045(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_bbsplit_4045:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_bbsplit"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_bbsplit_4045(
        res=out_channels.get("res")
    )


class Resparams_skip_bbsplit_4046(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_bbsplit_4046(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4045: typing.Union[str, None]
) -> Resparams_skip_bbsplit_4046:
    cond = ((channel_4045 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4045)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_bbsplit_4046(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_bbsplit_4047(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_bbsplit_4047(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4046: typing.Union[str, None]
) -> Resconditional_params_skip_bbsplit_4047:
    cond = ((channel_4046 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4046)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_bbsplit_4047(condition=res)


class ResMerge_trim_reads_4032(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_reads_4032(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4013: typing.Union[str, None],
    channel_3993: typing.Union[str, None]
) -> ResMerge_trim_reads_4032:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4013 or channel_3993 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_reads_4032(
        res=res.get('res')
    )


class Resjoin_3936(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_3936(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3933_0: typing.Union[str, None],
    channel_3933_1: typing.Union[str, None]
) -> Resjoin_3936:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3933_0 is not None) and (channel_3933_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3933_0), json.loads(channel_3933_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_3936(
        res=out_channels.get("res")
    )


class Resmap_3937(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3937(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3936: typing.Union[str, None]
) -> Resmap_3937:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3936 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3936)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"trim_log"}},"ifBlock":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"num_reads"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"getTrimGaloreReadsAfterFiltering","arguments":{"ArgumentListExpression":{"expressions":[{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"single_end"}}},"trueExpression":{"VariableExpression":"trim_log"},"falseExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"trim_log"},"operation":"[","rightExpression":{"ConstantExpression":-1}}}}}]}}}}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"},{"VariableExpression":"num_reads"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":["num_reads","getTrimGaloreReadsAfterFiltering"]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"},{"BinaryExpression":{"leftExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"min_trimmed_reads"},"method":"toFloat","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"operation":"+","rightExpression":{"ConstantExpression":1}}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":["min_trimmed_reads"]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":["num_reads","getTrimGaloreReadsAfterFiltering","min_trimmed_reads"]},"labels":[]}},"parameters":["meta","reads","trim_log"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3937(
        res=out_channels.get("res")
    )


class Resfilter_3938(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_3938(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3937: typing.Union[str, None]
) -> Resfilter_3938:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3937 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3937)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareGreaterThanEqual","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"num_reads"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"min_trimmed_reads"},"method":"toFloat","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["compareGreaterThanEqual","min_trimmed_reads"]},"labels":[]}},"parameters":["meta","reads","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfilter_3938(
        res=out_channels.get("res")
    )


class Resmap_3939(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3939(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3938: typing.Union[str, None]
) -> Resmap_3939:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3938 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3938)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"reads"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","reads","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3939(
        res=out_channels.get("res")
    )


class ResMerge_trim_reads_3941(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_reads_3941(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3939: typing.Union[str, None],
    channel_3922: typing.Union[str, None]
) -> ResMerge_trim_reads_3941:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3939 or channel_3922 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_reads_3941(
        res=res.get('res')
    )


class ResChannel_empty___3883(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3883(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3883:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3883(
        res=out_channels.get("res")
    )


class ResMerge_ch_filtered_reads_3953(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_filtered_reads_3953(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3941: typing.Union[str, None],
    channel_3883: typing.Union[str, None]
) -> ResMerge_ch_filtered_reads_3953:
    cond = True

    if cond:
        res = { 'res': channel_3941 or channel_3883 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_filtered_reads_3953(
        res=res.get('res')
    )


class ResMerge_ch_filtered_reads_4039(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_filtered_reads_4039(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4032: typing.Union[str, None],
    channel_3953: typing.Union[str, None]
) -> ResMerge_ch_filtered_reads_4039:
    cond = True

    if cond:
        res = { 'res': channel_4032 or channel_3953 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_filtered_reads_4039(
        res=res.get('res')
    )


class Res_bbsplit_in_prepare_tool_indices__3703(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _bbsplit_in_prepare_tool_indices__3703(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_bbsplit_in_prepare_tool_indices__3703:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"bbsplit"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_bbsplit_in_prepare_tool_indices__3703(
        res=out_channels.get("res")
    )


class Res_bbsplit_in_prepare_tool_indices__3704(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _bbsplit_in_prepare_tool_indices__3704(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3703: typing.Union[str, None]
) -> Res_bbsplit_in_prepare_tool_indices__3704:
    cond = ((channel_3703 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3703)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_bbsplit_in_prepare_tool_indices__3704(
        res=out_channels.get("res")
    )


class Resconditional__bbsplit_in_prepare_tool_indices__3705(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__bbsplit_in_prepare_tool_indices__3705(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3704: typing.Union[str, None]
) -> Resconditional__bbsplit_in_prepare_tool_indices__3705:
    cond = ((channel_3704 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3704)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__bbsplit_in_prepare_tool_indices__3705(condition=res)


class Resparams_bbsplit_index_3590(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bbsplit_index_3590(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_bbsplit_index_3590:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bbsplit_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bbsplit_index_3590(
        res=out_channels.get("res")
    )


class Resbbsplit_index_3706(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def bbsplit_index_3706(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    channel_3590: typing.Union[str, None]
) -> Resbbsplit_index_3706:
    cond = ((condition_3705 == True) and (channel_3590 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3590)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resbbsplit_index_3706(
        res=out_channels.get("res")
    )


class Resconditional_bbsplit_index_3707(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_bbsplit_index_3707(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    channel_3706: typing.Union[str, None]
) -> Resconditional_bbsplit_index_3707:
    cond = ((condition_3705 == True) and (channel_3706 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3706)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_bbsplit_index_3707(condition=res)


class Resbbsplit_index_endsWith__tar_gz__3708(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def bbsplit_index_endsWith__tar_gz__3708(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3590: typing.Union[str, None]
) -> Resbbsplit_index_endsWith__tar_gz__3708:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (channel_3590 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3590)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"bbsplit_index"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resbbsplit_index_endsWith__tar_gz__3708(
        res=out_channels.get("res")
    )


class Resbbsplit_index_endsWith__tar_gz__3709(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def bbsplit_index_endsWith__tar_gz__3709(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3708: typing.Union[str, None]
) -> Resbbsplit_index_endsWith__tar_gz__3709:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (channel_3708 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3708)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resbbsplit_index_endsWith__tar_gz__3709(
        res=out_channels.get("res")
    )


class Resconditional_bbsplit_index_endsWith__tar_gz__3710(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_bbsplit_index_endsWith__tar_gz__3710(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3709: typing.Union[str, None]
) -> Resconditional_bbsplit_index_endsWith__tar_gz__3710:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (channel_3709 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3709)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_bbsplit_index_endsWith__tar_gz__3710(condition=res)


class Res______bbsplit_index__3711(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______bbsplit_index__3711(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    condition_3710: typing.Union[bool, None],
    channel_3590: typing.Union[str, None]
) -> Res______bbsplit_index__3711:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (condition_3710 == True) and (channel_3590 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3590)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______bbsplit_index__3711(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3712_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3711: str


class Res_3712_pre(NamedTuple):
    default: typing.List[Dataclass_3712_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_BBSPLIT_INDEX_3712_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    condition_3710: typing.Union[bool, None],
    channel_3711: typing.Union[str, None]
) -> Res_3712_pre:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (condition_3710 == True) and (channel_3711 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3712_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3711': channel_3711})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3712_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_BBSPLIT_INDEX_3712_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3712_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_BBSPLIT_INDEX_3712_post(
    default: List[Dataclass_3712_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_BBSPLIT_INDEX_3712_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_BBSPLIT_INDEX_3712_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3712_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3712_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3712_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3712_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3711)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_BBSPLIT_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_BBSPLIT_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_BBSPLIT_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_BBSPLIT_INDEX_3712(
    default: Dataclass_3712_pre
) -> Dataclass_3712_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3711)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_BBSPLIT_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_BBSPLIT_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_BBSPLIT_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3712_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3713(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3713(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    condition_3710: typing.Union[bool, None],
    channel_3712_0: typing.Union[str, None]
) -> Resmap_3713:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (condition_3710 == True) and (channel_3712_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3712_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3713(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_bbsplit_index___3715(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_bbsplit_index___3715(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    condition_3710: typing.Union[bool, None]
) -> ResChannel_value_this_file_bbsplit_index___3715:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (condition_3710 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"bbsplit_index"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_bbsplit_index___3715(
        res=out_channels.get("res")
    )


class ResMerge_ch_bbsplit_index_3716(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bbsplit_index_3716(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3713: typing.Union[str, None],
    channel_3715: typing.Union[str, None]
) -> ResMerge_ch_bbsplit_index_3716:
    cond = ((condition_3705 == True) and (condition_3707 == True))

    if cond:
        res = { 'res': channel_3713 or channel_3715 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bbsplit_index_3716(
        res=res.get('res')
    )


class ResChannel_from_this_file_bbsplit_fasta_list___3718(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_from_this_file_bbsplit_fasta_list___3718(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None]
) -> ResChannel_from_this_file_bbsplit_fasta_list___3718:
    cond = ((condition_3705 == True) and (condition_3707 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"from","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"bbsplit_fasta_list"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_from_this_file_bbsplit_fasta_list___3718(
        res=out_channels.get("res")
    )


class RessplitCsv_3719(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def splitCsv_3719(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3718: typing.Union[str, None]
) -> RessplitCsv_3719:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3718 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3718)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"splitCsv","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RessplitCsv_3719(
        res=out_channels.get("res")
    )


class ResflatMap_3720(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def flatMap_3720(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3719: typing.Union[str, None]
) -> ResflatMap_3720:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3719 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3719)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"flatMap","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"ListExpression":[{"ConstantExpression":"id"},{"VariableExpression":"id"}]},{"ListExpression":[{"ConstantExpression":"fasta"},{"StaticMethodCallExpression":{"ownerType":"nextflow.Nextflow","method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"VariableExpression":"fasta"}]}}}}]}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":["file"]},"labels":[]}},"parameters":["id","fasta"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResflatMap_3720(
        res=out_channels.get("res")
    )


class ResgroupTuple_3721(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def groupTuple_3721(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3720: typing.Union[str, None]
) -> ResgroupTuple_3721:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3720 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3720)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"groupTuple","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResgroupTuple_3721(
        res=out_channels.get("res")
    )


class Resmap_3722(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3722(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3721: typing.Union[str, None]
) -> Resmap_3722:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3721 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3721)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["it"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3722(
        res=out_channels.get("res")
    )


class Rescollect_3723(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_3723(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3722: typing.Union[str, None]
) -> Rescollect_3723:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3722 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3722)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_3723(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3724_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3658: str
    channel_3723: str


class Res_3724_pre(NamedTuple):
    default: typing.List[Dataclass_3724_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BBMAP_BBSPLIT_3724_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3658: typing.Union[str, None],
    channel_3723: typing.Union[str, None]
) -> Res_3724_pre:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3658 is not None) and (channel_3723 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3724_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3658': channel_3658, 'channel_3723': channel_3723})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3724_pre(default=result, is_skipped = not cond)

class Respost_adapter_BBMAP_BBSPLIT_3724_post(NamedTuple):
    index: typing.Union[str, None]
    primary_fastq: typing.Union[str, None]
    all_fastq: typing.Union[str, None]
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3724_post:
    index: str
    primary_fastq: str
    all_fastq: str
    stats: str
    versions: str

@task(cache=True)
def post_adapter_BBMAP_BBSPLIT_3724_post(
    default: List[Dataclass_3724_post],
    is_skipped: bool,
) -> Respost_adapter_BBMAP_BBSPLIT_3724_post:
    return get_mapper_outputs(Respost_adapter_BBMAP_BBSPLIT_3724_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3724_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3724_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3724_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3724_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3723)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BBMAP_BBSPLIT","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"MapExpression":[]},{"ListExpression":[]}]},{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":true}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"primary_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BBMAP_BBSPLIT_3724(
    default: Dataclass_3724_pre
) -> Dataclass_3724_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3723)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BBMAP_BBSPLIT","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"MapExpression":[]},{"ListExpression":[]}]},{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":true}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"primary_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3724_post(
        index=out_channels.get(f"index"),
        primary_fastq=out_channels.get(f"primary_fastq"),
        all_fastq=out_channels.get(f"all_fastq"),
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_bbsplit_index_3726(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bbsplit_index_3726(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    channel_3716: typing.Union[str, None],
    channel_3724_0: typing.Union[str, None]
) -> ResMerge_ch_bbsplit_index_3726:
    cond = ((condition_3705 == True))

    if cond:
        res = { 'res': channel_3716 or channel_3724_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bbsplit_index_3726(
        res=res.get('res')
    )


class ResChannel_empty___3702(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3702(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3702:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3702(
        res=out_channels.get("res")
    )


class ResMerge_ch_bbsplit_index_3728(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bbsplit_index_3728(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3726: typing.Union[str, None],
    channel_3702: typing.Union[str, None]
) -> ResMerge_ch_bbsplit_index_3728:
    cond = True

    if cond:
        res = { 'res': channel_3726 or channel_3702 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bbsplit_index_3728(
        res=res.get('res')
    )


@dataclass
class Dataclass_4048_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4039: str
    channel_3728: str


class Res_4048_pre(NamedTuple):
    default: typing.List[Dataclass_4048_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BBMAP_BBSPLIT_4048_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4047: typing.Union[bool, None],
    channel_4039: typing.Union[str, None],
    channel_3728: typing.Union[str, None]
) -> Res_4048_pre:
    cond = ((condition_4047 == True) and (channel_4039 is not None) and (channel_3728 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4048_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4039': channel_4039, 'channel_3728': channel_3728})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4048_pre(default=result, is_skipped = not cond)

class Respost_adapter_BBMAP_BBSPLIT_4048_post(NamedTuple):
    index: typing.Union[str, None]
    primary_fastq: typing.Union[str, None]
    all_fastq: typing.Union[str, None]
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4048_post:
    index: str
    primary_fastq: str
    all_fastq: str
    stats: str
    versions: str

@task(cache=True)
def post_adapter_BBMAP_BBSPLIT_4048_post(
    default: List[Dataclass_4048_post],
    is_skipped: bool,
) -> Respost_adapter_BBMAP_BBSPLIT_4048_post:
    return get_mapper_outputs(Respost_adapter_BBMAP_BBSPLIT_4048_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4048_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4048_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4048_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4048_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4039),json.loads(default.channel_3728)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BBMAP_BBSPLIT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]},{"ListExpression":[{"ListExpression":[]},{"ListExpression":[]}]},{"ConstantExpression":false}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"primary_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BBMAP_BBSPLIT_4048(
    default: Dataclass_4048_pre
) -> Dataclass_4048_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4039),json.loads(default.channel_3728)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BBMAP_BBSPLIT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]},{"ListExpression":[{"ListExpression":[]},{"ListExpression":[]}]},{"ConstantExpression":false}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"primary_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"all_fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BBMAP_BBSPLIT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4048_post(
        index=out_channels.get(f"index"),
        primary_fastq=out_channels.get(f"primary_fastq"),
        all_fastq=out_channels.get(f"all_fastq"),
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_filtered_reads_4051(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_filtered_reads_4051(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4048_1: typing.Union[str, None],
    channel_4039: typing.Union[str, None]
) -> ResMerge_ch_filtered_reads_4051:
    cond = True

    if cond:
        res = { 'res': channel_4048_1 or channel_4039 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_filtered_reads_4051(
        res=res.get('res')
    )


class ResChannel_from_ch_ribo_db_readLines____4056(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_from_ch_ribo_db_readLines____4056(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4055: typing.Union[bool, None]
) -> ResChannel_from_ch_ribo_db_readLines____4056:
    cond = ((condition_4055 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"from","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"ch_ribo_db"},"method":"readLines","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_from_ch_ribo_db_readLines____4056(
        res=out_channels.get("res")
    )


class Resmap_4057(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4057(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4055: typing.Union[bool, None],
    channel_4056: typing.Union[str, None]
) -> Resmap_4057:
    cond = ((condition_4055 == True) and (channel_4056 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4056)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"StaticMethodCallExpression":{"ownerType":"nextflow.Nextflow","method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"checkIfExists"},"valueExpression":{"ConstantExpression":true}}}]},{"VariableExpression":"row"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["file"]},"labels":[]}},"parameters":["row"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4057(
        res=out_channels.get("res")
    )


class Rescollect_4058(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4058(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4055: typing.Union[bool, None],
    channel_4057: typing.Union[str, None]
) -> Rescollect_4058:
    cond = ((condition_4055 == True) and (channel_4057 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4057)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4058(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4059_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4051: str
    channel_4058: str


class Res_4059_pre(NamedTuple):
    default: typing.List[Dataclass_4059_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SORTMERNA_4059_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4055: typing.Union[bool, None],
    channel_4051: typing.Union[str, None],
    channel_4058: typing.Union[str, None]
) -> Res_4059_pre:
    cond = ((condition_4055 == True) and (channel_4051 is not None) and (channel_4058 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4059_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4051': channel_4051, 'channel_4058': channel_4058})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4059_pre(default=result, is_skipped = not cond)

class Respost_adapter_SORTMERNA_4059_post(NamedTuple):
    reads: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4059_post:
    reads: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_SORTMERNA_4059_post(
    default: List[Dataclass_4059_post],
    is_skipped: bool,
) -> Respost_adapter_SORTMERNA_4059_post:
    return get_mapper_outputs(Respost_adapter_SORTMERNA_4059_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4059_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4059_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4059_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4059_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4051),json.loads(default.channel_4058)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SORTMERNA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SORTMERNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SORTMERNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SORTMERNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SORTMERNA_4059(
    default: Dataclass_4059_pre
) -> Dataclass_4059_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4051),json.loads(default.channel_4058)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SORTMERNA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"reads\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SORTMERNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SORTMERNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SORTMERNA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4059_post(
        reads=out_channels.get(f"reads"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_filtered_reads_4062(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_filtered_reads_4062(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4059_0: typing.Union[str, None],
    channel_4051: typing.Union[str, None]
) -> ResMerge_ch_filtered_reads_4062:
    cond = True

    if cond:
        res = { 'res': channel_4059_0 or channel_4051 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_filtered_reads_4062(
        res=res.get('res')
    )


class Resbranch_4065(NamedTuple):
    auto_strand: typing.Union[str, None]
    known_strand: typing.Union[str, None]

@task(cache=True)
def branch_4065(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4062: typing.Union[str, None]
) -> Resbranch_4065:
    cond = ((channel_4062 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4062)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"branch","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"strandedness"}},{"ConstantExpression":"auto"}]}}}},"labels":["auto_strand"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"fastq"}]},{"ConstantExpression":"auto_strand"}]}}}}},{"ExpressionStatement":{"expression":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"strandedness"}},{"ConstantExpression":"auto"}]}}}}},"labels":["known_strand"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"fastq"}]},{"ConstantExpression":"known_strand"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","fastq"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"auto_strand\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"auto_strand\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"known_strand\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"known_strand\\"}}}},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'auto_strand': None, 'known_strand': None}

    return Resbranch_4065(
        auto_strand=out_channels.get("auto_strand"),
        known_strand=out_channels.get("known_strand")
    )


@dataclass
class Dataclass_4080_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4065_0: str


class Res_4080_pre(NamedTuple):
    default: typing.List[Dataclass_4080_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_FQ_SUBSAMPLE_4080_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4065_0: typing.Union[str, None]
) -> Res_4080_pre:
    cond = ((channel_4065_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4080_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4065_0': channel_4065_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4080_pre(default=result, is_skipped = not cond)

class Respost_adapter_FQ_SUBSAMPLE_4080_post(NamedTuple):
    fastq: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4080_post:
    fastq: str
    versions: str

@task(cache=True)
def post_adapter_FQ_SUBSAMPLE_4080_post(
    default: List[Dataclass_4080_post],
    is_skipped: bool,
) -> Respost_adapter_FQ_SUBSAMPLE_4080_post:
    return get_mapper_outputs(Respost_adapter_FQ_SUBSAMPLE_4080_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4080_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4080_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4080_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4080_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4065_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_SUBSAMPLE_FQ_SALMON'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FQ_SUBSAMPLE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FQ_SUBSAMPLE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FQ_SUBSAMPLE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def FQ_SUBSAMPLE_4080(
    default: Dataclass_4080_pre
) -> Dataclass_4080_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4065_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_SUBSAMPLE_FQ_SALMON'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"FQ_SUBSAMPLE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FQ_SUBSAMPLE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"FQ_SUBSAMPLE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4080_post(
        fastq=out_channels.get(f"fastq"),
        versions=out_channels.get(f"versions")
    )


class Resparams_salmon_index_4069(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_salmon_index_4069(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_salmon_index_4069:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"salmon_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_salmon_index_4069(
        res=out_channels.get("res")
    )


class Res_salmon_in_prepareToolIndices__4070(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _salmon_in_prepareToolIndices__4070(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_salmon_in_prepareToolIndices__4070:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"ConstantExpression":"salmon"},"operation":"in","rightExpression":{"VariableExpression":"prepareToolIndices"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_salmon_in_prepareToolIndices__4070(
        res=out_channels.get("res")
    )


class Res_salmon_in_prepareToolIndices__4071(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _salmon_in_prepareToolIndices__4071(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4070: typing.Union[str, None]
) -> Res_salmon_in_prepareToolIndices__4071:
    cond = ((channel_4070 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4070)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_salmon_in_prepareToolIndices__4071(
        res=out_channels.get("res")
    )


class Res_params_salmon_index_____salmon_in_prepareToolIndices___4072(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_salmon_index_____salmon_in_prepareToolIndices___4072(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4069: typing.Union[str, None],
    channel_4071: typing.Union[str, None]
) -> Res_params_salmon_index_____salmon_in_prepareToolIndices___4072:
    cond = ((channel_4069 is not None) and (channel_4071 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4069), json.loads(channel_4071)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_salmon_index_____salmon_in_prepareToolIndices___4072(
        res=out_channels.get("res")
    )


class Resmake_index_4074(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def make_index_4074(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4072: typing.Union[str, None]
) -> Resmake_index_4074:
    cond = ((channel_4072 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4072)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmake_index_4074(
        res=out_channels.get("res")
    )


class Resconditional_make_index_4075(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_make_index_4075(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4074: typing.Union[str, None]
) -> Resconditional_make_index_4075:
    cond = ((channel_4074 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4074)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_make_index_4075(condition=res)


class Rescombine_4066(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_4066(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3658: typing.Union[str, None],
    channel_4065_0: typing.Union[str, None]
) -> Rescombine_4066:
    cond = ((channel_3658 is not None) and (channel_4065_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658), json.loads(channel_4065_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescombine_4066(
        res=out_channels.get("res")
    )


class Resmap_4067(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4067(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4066: typing.Union[str, None]
) -> Resmap_4067:
    cond = ((channel_4066 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4066)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"it"},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4067(
        res=out_channels.get("res")
    )


class Resfirst_4068(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4068(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4067: typing.Union[str, None]
) -> Resfirst_4068:
    cond = ((channel_4067 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4067)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4068(
        res=out_channels.get("res")
    )


class Resparams_transcript_fasta_3581(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_transcript_fasta_3581(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_transcript_fasta_3581:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"transcript_fasta"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_transcript_fasta_3581(
        res=out_channels.get("res")
    )


class Restranscript_fasta_3675(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def transcript_fasta_3675(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3581: typing.Union[str, None]
) -> Restranscript_fasta_3675:
    cond = ((channel_3581 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3581)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Restranscript_fasta_3675(
        res=out_channels.get("res")
    )


class Resconditional_transcript_fasta_3676(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_transcript_fasta_3676(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3675: typing.Union[str, None]
) -> Resconditional_transcript_fasta_3676:
    cond = ((channel_3675 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3675)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_transcript_fasta_3676(condition=res)


class Resparams_gencode_3591(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_gencode_3591(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_gencode_3591:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"gencode"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_gencode_3591(
        res=out_channels.get("res")
    )


class Resgencode_3687(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gencode_3687(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3591: typing.Union[str, None]
) -> Resgencode_3687:
    cond = ((condition_3676 == True) and (channel_3591 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3591)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgencode_3687(
        res=out_channels.get("res")
    )


class Resconditional_gencode_3688(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gencode_3688(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3687: typing.Union[str, None]
) -> Resconditional_gencode_3688:
    cond = ((condition_3676 == True) and (channel_3687 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3687)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gencode_3688(condition=res)


class Restranscript_fasta_endsWith__gz__3677(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def transcript_fasta_endsWith__gz__3677(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3581: typing.Union[str, None]
) -> Restranscript_fasta_endsWith__gz__3677:
    cond = ((condition_3676 == True) and (channel_3581 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3581)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"transcript_fasta"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Restranscript_fasta_endsWith__gz__3677(
        res=out_channels.get("res")
    )


class Restranscript_fasta_endsWith__gz__3678(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def transcript_fasta_endsWith__gz__3678(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3677: typing.Union[str, None]
) -> Restranscript_fasta_endsWith__gz__3678:
    cond = ((condition_3676 == True) and (channel_3677 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3677)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Restranscript_fasta_endsWith__gz__3678(
        res=out_channels.get("res")
    )


class Resconditional_transcript_fasta_endsWith__gz__3679(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_transcript_fasta_endsWith__gz__3679(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3678: typing.Union[str, None]
) -> Resconditional_transcript_fasta_endsWith__gz__3679:
    cond = ((condition_3676 == True) and (channel_3678 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3678)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_transcript_fasta_endsWith__gz__3679(condition=res)


class Res______transcript_fasta__3680(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______transcript_fasta__3680(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3679: typing.Union[bool, None],
    channel_3581: typing.Union[str, None]
) -> Res______transcript_fasta__3680:
    cond = ((condition_3676 == True) and (condition_3679 == True) and (channel_3581 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3581)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______transcript_fasta__3680(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3681_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3680: str


class Res_3681_pre(NamedTuple):
    default: typing.List[Dataclass_3681_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GUNZIP_TRANSCRIPT_FASTA_3681_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3679: typing.Union[bool, None],
    channel_3680: typing.Union[str, None]
) -> Res_3681_pre:
    cond = ((condition_3676 == True) and (condition_3679 == True) and (channel_3680 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3681_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3680': channel_3680})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3681_pre(default=result, is_skipped = not cond)

class Respost_adapter_GUNZIP_TRANSCRIPT_FASTA_3681_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3681_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_TRANSCRIPT_FASTA_3681_post(
    default: List[Dataclass_3681_post],
    is_skipped: bool,
) -> Respost_adapter_GUNZIP_TRANSCRIPT_FASTA_3681_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_TRANSCRIPT_FASTA_3681_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3681_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3681_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3681_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3681_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3680)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_TRANSCRIPT_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_TRANSCRIPT_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_TRANSCRIPT_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GUNZIP_TRANSCRIPT_FASTA_3681(
    default: Dataclass_3681_pre
) -> Dataclass_3681_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3680)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_TRANSCRIPT_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_TRANSCRIPT_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_TRANSCRIPT_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3681_post(
        gunzip=out_channels.get(f"gunzip"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3682(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3682(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3679: typing.Union[bool, None],
    channel_3681_0: typing.Union[str, None]
) -> Resmap_3682:
    cond = ((condition_3676 == True) and (condition_3679 == True) and (channel_3681_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3681_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3682(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_transcript_fasta___3684(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_transcript_fasta___3684(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3679: typing.Union[bool, None]
) -> ResChannel_value_this_file_transcript_fasta___3684:
    cond = ((condition_3676 == True) and (condition_3679 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"transcript_fasta"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_transcript_fasta___3684(
        res=out_channels.get("res")
    )


class ResMerge_ch_transcript_fasta_3685(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_transcript_fasta_3685(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3682: typing.Union[str, None],
    channel_3684: typing.Union[str, None]
) -> ResMerge_ch_transcript_fasta_3685:
    cond = ((condition_3676 == True))

    if cond:
        res = { 'res': channel_3682 or channel_3684 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_transcript_fasta_3685(
        res=res.get('res')
    )


@dataclass
class Dataclass_3689_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3685: str


class Res_3689_pre(NamedTuple):
    default: typing.List[Dataclass_3689_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_PREPROCESS_TRANSCRIPTS_FASTA_GENCODE_3689_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3688: typing.Union[bool, None],
    channel_3685: typing.Union[str, None]
) -> Res_3689_pre:
    cond = ((condition_3676 == True) and (condition_3688 == True) and (channel_3685 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3689_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3685': channel_3685})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3689_pre(default=result, is_skipped = not cond)

class Respost_adapter_PREPROCESS_TRANSCRIPTS_FASTA_GENCODE_3689_post(NamedTuple):
    fasta: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3689_post:
    fasta: str
    versions: str

@task(cache=True)
def post_adapter_PREPROCESS_TRANSCRIPTS_FASTA_GENCODE_3689_post(
    default: List[Dataclass_3689_post],
    is_skipped: bool,
) -> Respost_adapter_PREPROCESS_TRANSCRIPTS_FASTA_GENCODE_3689_post:
    return get_mapper_outputs(Respost_adapter_PREPROCESS_TRANSCRIPTS_FASTA_GENCODE_3689_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3689_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3689_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3689_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3689_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3685)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PREPROCESS_TRANSCRIPTS_FASTA_GENCODE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PREPROCESS_TRANSCRIPTS_FASTA_GENCODE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PREPROCESS_TRANSCRIPTS_FASTA_GENCODE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def PREPROCESS_TRANSCRIPTS_FASTA_GENCODE_3689(
    default: Dataclass_3689_pre
) -> Dataclass_3689_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3685)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PREPROCESS_TRANSCRIPTS_FASTA_GENCODE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PREPROCESS_TRANSCRIPTS_FASTA_GENCODE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PREPROCESS_TRANSCRIPTS_FASTA_GENCODE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3689_post(
        fasta=out_channels.get(f"fasta"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_transcript_fasta_3691(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_transcript_fasta_3691(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3689_0: typing.Union[str, None],
    channel_3685: typing.Union[str, None]
) -> ResMerge_ch_transcript_fasta_3691:
    cond = ((condition_3676 == True))

    if cond:
        res = { 'res': channel_3689_0 or channel_3685 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_transcript_fasta_3691(
        res=res.get('res')
    )


class ResMerge_ch_gtf_3656(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gtf_3656(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3654_1: typing.Union[str, None],
    channel_3639: typing.Union[str, None]
) -> ResMerge_ch_gtf_3656:
    cond = True

    if cond:
        res = { 'res': channel_3654_1 or channel_3639 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gtf_3656(
        res=res.get('res')
    )


@dataclass
class Dataclass_3693_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3658: str
    channel_3656: str


class Res_3693_pre(NamedTuple):
    default: typing.List[Dataclass_3693_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_MAKE_TRANSCRIPTS_FASTA_3693_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3658: typing.Union[str, None],
    channel_3656: typing.Union[str, None]
) -> Res_3693_pre:
    cond = ((condition_3676 == False) and (channel_3658 is not None) and (channel_3656 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3693_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3658': channel_3658, 'channel_3656': channel_3656})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3693_pre(default=result, is_skipped = not cond)

class Respost_adapter_MAKE_TRANSCRIPTS_FASTA_3693_post(NamedTuple):
    index: typing.Union[str, None]
    transcript_fasta: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3693_post:
    index: str
    transcript_fasta: str
    versions: str

@task(cache=True)
def post_adapter_MAKE_TRANSCRIPTS_FASTA_3693_post(
    default: List[Dataclass_3693_post],
    is_skipped: bool,
) -> Respost_adapter_MAKE_TRANSCRIPTS_FASTA_3693_post:
    return get_mapper_outputs(Respost_adapter_MAKE_TRANSCRIPTS_FASTA_3693_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3693_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3693_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3693_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3693_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3656)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MAKE_TRANSCRIPTS_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MAKE_TRANSCRIPTS_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"transcript_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MAKE_TRANSCRIPTS_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MAKE_TRANSCRIPTS_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def MAKE_TRANSCRIPTS_FASTA_3693(
    default: Dataclass_3693_pre
) -> Dataclass_3693_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3656)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MAKE_TRANSCRIPTS_FASTA","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MAKE_TRANSCRIPTS_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"transcript_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MAKE_TRANSCRIPTS_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MAKE_TRANSCRIPTS_FASTA\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3693_post(
        index=out_channels.get(f"index"),
        transcript_fasta=out_channels.get(f"transcript_fasta"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_transcript_fasta_3695(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_transcript_fasta_3695(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3691: typing.Union[str, None],
    channel_3693_1: typing.Union[str, None]
) -> ResMerge_ch_transcript_fasta_3695:
    cond = True

    if cond:
        res = { 'res': channel_3691 or channel_3693_1 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_transcript_fasta_3695(
        res=res.get('res')
    )


@dataclass
class Dataclass_4076_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4068: str
    channel_3695: str


class Res_4076_pre(NamedTuple):
    default: typing.List[Dataclass_4076_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SALMON_INDEX_4076_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4075: typing.Union[bool, None],
    channel_4068: typing.Union[str, None],
    channel_3695: typing.Union[str, None]
) -> Res_4076_pre:
    cond = ((condition_4075 == True) and (channel_4068 is not None) and (channel_3695 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4076_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4068': channel_4068, 'channel_3695': channel_3695})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4076_pre(default=result, is_skipped = not cond)

class Respost_adapter_SALMON_INDEX_4076_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4076_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_SALMON_INDEX_4076_post(
    default: List[Dataclass_4076_post],
    is_skipped: bool,
) -> Respost_adapter_SALMON_INDEX_4076_post:
    return get_mapper_outputs(Respost_adapter_SALMON_INDEX_4076_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4076_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4076_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4076_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4076_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4068),json.loads(default.channel_3695)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_SUBSAMPLE_FQ_SALMON'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SALMON_INDEX_4076(
    default: Dataclass_4076_pre
) -> Dataclass_4076_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4068),json.loads(default.channel_3695)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_SUBSAMPLE_FQ_SALMON'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4076_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class Resparams_salmon_index_3587(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_salmon_index_3587(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_salmon_index_3587:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"salmon_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_salmon_index_3587(
        res=out_channels.get("res")
    )


class Ressalmon_index_3822(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def salmon_index_3822(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3587: typing.Union[str, None]
) -> Ressalmon_index_3822:
    cond = ((channel_3587 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3587)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Ressalmon_index_3822(
        res=out_channels.get("res")
    )


class Resconditional_salmon_index_3823(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_salmon_index_3823(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3822: typing.Union[str, None]
) -> Resconditional_salmon_index_3823:
    cond = ((channel_3822 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3822)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_salmon_index_3823(condition=res)


class Ressalmon_index_endsWith__tar_gz__3824(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def salmon_index_endsWith__tar_gz__3824(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3587: typing.Union[str, None]
) -> Ressalmon_index_endsWith__tar_gz__3824:
    cond = ((condition_3823 == True) and (channel_3587 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3587)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"salmon_index"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Ressalmon_index_endsWith__tar_gz__3824(
        res=out_channels.get("res")
    )


class Ressalmon_index_endsWith__tar_gz__3825(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def salmon_index_endsWith__tar_gz__3825(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3824: typing.Union[str, None]
) -> Ressalmon_index_endsWith__tar_gz__3825:
    cond = ((condition_3823 == True) and (channel_3824 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3824)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Ressalmon_index_endsWith__tar_gz__3825(
        res=out_channels.get("res")
    )


class Resconditional_salmon_index_endsWith__tar_gz__3826(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_salmon_index_endsWith__tar_gz__3826(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3825: typing.Union[str, None]
) -> Resconditional_salmon_index_endsWith__tar_gz__3826:
    cond = ((condition_3823 == True) and (channel_3825 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3825)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_salmon_index_endsWith__tar_gz__3826(condition=res)


class Res______salmon_index__3827(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______salmon_index__3827(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3826: typing.Union[bool, None],
    channel_3587: typing.Union[str, None]
) -> Res______salmon_index__3827:
    cond = ((condition_3823 == True) and (condition_3826 == True) and (channel_3587 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3587)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______salmon_index__3827(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3828_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3827: str


class Res_3828_pre(NamedTuple):
    default: typing.List[Dataclass_3828_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_SALMON_INDEX_3828_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3826: typing.Union[bool, None],
    channel_3827: typing.Union[str, None]
) -> Res_3828_pre:
    cond = ((condition_3823 == True) and (condition_3826 == True) and (channel_3827 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3828_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3827': channel_3827})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3828_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_SALMON_INDEX_3828_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3828_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_SALMON_INDEX_3828_post(
    default: List[Dataclass_3828_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_SALMON_INDEX_3828_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_SALMON_INDEX_3828_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3828_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3828_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3828_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3828_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3827)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_SALMON_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_SALMON_INDEX_3828(
    default: Dataclass_3828_pre
) -> Dataclass_3828_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3827)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_SALMON_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3828_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3829(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3829(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3826: typing.Union[bool, None],
    channel_3828_0: typing.Union[str, None]
) -> Resmap_3829:
    cond = ((condition_3823 == True) and (condition_3826 == True) and (channel_3828_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3828_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3829(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_salmon_index___3831(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_salmon_index___3831(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3826: typing.Union[bool, None]
) -> ResChannel_value_this_file_salmon_index___3831:
    cond = ((condition_3823 == True) and (condition_3826 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"salmon_index"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_salmon_index___3831(
        res=out_channels.get("res")
    )


class ResMerge_ch_salmon_index_3832(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_salmon_index_3832(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3829: typing.Union[str, None],
    channel_3831: typing.Union[str, None]
) -> ResMerge_ch_salmon_index_3832:
    cond = ((condition_3823 == True))

    if cond:
        res = { 'res': channel_3829 or channel_3831 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_salmon_index_3832(
        res=res.get('res')
    )


class Res_salmon_in_prepare_tool_indices__3834(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _salmon_in_prepare_tool_indices__3834(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None]
) -> Res_salmon_in_prepare_tool_indices__3834:
    cond = ((condition_3823 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"salmon"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_salmon_in_prepare_tool_indices__3834(
        res=out_channels.get("res")
    )


class Res_salmon_in_prepare_tool_indices__3835(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _salmon_in_prepare_tool_indices__3835(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3834: typing.Union[str, None]
) -> Res_salmon_in_prepare_tool_indices__3835:
    cond = ((condition_3823 == False) and (channel_3834 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3834)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_salmon_in_prepare_tool_indices__3835(
        res=out_channels.get("res")
    )


class Resconditional__salmon_in_prepare_tool_indices__3836(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__salmon_in_prepare_tool_indices__3836(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3835: typing.Union[str, None]
) -> Resconditional__salmon_in_prepare_tool_indices__3836:
    cond = ((condition_3823 == False) and (channel_3835 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3835)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__salmon_in_prepare_tool_indices__3836(condition=res)


@dataclass
class Dataclass_3837_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3658: str
    channel_3695: str


class Res_3837_pre(NamedTuple):
    default: typing.List[Dataclass_3837_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SALMON_INDEX_3837_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3836: typing.Union[bool, None],
    channel_3658: typing.Union[str, None],
    channel_3695: typing.Union[str, None]
) -> Res_3837_pre:
    cond = ((condition_3823 == False) and (condition_3836 == True) and (channel_3658 is not None) and (channel_3695 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3837_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3658': channel_3658, 'channel_3695': channel_3695})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3837_pre(default=result, is_skipped = not cond)

class Respost_adapter_SALMON_INDEX_3837_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3837_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_SALMON_INDEX_3837_post(
    default: List[Dataclass_3837_post],
    is_skipped: bool,
) -> Respost_adapter_SALMON_INDEX_3837_post:
    return get_mapper_outputs(Respost_adapter_SALMON_INDEX_3837_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3837_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3837_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3837_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3837_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3695)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SALMON_INDEX_3837(
    default: Dataclass_3837_pre
) -> Dataclass_3837_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3695)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3837_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3821(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3821(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3821:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3821(
        res=out_channels.get("res")
    )


class ResMerge_ch_salmon_index_3839(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_salmon_index_3839(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3837_0: typing.Union[str, None],
    channel_3821: typing.Union[str, None]
) -> ResMerge_ch_salmon_index_3839:
    cond = ((condition_3823 == False))

    if cond:
        res = { 'res': channel_3837_0 or channel_3821 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_salmon_index_3839(
        res=res.get('res')
    )


class ResMerge_ch_salmon_index_3841(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_salmon_index_3841(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3832: typing.Union[str, None],
    channel_3839: typing.Union[str, None]
) -> ResMerge_ch_salmon_index_3841:
    cond = True

    if cond:
        res = { 'res': channel_3832 or channel_3839 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_salmon_index_3841(
        res=res.get('res')
    )


class ResMerge_ch_index_4078(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_index_4078(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4076_0: typing.Union[str, None],
    channel_3841: typing.Union[str, None]
) -> ResMerge_ch_index_4078:
    cond = True

    if cond:
        res = { 'res': channel_4076_0 or channel_3841 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_index_4078(
        res=res.get('res')
    )


class Resfalse_4084(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def false_4084(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resfalse_4084:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":false}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfalse_4084(
        res=out_channels.get("res")
    )


class ResA_4083(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def A_4083(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResA_4083:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"A"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResA_4083(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4085_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4080_0: str
    channel_4078: str
    channel_3656: str
    channel_3695: str
    channel_4084: str
    channel_4083: str


class Res_4085_pre(NamedTuple):
    default: typing.List[Dataclass_4085_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SALMON_QUANT_4085_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4080_0: typing.Union[str, None],
    channel_4078: typing.Union[str, None],
    channel_3656: typing.Union[str, None],
    channel_3695: typing.Union[str, None],
    channel_4084: typing.Union[str, None],
    channel_4083: typing.Union[str, None]
) -> Res_4085_pre:
    cond = ((channel_4080_0 is not None) and (channel_4078 is not None) and (channel_3656 is not None) and (channel_3695 is not None) and (channel_4084 is not None) and (channel_4083 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4085_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4080_0': channel_4080_0, 'channel_4078': channel_4078, 'channel_3656': channel_3656, 'channel_3695': channel_3695, 'channel_4084': channel_4084, 'channel_4083': channel_4083})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4085_pre(default=result, is_skipped = not cond)

class Respost_adapter_SALMON_QUANT_4085_post(NamedTuple):
    results: typing.Union[str, None]
    json_info: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4085_post:
    results: str
    json_info: str
    versions: str

@task(cache=True)
def post_adapter_SALMON_QUANT_4085_post(
    default: List[Dataclass_4085_post],
    is_skipped: bool,
) -> Respost_adapter_SALMON_QUANT_4085_post:
    return get_mapper_outputs(Respost_adapter_SALMON_QUANT_4085_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4085_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4085_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4085_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4085_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4080_0),json.loads(default.channel_4078),json.loads(default.channel_3656),json.loads(default.channel_3695),json.loads(default.channel_4084),json.loads(default.channel_4083)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_SUBSAMPLE_FQ_SALMON'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SALMON_QUANT_4085(
    default: Dataclass_4085_pre
) -> Dataclass_4085_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4080_0),json.loads(default.channel_4078),json.loads(default.channel_3656),json.loads(default.channel_3695),json.loads(default.channel_4084),json.loads(default.channel_4083)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_SUBSAMPLE_FQ_SALMON'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4085_post(
        results=out_channels.get(f"results"),
        json_info=out_channels.get(f"json_info"),
        versions=out_channels.get(f"versions")
    )


class Resjoin_4089(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4089(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4085_1: typing.Union[str, None],
    channel_4065_0: typing.Union[str, None]
) -> Resjoin_4089:
    cond = ((channel_4085_1 is not None) and (channel_4065_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4085_1), json.loads(channel_4065_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4089(
        res=out_channels.get("res")
    )


class Resmap_4090(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4090(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4089: typing.Union[str, None]
) -> Resmap_4090:
    cond = ((channel_4089 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4089)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"meta"},"operation":"+","rightExpression":{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"strandedness"},"valueExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"getSalmonInferredStrandedness","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"json"}]}}}}}}]}}},{"VariableExpression":"reads"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","json","reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4090(
        res=out_channels.get("res")
    )


class Resmix_4091(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4091(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4090: typing.Union[str, None],
    channel_4065_1: typing.Union[str, None]
) -> Resmix_4091:
    cond = ((channel_4090 is not None) and (channel_4065_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4090), json.loads(channel_4065_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4091(
        res=out_channels.get("res")
    )


class Res_star_salmon_in_prepare_tool_indices__3731(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _star_salmon_in_prepare_tool_indices__3731(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_star_salmon_in_prepare_tool_indices__3731:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"star_salmon"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_star_salmon_in_prepare_tool_indices__3731(
        res=out_channels.get("res")
    )


class Res_star_salmon_in_prepare_tool_indices__3732(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _star_salmon_in_prepare_tool_indices__3732(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3731: typing.Union[str, None]
) -> Res_star_salmon_in_prepare_tool_indices__3732:
    cond = ((channel_3731 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3731)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_star_salmon_in_prepare_tool_indices__3732(
        res=out_channels.get("res")
    )


class Resconditional__star_salmon_in_prepare_tool_indices__3733(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__star_salmon_in_prepare_tool_indices__3733(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3732: typing.Union[str, None]
) -> Resconditional__star_salmon_in_prepare_tool_indices__3733:
    cond = ((channel_3732 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3732)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__star_salmon_in_prepare_tool_indices__3733(condition=res)


class Resparams_star_index_3585(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_star_index_3585(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_star_index_3585:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"star_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_star_index_3585(
        res=out_channels.get("res")
    )


class Resstar_index_3734(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def star_index_3734(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    channel_3585: typing.Union[str, None]
) -> Resstar_index_3734:
    cond = ((condition_3733 == True) and (channel_3585 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3585)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resstar_index_3734(
        res=out_channels.get("res")
    )


class Resconditional_star_index_3735(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_star_index_3735(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    channel_3734: typing.Union[str, None]
) -> Resconditional_star_index_3735:
    cond = ((condition_3733 == True) and (channel_3734 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3734)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_star_index_3735(condition=res)


class Resstar_index_endsWith__tar_gz__3736(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def star_index_endsWith__tar_gz__3736(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3585: typing.Union[str, None]
) -> Resstar_index_endsWith__tar_gz__3736:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (channel_3585 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3585)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"star_index"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resstar_index_endsWith__tar_gz__3736(
        res=out_channels.get("res")
    )


class Resstar_index_endsWith__tar_gz__3737(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def star_index_endsWith__tar_gz__3737(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3736: typing.Union[str, None]
) -> Resstar_index_endsWith__tar_gz__3737:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (channel_3736 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3736)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resstar_index_endsWith__tar_gz__3737(
        res=out_channels.get("res")
    )


class Resconditional_star_index_endsWith__tar_gz__3738(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_star_index_endsWith__tar_gz__3738(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3737: typing.Union[str, None]
) -> Resconditional_star_index_endsWith__tar_gz__3738:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (channel_3737 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3737)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_star_index_endsWith__tar_gz__3738(condition=res)


class Res______star_index__3739(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______star_index__3739(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3738: typing.Union[bool, None],
    channel_3585: typing.Union[str, None]
) -> Res______star_index__3739:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (condition_3738 == True) and (channel_3585 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3585)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______star_index__3739(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3740_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3739: str


class Res_3740_pre(NamedTuple):
    default: typing.List[Dataclass_3740_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_STAR_INDEX_3740_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3738: typing.Union[bool, None],
    channel_3739: typing.Union[str, None]
) -> Res_3740_pre:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (condition_3738 == True) and (channel_3739 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3740_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3739': channel_3739})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3740_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_STAR_INDEX_3740_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3740_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_STAR_INDEX_3740_post(
    default: List[Dataclass_3740_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_STAR_INDEX_3740_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_STAR_INDEX_3740_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3740_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3740_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3740_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3740_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3739)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_STAR_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_STAR_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_STAR_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_STAR_INDEX_3740(
    default: Dataclass_3740_pre
) -> Dataclass_3740_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3739)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_STAR_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_STAR_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_STAR_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3740_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3741(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3741(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3738: typing.Union[bool, None],
    channel_3740_0: typing.Union[str, None]
) -> Resmap_3741:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (condition_3738 == True) and (channel_3740_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3740_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3741(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_star_index___3743(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_star_index___3743(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3738: typing.Union[bool, None]
) -> ResChannel_value_this_file_star_index___3743:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (condition_3738 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"star_index"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_star_index___3743(
        res=out_channels.get("res")
    )


class ResMerge_ch_star_index_3744(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_star_index_3744(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3741: typing.Union[str, None],
    channel_3743: typing.Union[str, None]
) -> ResMerge_ch_star_index_3744:
    cond = ((condition_3733 == True) and (condition_3735 == True))

    if cond:
        res = { 'res': channel_3741 or channel_3743 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_star_index_3744(
        res=res.get('res')
    )


class Res_params_gencode____gene_type___params_featurecounts_group_type_3576(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_gencode____gene_type___params_featurecounts_group_type_3576(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_params_gencode____gene_type___params_featurecounts_group_type_3576:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"gencode"}}},"trueExpression":{"ConstantExpression":"gene_type"},"falseExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"featurecounts_group_type"}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_gencode____gene_type___params_featurecounts_group_type_3576(
        res=out_channels.get("res")
    )


class Resis_aws_igenome_3746(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def is_aws_igenome_3746(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3576: typing.Union[str, None]
) -> Resis_aws_igenome_3746:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (channel_3576 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3576)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resis_aws_igenome_3746(
        res=out_channels.get("res")
    )


class Resconditional_is_aws_igenome_3747(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_is_aws_igenome_3747(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3746: typing.Union[str, None]
) -> Resconditional_is_aws_igenome_3747:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (channel_3746 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3746)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_is_aws_igenome_3747(condition=res)


@dataclass
class Dataclass_3748_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3658: str
    channel_3656: str


class Res_3748_pre(NamedTuple):
    default: typing.List[Dataclass_3748_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_STAR_GENOMEGENERATE_IGENOMES_3748_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3658: typing.Union[str, None],
    channel_3656: typing.Union[str, None]
) -> Res_3748_pre:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == True) and (channel_3658 is not None) and (channel_3656 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3748_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3658': channel_3658, 'channel_3656': channel_3656})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3748_pre(default=result, is_skipped = not cond)

class Respost_adapter_STAR_GENOMEGENERATE_IGENOMES_3748_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3748_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_STAR_GENOMEGENERATE_IGENOMES_3748_post(
    default: List[Dataclass_3748_post],
    is_skipped: bool,
) -> Respost_adapter_STAR_GENOMEGENERATE_IGENOMES_3748_post:
    return get_mapper_outputs(Respost_adapter_STAR_GENOMEGENERATE_IGENOMES_3748_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3748_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3748_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3748_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3748_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3656)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_GENOMEGENERATE_IGENOMES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def STAR_GENOMEGENERATE_IGENOMES_3748(
    default: Dataclass_3748_pre
) -> Dataclass_3748_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3656)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_GENOMEGENERATE_IGENOMES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3748_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3750(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3750(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_3750:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == False) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3750(
        res=out_channels.get("res")
    )


class Resmap_3751(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3751(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Resmap_3751:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == False) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3751(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3752_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3750: str
    channel_3751: str


class Res_3752_pre(NamedTuple):
    default: typing.List[Dataclass_3752_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_STAR_GENOMEGENERATE_3752_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3750: typing.Union[str, None],
    channel_3751: typing.Union[str, None]
) -> Res_3752_pre:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == False) and (channel_3750 is not None) and (channel_3751 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3752_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3750': channel_3750, 'channel_3751': channel_3751})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3752_pre(default=result, is_skipped = not cond)

class Respost_adapter_STAR_GENOMEGENERATE_3752_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3752_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_STAR_GENOMEGENERATE_3752_post(
    default: List[Dataclass_3752_post],
    is_skipped: bool,
) -> Respost_adapter_STAR_GENOMEGENERATE_3752_post:
    return get_mapper_outputs(Respost_adapter_STAR_GENOMEGENERATE_3752_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3752_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3752_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3752_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3752_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3750),json.loads(default.channel_3751)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_GENOMEGENERATE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def STAR_GENOMEGENERATE_3752(
    default: Dataclass_3752_pre
) -> Dataclass_3752_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3750),json.loads(default.channel_3751)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_GENOMEGENERATE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_GENOMEGENERATE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3752_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3753(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3753(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3752_0: typing.Union[str, None]
) -> Resmap_3753:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == False) and (channel_3752_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3752_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3753(
        res=out_channels.get("res")
    )


class ResMerge_ch_star_index_3755(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_star_index_3755(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3748_0: typing.Union[str, None],
    channel_3753: typing.Union[str, None]
) -> ResMerge_ch_star_index_3755:
    cond = ((condition_3733 == True) and (condition_3735 == False))

    if cond:
        res = { 'res': channel_3748_0 or channel_3753 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_star_index_3755(
        res=res.get('res')
    )


class ResMerge_ch_star_index_3757(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_star_index_3757(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    channel_3744: typing.Union[str, None],
    channel_3755: typing.Union[str, None]
) -> ResMerge_ch_star_index_3757:
    cond = ((condition_3733 == True))

    if cond:
        res = { 'res': channel_3744 or channel_3755 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_star_index_3757(
        res=res.get('res')
    )


class ResChannel_empty___3730(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3730(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3730:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3730(
        res=out_channels.get("res")
    )


class ResMerge_ch_star_index_3759(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_star_index_3759(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3757: typing.Union[str, None],
    channel_3730: typing.Union[str, None]
) -> ResMerge_ch_star_index_3759:
    cond = True

    if cond:
        res = { 'res': channel_3757 or channel_3730 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_star_index_3759(
        res=res.get('res')
    )


class Resmap_4105(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4105(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_3759: typing.Union[str, None]
) -> Resmap_4105:
    cond = ((condition_4104 == True) and (channel_3759 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3759)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4105(
        res=out_channels.get("res")
    )


class Resmap_4106(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4106(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Resmap_4106:
    cond = ((condition_4104 == True) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4106(
        res=out_channels.get("res")
    )


class Resparams_star_ignore_sjdbgtf_4107(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_star_ignore_sjdbgtf_4107(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_star_ignore_sjdbgtf_4107:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"star_ignore_sjdbgtf"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_star_ignore_sjdbgtf_4107(
        res=out_channels.get("res")
    )


class Res___4108(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___4108(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Res___4108:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":""}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res___4108(
        res=out_channels.get("res")
    )


class Res_params_seq_center____params_seq_center____4109(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_seq_center____params_seq_center____4109(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Res_params_seq_center____params_seq_center____4109:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"seq_center"}}},"trueExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"seq_center"}},"falseExpression":{"ConstantExpression":""}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_seq_center____params_seq_center____4109(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4122_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4091: str
    channel_4105: str
    channel_4106: str
    channel_4107: str
    channel_4108: str
    channel_4109: str


class Res_4122_pre(NamedTuple):
    default: typing.List[Dataclass_4122_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_STAR_ALIGN_IGENOMES_4122_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4121: typing.Union[bool, None],
    channel_4091: typing.Union[str, None],
    channel_4105: typing.Union[str, None],
    channel_4106: typing.Union[str, None],
    channel_4107: typing.Union[str, None],
    channel_4108: typing.Union[str, None],
    channel_4109: typing.Union[str, None]
) -> Res_4122_pre:
    cond = ((condition_4104 == True) and (condition_4121 == True) and (channel_4091 is not None) and (channel_4105 is not None) and (channel_4106 is not None) and (channel_4107 is not None) and (channel_4108 is not None) and (channel_4109 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4122_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4091': channel_4091, 'channel_4105': channel_4105, 'channel_4106': channel_4106, 'channel_4107': channel_4107, 'channel_4108': channel_4108, 'channel_4109': channel_4109})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4122_pre(default=result, is_skipped = not cond)

class Respost_adapter_STAR_ALIGN_IGENOMES_4122_post(NamedTuple):
    bam: typing.Union[str, None]
    log_final: typing.Union[str, None]
    log_out: typing.Union[str, None]
    log_progress: typing.Union[str, None]
    versions: typing.Union[str, None]
    bam_sorted: typing.Union[str, None]
    bam_transcript: typing.Union[str, None]
    bam_unsorted: typing.Union[str, None]
    fastq: typing.Union[str, None]
    tab: typing.Union[str, None]
    junction: typing.Union[str, None]
    sam: typing.Union[str, None]

@dataclass
class Dataclass_4122_post:
    bam: str
    log_final: str
    log_out: str
    log_progress: str
    versions: str
    bam_sorted: str
    bam_transcript: str
    bam_unsorted: str
    fastq: str
    tab: str
    junction: str
    sam: str

@task(cache=True)
def post_adapter_STAR_ALIGN_IGENOMES_4122_post(
    default: List[Dataclass_4122_post],
    is_skipped: bool,
) -> Respost_adapter_STAR_ALIGN_IGENOMES_4122_post:
    return get_mapper_outputs(Respost_adapter_STAR_ALIGN_IGENOMES_4122_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4122_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4122_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4122_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4122_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4105),json.loads(default.channel_4106),json.loads(default.channel_4107),json.loads(default.channel_4108),json.loads(default.channel_4109)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/align_star/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','ALIGN_STAR'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_ALIGN_IGENOMES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_final\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_out\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_progress\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_sorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_unsorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"junction\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def STAR_ALIGN_IGENOMES_4122(
    default: Dataclass_4122_pre
) -> Dataclass_4122_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4105),json.loads(default.channel_4106),json.loads(default.channel_4107),json.loads(default.channel_4108),json.loads(default.channel_4109)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/align_star/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','ALIGN_STAR'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_ALIGN_IGENOMES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_final\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_out\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_progress\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_sorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_unsorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"junction\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN_IGENOMES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4122_post(
        bam=out_channels.get(f"bam"),
        log_final=out_channels.get(f"log_final"),
        log_out=out_channels.get(f"log_out"),
        log_progress=out_channels.get(f"log_progress"),
        versions=out_channels.get(f"versions"),
        bam_sorted=out_channels.get(f"bam_sorted"),
        bam_transcript=out_channels.get(f"bam_transcript"),
        bam_unsorted=out_channels.get(f"bam_unsorted"),
        fastq=out_channels.get(f"fastq"),
        tab=out_channels.get(f"tab"),
        junction=out_channels.get(f"junction"),
        sam=out_channels.get(f"sam")
    )


@dataclass
class Dataclass_4125_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4091: str
    channel_4105: str
    channel_4106: str
    channel_4107: str
    channel_4108: str
    channel_4109: str


class Res_4125_pre(NamedTuple):
    default: typing.List[Dataclass_4125_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_STAR_ALIGN_4125_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4121: typing.Union[bool, None],
    channel_4091: typing.Union[str, None],
    channel_4105: typing.Union[str, None],
    channel_4106: typing.Union[str, None],
    channel_4107: typing.Union[str, None],
    channel_4108: typing.Union[str, None],
    channel_4109: typing.Union[str, None]
) -> Res_4125_pre:
    cond = ((condition_4104 == True) and (condition_4121 == False) and (channel_4091 is not None) and (channel_4105 is not None) and (channel_4106 is not None) and (channel_4107 is not None) and (channel_4108 is not None) and (channel_4109 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4125_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4091': channel_4091, 'channel_4105': channel_4105, 'channel_4106': channel_4106, 'channel_4107': channel_4107, 'channel_4108': channel_4108, 'channel_4109': channel_4109})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4125_pre(default=result, is_skipped = not cond)

class Respost_adapter_STAR_ALIGN_4125_post(NamedTuple):
    log_final: typing.Union[str, None]
    log_out: typing.Union[str, None]
    log_progress: typing.Union[str, None]
    versions: typing.Union[str, None]
    bam: typing.Union[str, None]
    bam_sorted: typing.Union[str, None]
    bam_transcript: typing.Union[str, None]
    bam_unsorted: typing.Union[str, None]
    fastq: typing.Union[str, None]
    tab: typing.Union[str, None]
    spl_junc_tab: typing.Union[str, None]
    read_per_gene_tab: typing.Union[str, None]
    junction: typing.Union[str, None]
    sam: typing.Union[str, None]
    wig: typing.Union[str, None]
    bedgraph: typing.Union[str, None]

@dataclass
class Dataclass_4125_post:
    log_final: str
    log_out: str
    log_progress: str
    versions: str
    bam: str
    bam_sorted: str
    bam_transcript: str
    bam_unsorted: str
    fastq: str
    tab: str
    spl_junc_tab: str
    read_per_gene_tab: str
    junction: str
    sam: str
    wig: str
    bedgraph: str

@task(cache=True)
def post_adapter_STAR_ALIGN_4125_post(
    default: List[Dataclass_4125_post],
    is_skipped: bool,
) -> Respost_adapter_STAR_ALIGN_4125_post:
    return get_mapper_outputs(Respost_adapter_STAR_ALIGN_4125_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4125_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4125_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4125_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4125_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4105),json.loads(default.channel_4106),json.loads(default.channel_4107),json.loads(default.channel_4108),json.loads(default.channel_4109)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/align_star/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','ALIGN_STAR'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_final\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_out\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_progress\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_sorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_unsorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"spl_junc_tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"read_per_gene_tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"junction\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":12}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":13}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"wig\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":14}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":15}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def STAR_ALIGN_4125(
    default: Dataclass_4125_pre
) -> Dataclass_4125_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4105),json.loads(default.channel_4106),json.loads(default.channel_4107),json.loads(default.channel_4108),json.loads(default.channel_4109)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/align_star/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','ALIGN_STAR'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STAR_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_final\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_out\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"log_progress\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_sorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_unsorted\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":9}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"spl_junc_tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":10}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"read_per_gene_tab\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":11}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"junction\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":12}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"sam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":13}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"wig\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":14}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STAR_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":15}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4125_post(
        log_final=out_channels.get(f"log_final"),
        log_out=out_channels.get(f"log_out"),
        log_progress=out_channels.get(f"log_progress"),
        versions=out_channels.get(f"versions"),
        bam=out_channels.get(f"bam"),
        bam_sorted=out_channels.get(f"bam_sorted"),
        bam_transcript=out_channels.get(f"bam_transcript"),
        bam_unsorted=out_channels.get(f"bam_unsorted"),
        fastq=out_channels.get(f"fastq"),
        tab=out_channels.get(f"tab"),
        spl_junc_tab=out_channels.get(f"spl_junc_tab"),
        read_per_gene_tab=out_channels.get(f"read_per_gene_tab"),
        junction=out_channels.get(f"junction"),
        sam=out_channels.get(f"sam"),
        wig=out_channels.get(f"wig"),
        bedgraph=out_channels.get(f"bedgraph")
    )


class ResMerge_ch_log_progress_4130(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_log_progress_4130(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_3: typing.Union[str, None],
    channel_4125_2: typing.Union[str, None]
) -> ResMerge_ch_log_progress_4130:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_3 or channel_4125_2 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_log_progress_4130(
        res=res.get('res')
    )


class ResMerge_ch_bam_sorted_4131(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bam_sorted_4131(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_5: typing.Union[str, None],
    channel_4125_5: typing.Union[str, None]
) -> ResMerge_ch_bam_sorted_4131:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_5 or channel_4125_5 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bam_sorted_4131(
        res=res.get('res')
    )


class ResMerge_ch_tab_4133(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_tab_4133(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_9: typing.Union[str, None],
    channel_4125_9: typing.Union[str, None]
) -> ResMerge_ch_tab_4133:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_9 or channel_4125_9 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_tab_4133(
        res=res.get('res')
    )


class ResMerge_ch_log_out_4134(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_log_out_4134(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_2: typing.Union[str, None],
    channel_4125_1: typing.Union[str, None]
) -> ResMerge_ch_log_out_4134:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_2 or channel_4125_1 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_log_out_4134(
        res=res.get('res')
    )


class ResMerge_ch_fastq_4135(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fastq_4135(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_8: typing.Union[str, None],
    channel_4125_8: typing.Union[str, None]
) -> ResMerge_ch_fastq_4135:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_8 or channel_4125_8 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fastq_4135(
        res=res.get('res')
    )


class Resparams_bam_csi_index_4156(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_4156(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_bam_csi_index_4156:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_4156(
        res=out_channels.get("res")
    )


class Resconditional_params_bam_csi_index_4157(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bam_csi_index_4157(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4156: typing.Union[str, None]
) -> Resconditional_params_bam_csi_index_4157:
    cond = ((condition_4104 == True) and (channel_4156 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4156)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bam_csi_index_4157(condition=res)


class Resparams_with_umi_4160(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_with_umi_4160(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_with_umi_4160:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"with_umi"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_with_umi_4160(
        res=out_channels.get("res")
    )


class Resconditional_params_with_umi_4161(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_with_umi_4161(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4160: typing.Union[str, None]
) -> Resconditional_params_with_umi_4161:
    cond = ((condition_4104 == True) and (channel_4160 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4160)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_with_umi_4161(condition=res)


class Resparams_bam_csi_index_4183(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_4183(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> Resparams_bam_csi_index_4183:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_4183(
        res=out_channels.get("res")
    )


class Resconditional_params_bam_csi_index_4184(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bam_csi_index_4184(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4183: typing.Union[str, None]
) -> Resconditional_params_bam_csi_index_4184:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4183 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4183)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bam_csi_index_4184(condition=res)


class ResChannel_empty___4188(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4188(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> ResChannel_empty___4188:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4188(
        res=out_channels.get("res")
    )


class ResMerge_ch_bam_transcript_4129(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bam_transcript_4129(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_6: typing.Union[str, None],
    channel_4125_6: typing.Union[str, None]
) -> ResMerge_ch_bam_transcript_4129:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_6 or channel_4125_6 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bam_transcript_4129(
        res=res.get('res')
    )


@dataclass
class Dataclass_4189_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4129: str


class Res_4189_pre(NamedTuple):
    default: typing.List[Dataclass_4189_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_4189_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4129: typing.Union[str, None]
) -> Res_4189_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4129 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4189_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4129': channel_4129})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4189_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_4189_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4189_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_4189_post(
    default: List[Dataclass_4189_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_4189_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_4189_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4189_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4189_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4189_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4189_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4129)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_4189(
    default: Dataclass_4189_pre
) -> Dataclass_4189_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4129)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4189_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4190(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4190(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4189_2: typing.Union[str, None]
) -> Resfirst_4190:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4189_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4189_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4190(
        res=out_channels.get("res")
    )


class Resmix_4191(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4191(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4188: typing.Union[str, None],
    channel_4190: typing.Union[str, None]
) -> Resmix_4191:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4188 is not None) and (channel_4190 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4188), json.loads(channel_4190)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4191(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4192_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4189_0: str


class Res_4192_pre(NamedTuple):
    default: typing.List[Dataclass_4192_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4192_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4189_0: typing.Union[str, None]
) -> Res_4192_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4189_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4192_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4189_0': channel_4189_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4192_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4192_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4192_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4192_post(
    default: List[Dataclass_4192_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4192_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4192_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4192_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4192_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4192_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4192_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4189_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4192(
    default: Dataclass_4192_pre
) -> Dataclass_4192_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4189_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4192_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4193(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4193(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4192_3: typing.Union[str, None]
) -> Resfirst_4193:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4192_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4192_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4193(
        res=out_channels.get("res")
    )


class Resmix_4194(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4194(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4191: typing.Union[str, None],
    channel_4193: typing.Union[str, None]
) -> Resmix_4194:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4191 is not None) and (channel_4193 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4191), json.loads(channel_4193)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4194(
        res=out_channels.get("res")
    )


class ResChannel_empty___4198(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4198(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> ResChannel_empty___4198:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4198(
        res=out_channels.get("res")
    )


class Resjoin_4195(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4195(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4189_0: typing.Union[str, None],
    channel_4192_0: typing.Union[str, None]
) -> Resjoin_4195:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4189_0 is not None) and (channel_4192_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4189_0), json.loads(channel_4192_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4195(
        res=out_channels.get("res")
    )


class Resjoin_4196(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4196(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4195: typing.Union[str, None],
    channel_4192_1: typing.Union[str, None]
) -> Resjoin_4196:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4195 is not None) and (channel_4192_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4195), json.loads(channel_4192_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4196(
        res=out_channels.get("res")
    )


class Resmap_4197(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4197(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4196: typing.Union[str, None]
) -> Resmap_4197:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4196 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4196)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4197(
        res=out_channels.get("res")
    )


class Resmap_4187(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4187(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_4187:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4187(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4199_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4197: str
    channel_4187: str


class Res_4199_pre(NamedTuple):
    default: typing.List[Dataclass_4199_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4199_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4197: typing.Union[str, None],
    channel_4187: typing.Union[str, None]
) -> Res_4199_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4197 is not None) and (channel_4187 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4199_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4197': channel_4197, 'channel_4187': channel_4187})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4199_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4199_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4199_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4199_post(
    default: List[Dataclass_4199_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4199_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4199_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4199_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4199_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4199_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4199_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4197),json.loads(default.channel_4187)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4199(
    default: Dataclass_4199_pre
) -> Dataclass_4199_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4197),json.loads(default.channel_4187)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4199_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4200(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4200(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4198: typing.Union[str, None],
    channel_4199_1: typing.Union[str, None]
) -> Resmix_4200:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4198 is not None) and (channel_4199_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4198), json.loads(channel_4199_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4200(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4201_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4197: str


class Res_4201_pre(NamedTuple):
    default: typing.List[Dataclass_4201_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4201_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4197: typing.Union[str, None]
) -> Res_4201_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4197 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4201_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4197': channel_4197})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4201_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4201_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4201_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4201_post(
    default: List[Dataclass_4201_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4201_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4201_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4201_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4201_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4201_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4201_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4197)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4201(
    default: Dataclass_4201_pre
) -> Dataclass_4201_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4197)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4201_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4202(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4202(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4200: typing.Union[str, None],
    channel_4201_1: typing.Union[str, None]
) -> Resmix_4202:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4200 is not None) and (channel_4201_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4200), json.loads(channel_4201_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4202(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4203_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4197: str


class Res_4203_pre(NamedTuple):
    default: typing.List[Dataclass_4203_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4203_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4197: typing.Union[str, None]
) -> Res_4203_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4197 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4203_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4197': channel_4197})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4203_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4203_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4203_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4203_post(
    default: List[Dataclass_4203_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4203_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4203_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4203_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4203_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4203_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4203_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4197)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4203(
    default: Dataclass_4203_pre
) -> Dataclass_4203_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4197)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4203_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4204(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4204(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4202: typing.Union[str, None],
    channel_4203_1: typing.Union[str, None]
) -> Resmix_4204:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4202 is not None) and (channel_4203_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4202), json.loads(channel_4203_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4204(
        res=out_channels.get("res")
    )


class Resmix_4205(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4205(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4194: typing.Union[str, None],
    channel_4204: typing.Union[str, None]
) -> Resmix_4205:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4194 is not None) and (channel_4204 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4194), json.loads(channel_4204)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4205(
        res=out_channels.get("res")
    )


class ResChannel_empty___4208(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4208(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> ResChannel_empty___4208:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4208(
        res=out_channels.get("res")
    )


class Resjoin_4206(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4206(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4189_0: typing.Union[str, None],
    channel_4192_0: typing.Union[str, None]
) -> Resjoin_4206:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4189_0 is not None) and (channel_4192_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4189_0), json.loads(channel_4192_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4206(
        res=out_channels.get("res")
    )


class Resparams_umitools_dedup_stats_4207(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_umitools_dedup_stats_4207(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> Resparams_umitools_dedup_stats_4207:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"umitools_dedup_stats"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_umitools_dedup_stats_4207(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4209_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4206: str
    channel_4207: str


class Res_4209_pre(NamedTuple):
    default: typing.List[Dataclass_4209_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UMITOOLS_DEDUP_4209_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4206: typing.Union[str, None],
    channel_4207: typing.Union[str, None]
) -> Res_4209_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4206 is not None) and (channel_4207 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4209_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4206': channel_4206, 'channel_4207': channel_4207})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4209_pre(default=result, is_skipped = not cond)

class Respost_adapter_UMITOOLS_DEDUP_4209_post(NamedTuple):
    bam: typing.Union[str, None]
    log: typing.Union[str, None]
    tsv_edit_distance: typing.Union[str, None]
    tsv_per_umi: typing.Union[str, None]
    tsv_umi_per_position: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4209_post:
    bam: str
    log: str
    tsv_edit_distance: str
    tsv_per_umi: str
    tsv_umi_per_position: str
    versions: str

@task(cache=True)
def post_adapter_UMITOOLS_DEDUP_4209_post(
    default: List[Dataclass_4209_post],
    is_skipped: bool,
) -> Respost_adapter_UMITOOLS_DEDUP_4209_post:
    return get_mapper_outputs(Respost_adapter_UMITOOLS_DEDUP_4209_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4209_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4209_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4209_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4209_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4206),json.loads(default.channel_4207)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_DEDUP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_edit_distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_per_umi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_umi_per_position\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UMITOOLS_DEDUP_4209(
    default: Dataclass_4209_pre
) -> Dataclass_4209_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4206),json.loads(default.channel_4207)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_DEDUP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_edit_distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_per_umi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_umi_per_position\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4209_post(
        bam=out_channels.get(f"bam"),
        log=out_channels.get(f"log"),
        tsv_edit_distance=out_channels.get(f"tsv_edit_distance"),
        tsv_per_umi=out_channels.get(f"tsv_per_umi"),
        tsv_umi_per_position=out_channels.get(f"tsv_umi_per_position"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4210(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4210(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4209_5: typing.Union[str, None]
) -> Resfirst_4210:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4209_5 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4209_5)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4210(
        res=out_channels.get("res")
    )


class Resmix_4211(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4211(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4208: typing.Union[str, None],
    channel_4210: typing.Union[str, None]
) -> Resmix_4211:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4208 is not None) and (channel_4210 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4208), json.loads(channel_4210)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4211(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4212_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4209_0: str


class Res_4212_pre(NamedTuple):
    default: typing.List[Dataclass_4212_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4212_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4209_0: typing.Union[str, None]
) -> Res_4212_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4209_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4212_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4209_0': channel_4209_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4212_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4212_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4212_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4212_post(
    default: List[Dataclass_4212_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4212_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4212_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4212_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4212_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4212_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4212_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4209_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4212(
    default: Dataclass_4212_pre
) -> Dataclass_4212_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4209_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4212_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4213(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4213(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4212_3: typing.Union[str, None]
) -> Resfirst_4213:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4212_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4212_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4213(
        res=out_channels.get("res")
    )


class Resmix_4214(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4214(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4211: typing.Union[str, None],
    channel_4213: typing.Union[str, None]
) -> Resmix_4214:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4211 is not None) and (channel_4213 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4211), json.loads(channel_4213)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4214(
        res=out_channels.get("res")
    )


class ResChannel_empty___4219(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4219(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> ResChannel_empty___4219:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4219(
        res=out_channels.get("res")
    )


class Resjoin_4215(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4215(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4209_0: typing.Union[str, None],
    channel_4212_0: typing.Union[str, None]
) -> Resjoin_4215:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4209_0 is not None) and (channel_4212_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4209_0), json.loads(channel_4212_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4215(
        res=out_channels.get("res")
    )


class Resjoin_4216(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4216(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4215: typing.Union[str, None],
    channel_4212_1: typing.Union[str, None]
) -> Resjoin_4216:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4215 is not None) and (channel_4212_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4215), json.loads(channel_4212_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4216(
        res=out_channels.get("res")
    )


class Resmap_4217(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4217(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4216: typing.Union[str, None]
) -> Resmap_4217:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4216 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4216)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4217(
        res=out_channels.get("res")
    )


class Res__________4218(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __________4218(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> Res__________4218:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"MapExpression":[]},{"ListExpression":[]}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__________4218(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4220_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4217: str
    channel_4218: str


class Res_4220_pre(NamedTuple):
    default: typing.List[Dataclass_4220_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4220_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4217: typing.Union[str, None],
    channel_4218: typing.Union[str, None]
) -> Res_4220_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4217 is not None) and (channel_4218 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4220_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4217': channel_4217, 'channel_4218': channel_4218})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4220_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4220_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4220_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4220_post(
    default: List[Dataclass_4220_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4220_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4220_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4220_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4220_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4220_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4220_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4217),json.loads(default.channel_4218)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4220(
    default: Dataclass_4220_pre
) -> Dataclass_4220_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4217),json.loads(default.channel_4218)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4220_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4221(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4221(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4219: typing.Union[str, None],
    channel_4220_1: typing.Union[str, None]
) -> Resmix_4221:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4219 is not None) and (channel_4220_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4219), json.loads(channel_4220_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4221(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4222_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4217: str


class Res_4222_pre(NamedTuple):
    default: typing.List[Dataclass_4222_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4222_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4217: typing.Union[str, None]
) -> Res_4222_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4217 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4222_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4217': channel_4217})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4222_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4222_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4222_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4222_post(
    default: List[Dataclass_4222_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4222_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4222_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4222_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4222_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4222_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4222_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4217)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4222(
    default: Dataclass_4222_pre
) -> Dataclass_4222_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4217)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4222_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4223(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4223(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4221: typing.Union[str, None],
    channel_4222_1: typing.Union[str, None]
) -> Resmix_4223:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4221 is not None) and (channel_4222_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4221), json.loads(channel_4222_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4223(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4224_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4217: str


class Res_4224_pre(NamedTuple):
    default: typing.List[Dataclass_4224_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4224_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4217: typing.Union[str, None]
) -> Res_4224_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4217 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4224_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4217': channel_4217})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4224_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4224_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4224_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4224_post(
    default: List[Dataclass_4224_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4224_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4224_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4224_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4224_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4224_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4224_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4217)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4224(
    default: Dataclass_4224_pre
) -> Dataclass_4224_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4217)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4224_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4225(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4225(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4223: typing.Union[str, None],
    channel_4224_1: typing.Union[str, None]
) -> Resmix_4225:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4223 is not None) and (channel_4224_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4223), json.loads(channel_4224_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4225(
        res=out_channels.get("res")
    )


class Resmix_4226(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4226(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4214: typing.Union[str, None],
    channel_4225: typing.Union[str, None]
) -> Resmix_4226:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4214 is not None) and (channel_4225 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4214), json.loads(channel_4225)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4226(
        res=out_channels.get("res")
    )


class Restrue_4241(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def true_4241(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Restrue_4241:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Restrue_4241(
        res=out_channels.get("res")
    )


class Res_pseudo_aligner____salmon__4246(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _pseudo_aligner____salmon__4246(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4241: typing.Union[str, None]
) -> Res_pseudo_aligner____salmon__4246:
    cond = ((condition_4104 == True) and (channel_4241 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4241)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"salmon"},{"ConstantExpression":"=="}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_pseudo_aligner____salmon__4246(
        res=out_channels.get("res")
    )


class Res_pseudo_aligner____salmon__4247(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _pseudo_aligner____salmon__4247(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4246: typing.Union[str, None]
) -> Res_pseudo_aligner____salmon__4247:
    cond = ((condition_4104 == True) and (channel_4246 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4246)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_pseudo_aligner____salmon__4247(
        res=out_channels.get("res")
    )


class Resconditional__pseudo_aligner____salmon__4248(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__pseudo_aligner____salmon__4248(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4247: typing.Union[str, None]
) -> Resconditional__pseudo_aligner____salmon__4248:
    cond = ((condition_4104 == True) and (channel_4247 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4247)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__pseudo_aligner____salmon__4248(condition=res)


@dataclass
class Dataclass_4227_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4209_0: str


class Res_4227_pre(NamedTuple):
    default: typing.List[Dataclass_4227_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_4227_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4209_0: typing.Union[str, None]
) -> Res_4227_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4209_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4227_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4209_0': channel_4209_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4227_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_4227_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4227_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_4227_post(
    default: List[Dataclass_4227_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_4227_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_4227_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4227_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4227_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4227_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4227_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4209_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_4227(
    default: Dataclass_4227_pre
) -> Dataclass_4227_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4209_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4227_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


class Resbranch_4228(NamedTuple):
    single_end: typing.Union[str, None]
    paired_end: typing.Union[str, None]

@task(cache=True)
def branch_4228(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4227_0: typing.Union[str, None]
) -> Resbranch_4228:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4227_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4227_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"branch","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"single_end"}},"labels":["single_end"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"}]},{"ConstantExpression":"single_end"}]}}}}},{"ExpressionStatement":{"expression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"single_end"}}},"labels":["paired_end"]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"}]},{"ConstantExpression":"paired_end"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"single_end\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"single_end\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"paired_end\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"paired_end\\"}}}},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'single_end': None, 'paired_end': None}

    return Resbranch_4228(
        single_end=out_channels.get("single_end"),
        paired_end=out_channels.get("paired_end")
    )


@dataclass
class Dataclass_4229_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4228_1: str


class Res_4229_pre(NamedTuple):
    default: typing.List[Dataclass_4229_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UMITOOLS_PREPAREFORSALMON_4229_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4228_1: typing.Union[str, None]
) -> Res_4229_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4228_1 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4229_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4228_1': channel_4228_1})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4229_pre(default=result, is_skipped = not cond)

class Respost_adapter_UMITOOLS_PREPAREFORSALMON_4229_post(NamedTuple):
    bam: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4229_post:
    bam: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_UMITOOLS_PREPAREFORSALMON_4229_post(
    default: List[Dataclass_4229_post],
    is_skipped: bool,
) -> Respost_adapter_UMITOOLS_PREPAREFORSALMON_4229_post:
    return get_mapper_outputs(Respost_adapter_UMITOOLS_PREPAREFORSALMON_4229_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4229_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4229_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4229_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4229_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4228_1)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_PREPAREFORSALMON","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_PREPAREFORSALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_PREPAREFORSALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_PREPAREFORSALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UMITOOLS_PREPAREFORSALMON_4229(
    default: Dataclass_4229_pre
) -> Dataclass_4229_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4228_1)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_PREPAREFORSALMON","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_PREPAREFORSALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_PREPAREFORSALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_PREPAREFORSALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4229_post(
        bam=out_channels.get(f"bam"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4232(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4232(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4228_0: typing.Union[str, None],
    channel_4229_0: typing.Union[str, None]
) -> Resmix_4232:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4228_0 is not None) and (channel_4229_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4228_0), json.loads(channel_4229_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4232(
        res=out_channels.get("res")
    )


class ResMerge_ch_transcriptome_bam_4239(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_transcriptome_bam_4239(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4232: typing.Union[str, None],
    channel_4129: typing.Union[str, None]
) -> ResMerge_ch_transcriptome_bam_4239:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4232 or channel_4129 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_transcriptome_bam_4239(
        res=res.get('res')
    )


class Ressalmon_4240(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def salmon_4240(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Ressalmon_4240:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"salmon"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Ressalmon_4240(
        res=out_channels.get("res")
    )


class Res_params_salmon_quant_libtype____params_salmon_quant_libtype____4242(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_salmon_quant_libtype____params_salmon_quant_libtype____4242(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Res_params_salmon_quant_libtype____params_salmon_quant_libtype____4242:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"salmon_quant_libtype"}}},"trueExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"salmon_quant_libtype"}},"falseExpression":{"ConstantExpression":""}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_salmon_quant_libtype____params_salmon_quant_libtype____4242(
        res=out_channels.get("res")
    )


class Resparams_kallisto_quant_fraglen_4243(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_kallisto_quant_fraglen_4243(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_kallisto_quant_fraglen_4243:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"kallisto_quant_fraglen"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_kallisto_quant_fraglen_4243(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4249_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4239: str
    channel_3695: str
    channel_4240: str
    channel_3656: str
    channel_4242: str
    channel_4243: str


class Res_4249_pre(NamedTuple):
    default: typing.List[Dataclass_4249_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SALMON_QUANT_4249_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4248: typing.Union[bool, None],
    channel_4239: typing.Union[str, None],
    channel_3695: typing.Union[str, None],
    channel_4240: typing.Union[str, None],
    channel_3656: typing.Union[str, None],
    channel_4242: typing.Union[str, None],
    channel_4243: typing.Union[str, None]
) -> Res_4249_pre:
    cond = ((condition_4104 == True) and (condition_4248 == True) and (channel_4239 is not None) and (channel_3695 is not None) and (channel_4240 is not None) and (channel_3656 is not None) and (channel_4242 is not None) and (channel_4243 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4249_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4239': channel_4239, 'channel_3695': channel_3695, 'channel_4240': channel_4240, 'channel_3656': channel_3656, 'channel_4242': channel_4242, 'channel_4243': channel_4243})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4249_pre(default=result, is_skipped = not cond)

class Respost_adapter_SALMON_QUANT_4249_post(NamedTuple):
    results: typing.Union[str, None]
    json_info: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4249_post:
    results: str
    json_info: str
    versions: str

@task(cache=True)
def post_adapter_SALMON_QUANT_4249_post(
    default: List[Dataclass_4249_post],
    is_skipped: bool,
) -> Respost_adapter_SALMON_QUANT_4249_post:
    return get_mapper_outputs(Respost_adapter_SALMON_QUANT_4249_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4249_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4249_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4249_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4249_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4239),json.loads(default.channel_3695),json.loads(default.channel_4240),json.loads(default.channel_3656),json.loads(default.channel_4242),json.loads(default.channel_4243)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SALMON_QUANT_4249(
    default: Dataclass_4249_pre
) -> Dataclass_4249_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4239),json.loads(default.channel_3695),json.loads(default.channel_4240),json.loads(default.channel_3656),json.loads(default.channel_4242),json.loads(default.channel_4243)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4249_post(
        results=out_channels.get(f"results"),
        json_info=out_channels.get(f"json_info"),
        versions=out_channels.get(f"versions")
    )


class Resparams_kallisto_quant_fraglen_sd_4244(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_kallisto_quant_fraglen_sd_4244(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_kallisto_quant_fraglen_sd_4244:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"kallisto_quant_fraglen_sd"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_kallisto_quant_fraglen_sd_4244(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4252_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4239: str
    channel_3695: str
    channel_4240: str
    channel_4244: str


class Res_4252_pre(NamedTuple):
    default: typing.List[Dataclass_4252_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_KALLISTO_QUANT_4252_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4248: typing.Union[bool, None],
    channel_4239: typing.Union[str, None],
    channel_3695: typing.Union[str, None],
    channel_4240: typing.Union[str, None],
    channel_4244: typing.Union[str, None]
) -> Res_4252_pre:
    cond = ((condition_4104 == True) and (condition_4248 == False) and (channel_4239 is not None) and (channel_3695 is not None) and (channel_4240 is not None) and (channel_4244 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4252_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4239': channel_4239, 'channel_3695': channel_3695, 'channel_4240': channel_4240, 'channel_4244': channel_4244})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4252_pre(default=result, is_skipped = not cond)

class Respost_adapter_KALLISTO_QUANT_4252_post(NamedTuple):
    results: typing.Union[str, None]
    json_info: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4252_post:
    results: str
    json_info: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_KALLISTO_QUANT_4252_post(
    default: List[Dataclass_4252_post],
    is_skipped: bool,
) -> Respost_adapter_KALLISTO_QUANT_4252_post:
    return get_mapper_outputs(Respost_adapter_KALLISTO_QUANT_4252_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4252_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4252_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4252_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4252_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4239),json.loads(default.channel_3695),json.loads(default.channel_4240),json.loads(default.channel_4244)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"KALLISTO_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def KALLISTO_QUANT_4252(
    default: Dataclass_4252_pre
) -> Dataclass_4252_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4239),json.loads(default.channel_3695),json.loads(default.channel_4240),json.loads(default.channel_4244)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"KALLISTO_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4252_post(
        results=out_channels.get(f"results"),
        json_info=out_channels.get(f"json_info"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_pseudo_multiqc_4255(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudo_multiqc_4255(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4249_0: typing.Union[str, None],
    channel_4252_2: typing.Union[str, None]
) -> ResMerge_ch_pseudo_multiqc_4255:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4249_0 or channel_4252_2 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudo_multiqc_4255(
        res=res.get('res')
    )


class ResMerge_ch_pseudo_results_4256(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudo_results_4256(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4249_0: typing.Union[str, None],
    channel_4252_0: typing.Union[str, None]
) -> ResMerge_ch_pseudo_results_4256:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4249_0 or channel_4252_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudo_results_4256(
        res=res.get('res')
    )


class Rescollect_4261(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4261(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4256: typing.Union[str, None]
) -> Rescollect_4261:
    cond = ((condition_4104 == True) and (channel_4256 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4256)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4261(
        res=out_channels.get("res")
    )


class Rescollect_4258(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4258(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4256: typing.Union[str, None]
) -> Rescollect_4258:
    cond = ((condition_4104 == True) and (channel_4256 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4256)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4258(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4259_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4258: str
    channel_4241: str
    channel_4240: str


class Res_4259_pre(NamedTuple):
    default: typing.List[Dataclass_4259_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_TX2GENE_4259_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4258: typing.Union[str, None],
    channel_4241: typing.Union[str, None],
    channel_4240: typing.Union[str, None]
) -> Res_4259_pre:
    cond = ((condition_4104 == True) and (channel_4258 is not None) and (channel_4241 is not None) and (channel_4240 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4259_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4258': channel_4258, 'channel_4241': channel_4241, 'channel_4240': channel_4240})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4259_pre(default=result, is_skipped = not cond)

class Respost_adapter_TX2GENE_4259_post(NamedTuple):
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4259_post:
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_TX2GENE_4259_post(
    default: List[Dataclass_4259_post],
    is_skipped: bool,
) -> Respost_adapter_TX2GENE_4259_post:
    return get_mapper_outputs(Respost_adapter_TX2GENE_4259_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4259_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4259_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4259_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4259_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4258),json.loads(default.channel_4241),json.loads(default.channel_4240)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TX2GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def TX2GENE_4259(
    default: Dataclass_4259_pre
) -> Dataclass_4259_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4258),json.loads(default.channel_4241),json.loads(default.channel_4240)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TX2GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4259_post(
        tsv=out_channels.get(f"tsv"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4262(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4262(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4259_0: typing.Union[str, None]
) -> Rescollect_4262:
    cond = ((condition_4104 == True) and (channel_4259_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4259_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4262(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4263_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4261: str
    channel_4262: str
    channel_4241: str


class Res_4263_pre(NamedTuple):
    default: typing.List[Dataclass_4263_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_TXIMPORT_4263_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4261: typing.Union[str, None],
    channel_4262: typing.Union[str, None],
    channel_4241: typing.Union[str, None]
) -> Res_4263_pre:
    cond = ((condition_4104 == True) and (channel_4261 is not None) and (channel_4262 is not None) and (channel_4241 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4263_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4261': channel_4261, 'channel_4262': channel_4262, 'channel_4241': channel_4241})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4263_pre(default=result, is_skipped = not cond)

class Respost_adapter_TXIMPORT_4263_post(NamedTuple):
    tpm_gene: typing.Union[str, None]
    counts_gene: typing.Union[str, None]
    counts_gene_length_scaled: typing.Union[str, None]
    counts_gene_scaled: typing.Union[str, None]
    lengths_gene: typing.Union[str, None]
    tpm_transcript: typing.Union[str, None]
    counts_transcript: typing.Union[str, None]
    lengths_transcript: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4263_post:
    tpm_gene: str
    counts_gene: str
    counts_gene_length_scaled: str
    counts_gene_scaled: str
    lengths_gene: str
    tpm_transcript: str
    counts_transcript: str
    lengths_transcript: str
    versions: str

@task(cache=True)
def post_adapter_TXIMPORT_4263_post(
    default: List[Dataclass_4263_post],
    is_skipped: bool,
) -> Respost_adapter_TXIMPORT_4263_post:
    return get_mapper_outputs(Respost_adapter_TXIMPORT_4263_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4263_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4263_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4263_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4263_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4261),json.loads(default.channel_4262),json.loads(default.channel_4241)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TXIMPORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_length_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def TXIMPORT_4263(
    default: Dataclass_4263_pre
) -> Dataclass_4263_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4261),json.loads(default.channel_4262),json.loads(default.channel_4241)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TXIMPORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_length_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4263_post(
        tpm_gene=out_channels.get(f"tpm_gene"),
        counts_gene=out_channels.get(f"counts_gene"),
        counts_gene_length_scaled=out_channels.get(f"counts_gene_length_scaled"),
        counts_gene_scaled=out_channels.get(f"counts_gene_scaled"),
        lengths_gene=out_channels.get(f"lengths_gene"),
        tpm_transcript=out_channels.get(f"tpm_transcript"),
        counts_transcript=out_channels.get(f"counts_transcript"),
        lengths_transcript=out_channels.get(f"lengths_transcript"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4268(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4268(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4259_0: typing.Union[str, None]
) -> Rescollect_4268:
    cond = ((condition_4104 == True) and (channel_4259_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4259_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4268(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4269_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4263_2: str
    channel_4263_0: str
    channel_4268: str


class Res_4269_pre(NamedTuple):
    default: typing.List[Dataclass_4269_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_GENE_LENGTH_SCALED_4269_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4263_2: typing.Union[str, None],
    channel_4263_0: typing.Union[str, None],
    channel_4268: typing.Union[str, None]
) -> Res_4269_pre:
    cond = ((condition_4104 == True) and (channel_4263_2 is not None) and (channel_4263_0 is not None) and (channel_4268 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4269_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4263_2': channel_4263_2, 'channel_4263_0': channel_4263_0, 'channel_4268': channel_4268})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4269_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_GENE_LENGTH_SCALED_4269_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4269_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_GENE_LENGTH_SCALED_4269_post(
    default: List[Dataclass_4269_post],
    is_skipped: bool,
) -> Respost_adapter_SE_GENE_LENGTH_SCALED_4269_post:
    return get_mapper_outputs(Respost_adapter_SE_GENE_LENGTH_SCALED_4269_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4269_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4269_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4269_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4269_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_2),json.loads(default.channel_4263_0),json.loads(default.channel_4268)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_LENGTH_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_GENE_LENGTH_SCALED_4269(
    default: Dataclass_4269_pre
) -> Dataclass_4269_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_2),json.loads(default.channel_4263_0),json.loads(default.channel_4268)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_LENGTH_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4269_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4270(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4270(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4259_0: typing.Union[str, None]
) -> Rescollect_4270:
    cond = ((condition_4104 == True) and (channel_4259_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4259_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4270(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4271_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4263_3: str
    channel_4263_0: str
    channel_4270: str


class Res_4271_pre(NamedTuple):
    default: typing.List[Dataclass_4271_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_GENE_SCALED_4271_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4263_3: typing.Union[str, None],
    channel_4263_0: typing.Union[str, None],
    channel_4270: typing.Union[str, None]
) -> Res_4271_pre:
    cond = ((condition_4104 == True) and (channel_4263_3 is not None) and (channel_4263_0 is not None) and (channel_4270 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4271_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4263_3': channel_4263_3, 'channel_4263_0': channel_4263_0, 'channel_4270': channel_4270})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4271_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_GENE_SCALED_4271_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4271_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_GENE_SCALED_4271_post(
    default: List[Dataclass_4271_post],
    is_skipped: bool,
) -> Respost_adapter_SE_GENE_SCALED_4271_post:
    return get_mapper_outputs(Respost_adapter_SE_GENE_SCALED_4271_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4271_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4271_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4271_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4271_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_3),json.loads(default.channel_4263_0),json.loads(default.channel_4270)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_GENE_SCALED_4271(
    default: Dataclass_4271_pre
) -> Dataclass_4271_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_3),json.loads(default.channel_4263_0),json.loads(default.channel_4270)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4271_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4272(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4272(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4259_0: typing.Union[str, None]
) -> Rescollect_4272:
    cond = ((condition_4104 == True) and (channel_4259_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4259_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4272(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4273_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4263_6: str
    channel_4263_5: str
    channel_4272: str


class Res_4273_pre(NamedTuple):
    default: typing.List[Dataclass_4273_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_TRANSCRIPT_4273_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4263_6: typing.Union[str, None],
    channel_4263_5: typing.Union[str, None],
    channel_4272: typing.Union[str, None]
) -> Res_4273_pre:
    cond = ((condition_4104 == True) and (channel_4263_6 is not None) and (channel_4263_5 is not None) and (channel_4272 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4273_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4263_6': channel_4263_6, 'channel_4263_5': channel_4263_5, 'channel_4272': channel_4272})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4273_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_TRANSCRIPT_4273_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4273_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_TRANSCRIPT_4273_post(
    default: List[Dataclass_4273_post],
    is_skipped: bool,
) -> Respost_adapter_SE_TRANSCRIPT_4273_post:
    return get_mapper_outputs(Respost_adapter_SE_TRANSCRIPT_4273_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4273_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4273_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4273_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4273_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_6),json.loads(default.channel_4263_5),json.loads(default.channel_4272)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_TRANSCRIPT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_TRANSCRIPT_4273(
    default: Dataclass_4273_pre
) -> Dataclass_4273_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_6),json.loads(default.channel_4263_5),json.loads(default.channel_4272)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_TRANSCRIPT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4273_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Resparams_skip_alignment_4295(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4295(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4295:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4295(
        res=out_channels.get("res")
    )


class Res_params_aligner____star_rsem__4296(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____star_rsem__4296(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_params_aligner____star_rsem__4296:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"star_rsem"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____star_rsem__4296(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment_____params_aligner____star_rsem___4297(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment_____params_aligner____star_rsem___4297(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4295: typing.Union[str, None],
    channel_4296: typing.Union[str, None]
) -> Res_params_skip_alignment_____params_aligner____star_rsem___4297:
    cond = ((channel_4295 is not None) and (channel_4296 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4295), json.loads(channel_4296)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment_____params_aligner____star_rsem___4297(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment_____params_aligner____star_rsem___4298(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment_____params_aligner____star_rsem___4298(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4297: typing.Union[str, None]
) -> Res_params_skip_alignment_____params_aligner____star_rsem___4298:
    cond = ((channel_4297 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4297)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment_____params_aligner____star_rsem___4298(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment_____params_aligner____star_rsem___4299(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment_____params_aligner____star_rsem___4299(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4298: typing.Union[str, None]
) -> Resconditional__params_skip_alignment_____params_aligner____star_rsem___4299:
    cond = ((channel_4298 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4298)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment_____params_aligner____star_rsem___4299(condition=res)


class Resparams_bam_csi_index_4328(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_4328(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None]
) -> Resparams_bam_csi_index_4328:
    cond = ((condition_4299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_4328(
        res=out_channels.get("res")
    )


class Resconditional_params_bam_csi_index_4329(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bam_csi_index_4329(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4328: typing.Union[str, None]
) -> Resconditional_params_bam_csi_index_4329:
    cond = ((condition_4299 == True) and (channel_4328 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4328)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bam_csi_index_4329(condition=res)


class Resparams_skip_alignment_4353(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4353(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4353:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4353(
        res=out_channels.get("res")
    )


class Res_params_aligner____hisat2__4354(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_aligner____hisat2__4354(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_params_aligner____hisat2__4354:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"hisat2"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_aligner____hisat2__4354(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment_____params_aligner____hisat2___4355(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment_____params_aligner____hisat2___4355(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4353: typing.Union[str, None],
    channel_4354: typing.Union[str, None]
) -> Res_params_skip_alignment_____params_aligner____hisat2___4355:
    cond = ((channel_4353 is not None) and (channel_4354 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4353), json.loads(channel_4354)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment_____params_aligner____hisat2___4355(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment_____params_aligner____hisat2___4356(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment_____params_aligner____hisat2___4356(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4355: typing.Union[str, None]
) -> Res_params_skip_alignment_____params_aligner____hisat2___4356:
    cond = ((channel_4355 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4355)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment_____params_aligner____hisat2___4356(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment_____params_aligner____hisat2___4357(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment_____params_aligner____hisat2___4357(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4356: typing.Union[str, None]
) -> Resconditional__params_skip_alignment_____params_aligner____hisat2___4357:
    cond = ((channel_4356 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4356)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment_____params_aligner____hisat2___4357(condition=res)


class Resparams_bam_csi_index_4384(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_4384(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None]
) -> Resparams_bam_csi_index_4384:
    cond = ((condition_4357 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_4384(
        res=out_channels.get("res")
    )


class Resconditional_params_bam_csi_index_4385(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bam_csi_index_4385(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4384: typing.Union[str, None]
) -> Resconditional_params_bam_csi_index_4385:
    cond = ((condition_4357 == True) and (channel_4384 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4384)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bam_csi_index_4385(condition=res)


class Resparams_with_umi_4388(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_with_umi_4388(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None]
) -> Resparams_with_umi_4388:
    cond = ((condition_4357 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"with_umi"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_with_umi_4388(
        res=out_channels.get("res")
    )


class Resconditional_params_with_umi_4389(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_with_umi_4389(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4388: typing.Union[str, None]
) -> Resconditional_params_with_umi_4389:
    cond = ((condition_4357 == True) and (channel_4388 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4388)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_with_umi_4389(condition=res)


class Resparams_bam_csi_index_4411(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_4411(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None]
) -> Resparams_bam_csi_index_4411:
    cond = ((condition_4357 == True) and (condition_4389 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_4411(
        res=out_channels.get("res")
    )


class Resconditional_params_bam_csi_index_4412(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bam_csi_index_4412(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4411: typing.Union[str, None]
) -> Resconditional_params_bam_csi_index_4412:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4411 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4411)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bam_csi_index_4412(condition=res)


class Res_hisat2_in_prepare_tool_indices__3785(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _hisat2_in_prepare_tool_indices__3785(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_hisat2_in_prepare_tool_indices__3785:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"hisat2"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_hisat2_in_prepare_tool_indices__3785(
        res=out_channels.get("res")
    )


class Res_hisat2_in_prepare_tool_indices__3786(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _hisat2_in_prepare_tool_indices__3786(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3785: typing.Union[str, None]
) -> Res_hisat2_in_prepare_tool_indices__3786:
    cond = ((channel_3785 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3785)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_hisat2_in_prepare_tool_indices__3786(
        res=out_channels.get("res")
    )


class Resconditional__hisat2_in_prepare_tool_indices__3787(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__hisat2_in_prepare_tool_indices__3787(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3786: typing.Union[str, None]
) -> Resconditional__hisat2_in_prepare_tool_indices__3787:
    cond = ((channel_3786 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3786)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__hisat2_in_prepare_tool_indices__3787(condition=res)


class Resparams_hisat2_index_3589(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_hisat2_index_3589(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_hisat2_index_3589:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"hisat2_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_hisat2_index_3589(
        res=out_channels.get("res")
    )


class Reshisat2_index_3798(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def hisat2_index_3798(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3589: typing.Union[str, None]
) -> Reshisat2_index_3798:
    cond = ((condition_3787 == True) and (channel_3589 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3589)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Reshisat2_index_3798(
        res=out_channels.get("res")
    )


class Resconditional_hisat2_index_3799(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_hisat2_index_3799(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3798: typing.Union[str, None]
) -> Resconditional_hisat2_index_3799:
    cond = ((condition_3787 == True) and (channel_3798 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3798)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_hisat2_index_3799(condition=res)


class Reshisat2_index_endsWith__tar_gz__3800(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def hisat2_index_endsWith__tar_gz__3800(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3589: typing.Union[str, None]
) -> Reshisat2_index_endsWith__tar_gz__3800:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (channel_3589 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3589)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"hisat2_index"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Reshisat2_index_endsWith__tar_gz__3800(
        res=out_channels.get("res")
    )


class Reshisat2_index_endsWith__tar_gz__3801(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def hisat2_index_endsWith__tar_gz__3801(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3800: typing.Union[str, None]
) -> Reshisat2_index_endsWith__tar_gz__3801:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (channel_3800 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3800)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Reshisat2_index_endsWith__tar_gz__3801(
        res=out_channels.get("res")
    )


class Resconditional_hisat2_index_endsWith__tar_gz__3802(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_hisat2_index_endsWith__tar_gz__3802(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3801: typing.Union[str, None]
) -> Resconditional_hisat2_index_endsWith__tar_gz__3802:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (channel_3801 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3801)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_hisat2_index_endsWith__tar_gz__3802(condition=res)


class Res______hisat2_index__3803(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______hisat2_index__3803(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    condition_3802: typing.Union[bool, None],
    channel_3589: typing.Union[str, None]
) -> Res______hisat2_index__3803:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (condition_3802 == True) and (channel_3589 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3589)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______hisat2_index__3803(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3804_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3803: str


class Res_3804_pre(NamedTuple):
    default: typing.List[Dataclass_3804_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_HISAT2_INDEX_3804_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    condition_3802: typing.Union[bool, None],
    channel_3803: typing.Union[str, None]
) -> Res_3804_pre:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (condition_3802 == True) and (channel_3803 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3804_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3803': channel_3803})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3804_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_HISAT2_INDEX_3804_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3804_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_HISAT2_INDEX_3804_post(
    default: List[Dataclass_3804_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_HISAT2_INDEX_3804_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_HISAT2_INDEX_3804_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3804_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3804_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3804_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3804_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3803)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_HISAT2_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_HISAT2_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_HISAT2_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_HISAT2_INDEX_3804(
    default: Dataclass_3804_pre
) -> Dataclass_3804_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3803)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_HISAT2_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_HISAT2_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_HISAT2_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3804_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3805(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3805(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    condition_3802: typing.Union[bool, None],
    channel_3804_0: typing.Union[str, None]
) -> Resmap_3805:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (condition_3802 == True) and (channel_3804_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3804_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3805(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_hisat2_index___3807(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_hisat2_index___3807(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    condition_3802: typing.Union[bool, None]
) -> ResChannel_value_this_file_hisat2_index___3807:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (condition_3802 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"hisat2_index"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_hisat2_index___3807(
        res=out_channels.get("res")
    )


class ResMerge_ch_hisat2_index_3808(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_hisat2_index_3808(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3805: typing.Union[str, None],
    channel_3807: typing.Union[str, None]
) -> ResMerge_ch_hisat2_index_3808:
    cond = ((condition_3787 == True) and (condition_3799 == True))

    if cond:
        res = { 'res': channel_3805 or channel_3807 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_hisat2_index_3808(
        res=res.get('res')
    )


class Resmap_3810(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3810(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_3810:
    cond = ((condition_3787 == True) and (condition_3799 == False) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3810(
        res=out_channels.get("res")
    )


class Resmap_3811(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3811(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Resmap_3811:
    cond = ((condition_3787 == True) and (condition_3799 == False) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3811(
        res=out_channels.get("res")
    )


class Resparams_splicesites_3583(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_splicesites_3583(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_splicesites_3583:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"splicesites"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_splicesites_3583(
        res=out_channels.get("res")
    )


class Ressplicesites_3788(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def splicesites_3788(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3583: typing.Union[str, None]
) -> Ressplicesites_3788:
    cond = ((condition_3787 == True) and (channel_3583 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3583)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Ressplicesites_3788(
        res=out_channels.get("res")
    )


class Ressplicesites_3789(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def splicesites_3789(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3788: typing.Union[str, None]
) -> Ressplicesites_3789:
    cond = ((condition_3787 == True) and (channel_3788 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3788)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Ressplicesites_3789(
        res=out_channels.get("res")
    )


class Resconditional_splicesites_3790(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_splicesites_3790(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3789: typing.Union[str, None]
) -> Resconditional_splicesites_3790:
    cond = ((condition_3787 == True) and (channel_3789 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3789)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_splicesites_3790(condition=res)


class Resmap_3791(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3791(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3790: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Resmap_3791:
    cond = ((condition_3787 == True) and (condition_3790 == True) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3791(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3792_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3791: str


class Res_3792_pre(NamedTuple):
    default: typing.List[Dataclass_3792_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_HISAT2_EXTRACTSPLICESITES_3792_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3790: typing.Union[bool, None],
    channel_3791: typing.Union[str, None]
) -> Res_3792_pre:
    cond = ((condition_3787 == True) and (condition_3790 == True) and (channel_3791 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3792_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3791': channel_3791})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3792_pre(default=result, is_skipped = not cond)

class Respost_adapter_HISAT2_EXTRACTSPLICESITES_3792_post(NamedTuple):
    txt: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3792_post:
    txt: str
    versions: str

@task(cache=True)
def post_adapter_HISAT2_EXTRACTSPLICESITES_3792_post(
    default: List[Dataclass_3792_post],
    is_skipped: bool,
) -> Respost_adapter_HISAT2_EXTRACTSPLICESITES_3792_post:
    return get_mapper_outputs(Respost_adapter_HISAT2_EXTRACTSPLICESITES_3792_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3792_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3792_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3792_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3792_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3791)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HISAT2_EXTRACTSPLICESITES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_EXTRACTSPLICESITES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_EXTRACTSPLICESITES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def HISAT2_EXTRACTSPLICESITES_3792(
    default: Dataclass_3792_pre
) -> Dataclass_3792_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3791)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HISAT2_EXTRACTSPLICESITES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_EXTRACTSPLICESITES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_EXTRACTSPLICESITES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3792_post(
        txt=out_channels.get(f"txt"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3793(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3793(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3790: typing.Union[bool, None],
    channel_3792_0: typing.Union[str, None]
) -> Resmap_3793:
    cond = ((condition_3787 == True) and (condition_3790 == True) and (channel_3792_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3792_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3793(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_splicesites___3795(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_splicesites___3795(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3790: typing.Union[bool, None]
) -> ResChannel_value_this_file_splicesites___3795:
    cond = ((condition_3787 == True) and (condition_3790 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"splicesites"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_splicesites___3795(
        res=out_channels.get("res")
    )


class ResMerge_ch_splicesites_3796(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_splicesites_3796(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3793: typing.Union[str, None],
    channel_3795: typing.Union[str, None]
) -> ResMerge_ch_splicesites_3796:
    cond = ((condition_3787 == True))

    if cond:
        res = { 'res': channel_3793 or channel_3795 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_splicesites_3796(
        res=res.get('res')
    )


class Resmap_3812(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3812(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3796: typing.Union[str, None]
) -> Resmap_3812:
    cond = ((condition_3787 == True) and (condition_3799 == False) and (channel_3796 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3796)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3812(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3813_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3810: str
    channel_3811: str
    channel_3812: str


class Res_3813_pre(NamedTuple):
    default: typing.List[Dataclass_3813_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_HISAT2_BUILD_3813_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3810: typing.Union[str, None],
    channel_3811: typing.Union[str, None],
    channel_3812: typing.Union[str, None]
) -> Res_3813_pre:
    cond = ((condition_3787 == True) and (condition_3799 == False) and (channel_3810 is not None) and (channel_3811 is not None) and (channel_3812 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3813_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3810': channel_3810, 'channel_3811': channel_3811, 'channel_3812': channel_3812})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3813_pre(default=result, is_skipped = not cond)

class Respost_adapter_HISAT2_BUILD_3813_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3813_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_HISAT2_BUILD_3813_post(
    default: List[Dataclass_3813_post],
    is_skipped: bool,
) -> Respost_adapter_HISAT2_BUILD_3813_post:
    return get_mapper_outputs(Respost_adapter_HISAT2_BUILD_3813_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3813_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3813_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3813_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3813_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3810),json.loads(default.channel_3811),json.loads(default.channel_3812)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HISAT2_BUILD","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_BUILD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_BUILD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def HISAT2_BUILD_3813(
    default: Dataclass_3813_pre
) -> Dataclass_3813_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3810),json.loads(default.channel_3811),json.loads(default.channel_3812)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HISAT2_BUILD","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_BUILD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_BUILD\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3813_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3814(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3814(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3813_0: typing.Union[str, None]
) -> Resmap_3814:
    cond = ((condition_3787 == True) and (condition_3799 == False) and (channel_3813_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3813_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3814(
        res=out_channels.get("res")
    )


class ResMerge_ch_hisat2_index_3816(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_hisat2_index_3816(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3808: typing.Union[str, None],
    channel_3814: typing.Union[str, None]
) -> ResMerge_ch_hisat2_index_3816:
    cond = ((condition_3787 == True))

    if cond:
        res = { 'res': channel_3808 or channel_3814 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_hisat2_index_3816(
        res=res.get('res')
    )


class ResChannel_empty___3784(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3784(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3784:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3784(
        res=out_channels.get("res")
    )


class ResMerge_ch_hisat2_index_3818(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_hisat2_index_3818(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3816: typing.Union[str, None],
    channel_3784: typing.Union[str, None]
) -> ResMerge_ch_hisat2_index_3818:
    cond = True

    if cond:
        res = { 'res': channel_3816 or channel_3784 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_hisat2_index_3818(
        res=res.get('res')
    )


class Resmap_4358(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4358(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_3818: typing.Union[str, None]
) -> Resmap_4358:
    cond = ((condition_4357 == True) and (channel_3818 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3818)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4358(
        res=out_channels.get("res")
    )


class ResChannel_empty___3783(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3783(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3783:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3783(
        res=out_channels.get("res")
    )


class ResMerge_ch_splicesites_3819(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_splicesites_3819(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3796: typing.Union[str, None],
    channel_3783: typing.Union[str, None]
) -> ResMerge_ch_splicesites_3819:
    cond = True

    if cond:
        res = { 'res': channel_3796 or channel_3783 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_splicesites_3819(
        res=res.get('res')
    )


class Resmap_4359(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4359(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_3819: typing.Union[str, None]
) -> Resmap_4359:
    cond = ((condition_4357 == True) and (channel_3819 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3819)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4359(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4362_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4091: str
    channel_4358: str
    channel_4359: str


class Res_4362_pre(NamedTuple):
    default: typing.List[Dataclass_4362_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_HISAT2_ALIGN_4362_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4091: typing.Union[str, None],
    channel_4358: typing.Union[str, None],
    channel_4359: typing.Union[str, None]
) -> Res_4362_pre:
    cond = ((condition_4357 == True) and (channel_4091 is not None) and (channel_4358 is not None) and (channel_4359 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4362_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4091': channel_4091, 'channel_4358': channel_4358, 'channel_4359': channel_4359})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4362_pre(default=result, is_skipped = not cond)

class Respost_adapter_HISAT2_ALIGN_4362_post(NamedTuple):
    bam: typing.Union[str, None]
    summary: typing.Union[str, None]
    fastq: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4362_post:
    bam: str
    summary: str
    fastq: str
    versions: str

@task(cache=True)
def post_adapter_HISAT2_ALIGN_4362_post(
    default: List[Dataclass_4362_post],
    is_skipped: bool,
) -> Respost_adapter_HISAT2_ALIGN_4362_post:
    return get_mapper_outputs(Respost_adapter_HISAT2_ALIGN_4362_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4362_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4362_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4362_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4362_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4358),json.loads(default.channel_4359)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_align_hisat2/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_ALIGN_HISAT2'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HISAT2_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def HISAT2_ALIGN_4362(
    default: Dataclass_4362_pre
) -> Dataclass_4362_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4358),json.loads(default.channel_4359)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/fastq_align_hisat2/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','FASTQ_ALIGN_HISAT2'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"HISAT2_ALIGN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fastq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"HISAT2_ALIGN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4362_post(
        bam=out_channels.get(f"bam"),
        summary=out_channels.get(f"summary"),
        fastq=out_channels.get(f"fastq"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4366_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4362_0: str


class Res_4366_pre(NamedTuple):
    default: typing.List[Dataclass_4366_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_4366_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4362_0: typing.Union[str, None]
) -> Res_4366_pre:
    cond = ((condition_4357 == True) and (channel_4362_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4366_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4362_0': channel_4362_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4366_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_4366_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4366_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_4366_post(
    default: List[Dataclass_4366_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_4366_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_4366_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4366_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4366_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4366_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4366_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4362_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_4366(
    default: Dataclass_4366_pre
) -> Dataclass_4366_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4362_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4366_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4369_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4366_0: str


class Res_4369_pre(NamedTuple):
    default: typing.List[Dataclass_4369_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4369_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4366_0: typing.Union[str, None]
) -> Res_4369_pre:
    cond = ((condition_4357 == True) and (channel_4366_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4369_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4366_0': channel_4366_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4369_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4369_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4369_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4369_post(
    default: List[Dataclass_4369_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4369_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4369_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4369_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4369_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4369_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4369_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4366_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4369(
    default: Dataclass_4369_pre
) -> Dataclass_4369_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4366_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4369_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_genome_bam_index_4386(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4386(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4369_1: typing.Union[str, None],
    channel_4369_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4386:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4369_1 or channel_4369_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4386(
        res=res.get('res')
    )


class Resjoin_4390(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4390(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4366_0: typing.Union[str, None],
    channel_4386: typing.Union[str, None]
) -> Resjoin_4390:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4366_0 is not None) and (channel_4386 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4366_0), json.loads(channel_4386)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4390(
        res=out_channels.get("res")
    )


class Resparams_umitools_dedup_stats_4391(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_umitools_dedup_stats_4391(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None]
) -> Resparams_umitools_dedup_stats_4391:
    cond = ((condition_4357 == True) and (condition_4389 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"umitools_dedup_stats"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_umitools_dedup_stats_4391(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4393_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4390: str
    channel_4391: str


class Res_4393_pre(NamedTuple):
    default: typing.List[Dataclass_4393_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UMITOOLS_DEDUP_4393_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4390: typing.Union[str, None],
    channel_4391: typing.Union[str, None]
) -> Res_4393_pre:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4390 is not None) and (channel_4391 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4393_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4390': channel_4390, 'channel_4391': channel_4391})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4393_pre(default=result, is_skipped = not cond)

class Respost_adapter_UMITOOLS_DEDUP_4393_post(NamedTuple):
    bam: typing.Union[str, None]
    log: typing.Union[str, None]
    tsv_edit_distance: typing.Union[str, None]
    tsv_per_umi: typing.Union[str, None]
    tsv_umi_per_position: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4393_post:
    bam: str
    log: str
    tsv_edit_distance: str
    tsv_per_umi: str
    tsv_umi_per_position: str
    versions: str

@task(cache=True)
def post_adapter_UMITOOLS_DEDUP_4393_post(
    default: List[Dataclass_4393_post],
    is_skipped: bool,
) -> Respost_adapter_UMITOOLS_DEDUP_4393_post:
    return get_mapper_outputs(Respost_adapter_UMITOOLS_DEDUP_4393_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4393_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4393_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4393_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4393_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4390),json.loads(default.channel_4391)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_DEDUP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_edit_distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_per_umi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_umi_per_position\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UMITOOLS_DEDUP_4393(
    default: Dataclass_4393_pre
) -> Dataclass_4393_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4390),json.loads(default.channel_4391)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_DEDUP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_edit_distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_per_umi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_umi_per_position\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4393_post(
        bam=out_channels.get(f"bam"),
        log=out_channels.get(f"log"),
        tsv_edit_distance=out_channels.get(f"tsv_edit_distance"),
        tsv_per_umi=out_channels.get(f"tsv_per_umi"),
        tsv_umi_per_position=out_channels.get(f"tsv_umi_per_position"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4396_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4393_0: str


class Res_4396_pre(NamedTuple):
    default: typing.List[Dataclass_4396_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4396_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4393_0: typing.Union[str, None]
) -> Res_4396_pre:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4393_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4396_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4393_0': channel_4393_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4396_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4396_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4396_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4396_post(
    default: List[Dataclass_4396_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4396_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4396_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4396_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4396_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4396_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4396_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4393_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4396(
    default: Dataclass_4396_pre
) -> Dataclass_4396_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4393_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4396_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class Resjoin_4399(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4399(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4393_0: typing.Union[str, None],
    channel_4396_0: typing.Union[str, None]
) -> Resjoin_4399:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4393_0 is not None) and (channel_4396_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4393_0), json.loads(channel_4396_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4399(
        res=out_channels.get("res")
    )


class Resjoin_4400(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4400(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4399: typing.Union[str, None],
    channel_4396_1: typing.Union[str, None]
) -> Resjoin_4400:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4399 is not None) and (channel_4396_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4399), json.loads(channel_4396_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4400(
        res=out_channels.get("res")
    )


class Resmap_4401(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4401(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4400: typing.Union[str, None]
) -> Resmap_4401:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4400 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4400)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4401(
        res=out_channels.get("res")
    )


class Res__________4402(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __________4402(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None]
) -> Res__________4402:
    cond = ((condition_4357 == True) and (condition_4389 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"MapExpression":[]},{"ListExpression":[]}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__________4402(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4404_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4401: str
    channel_4402: str


class Res_4404_pre(NamedTuple):
    default: typing.List[Dataclass_4404_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4404_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4401: typing.Union[str, None],
    channel_4402: typing.Union[str, None]
) -> Res_4404_pre:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4401 is not None) and (channel_4402 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4404_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4401': channel_4401, 'channel_4402': channel_4402})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4404_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4404_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4404_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4404_post(
    default: List[Dataclass_4404_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4404_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4404_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4404_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4404_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4404_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4404_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4401),json.loads(default.channel_4402)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4404(
    default: Dataclass_4404_pre
) -> Dataclass_4404_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4401),json.loads(default.channel_4402)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4404_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4406_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4401: str


class Res_4406_pre(NamedTuple):
    default: typing.List[Dataclass_4406_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4406_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4401: typing.Union[str, None]
) -> Res_4406_pre:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4401 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4406_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4401': channel_4401})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4406_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4406_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4406_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4406_post(
    default: List[Dataclass_4406_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4406_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4406_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4406_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4406_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4406_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4406_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4401)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4406(
    default: Dataclass_4406_pre
) -> Dataclass_4406_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4401)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4406_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4408_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4401: str


class Res_4408_pre(NamedTuple):
    default: typing.List[Dataclass_4408_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4408_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4401: typing.Union[str, None]
) -> Res_4408_pre:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4401 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4408_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4401': channel_4401})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4408_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4408_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4408_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4408_post(
    default: List[Dataclass_4408_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4408_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4408_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4408_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4408_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4408_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4408_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4401)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4408(
    default: Dataclass_4408_pre
) -> Dataclass_4408_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4401)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4408_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4392(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4392(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None]
) -> ResChannel_empty___4392:
    cond = ((condition_4357 == True) and (condition_4389 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4392(
        res=out_channels.get("res")
    )


class Resfirst_4394(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4394(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4393_5: typing.Union[str, None]
) -> Resfirst_4394:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4393_5 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4393_5)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4394(
        res=out_channels.get("res")
    )


class Resmix_4395(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4395(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4392: typing.Union[str, None],
    channel_4394: typing.Union[str, None]
) -> Resmix_4395:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4392 is not None) and (channel_4394 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4392), json.loads(channel_4394)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4395(
        res=out_channels.get("res")
    )


class Resfirst_4397(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4397(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4396_3: typing.Union[str, None]
) -> Resfirst_4397:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4396_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4396_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4397(
        res=out_channels.get("res")
    )


class Resmix_4398(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4398(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4395: typing.Union[str, None],
    channel_4397: typing.Union[str, None]
) -> Resmix_4398:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4395 is not None) and (channel_4397 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4395), json.loads(channel_4397)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4398(
        res=out_channels.get("res")
    )


class ResChannel_empty___4403(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4403(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None]
) -> ResChannel_empty___4403:
    cond = ((condition_4357 == True) and (condition_4389 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4403(
        res=out_channels.get("res")
    )


class Resmix_4405(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4405(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4403: typing.Union[str, None],
    channel_4404_1: typing.Union[str, None]
) -> Resmix_4405:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4403 is not None) and (channel_4404_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4403), json.loads(channel_4404_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4405(
        res=out_channels.get("res")
    )


class Resmix_4407(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4407(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4405: typing.Union[str, None],
    channel_4406_1: typing.Union[str, None]
) -> Resmix_4407:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4405 is not None) and (channel_4406_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4405), json.loads(channel_4406_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4407(
        res=out_channels.get("res")
    )


class Resmix_4409(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4409(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4407: typing.Union[str, None],
    channel_4408_1: typing.Union[str, None]
) -> Resmix_4409:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4407 is not None) and (channel_4408_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4407), json.loads(channel_4408_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4409(
        res=out_channels.get("res")
    )


class Resmix_4410(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4410(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4398: typing.Union[str, None],
    channel_4409: typing.Union[str, None]
) -> Resmix_4410:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4398 is not None) and (channel_4409 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4398), json.loads(channel_4409)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4410(
        res=out_channels.get("res")
    )


class ResMerge_ch_orig_bam_4128(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_orig_bam_4128(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_0: typing.Union[str, None],
    channel_4125_4: typing.Union[str, None]
) -> ResMerge_ch_orig_bam_4128:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_0 or channel_4125_4 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_orig_bam_4128(
        res=res.get('res')
    )


@dataclass
class Dataclass_4138_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4128: str


class Res_4138_pre(NamedTuple):
    default: typing.List[Dataclass_4138_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_4138_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4128: typing.Union[str, None]
) -> Res_4138_pre:
    cond = ((condition_4104 == True) and (channel_4128 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4138_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4128': channel_4128})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4138_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_4138_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4138_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_4138_post(
    default: List[Dataclass_4138_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_4138_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_4138_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4138_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4138_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4138_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4138_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4128)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_4138(
    default: Dataclass_4138_pre
) -> Dataclass_4138_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4128)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4138_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4141_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4138_0: str


class Res_4141_pre(NamedTuple):
    default: typing.List[Dataclass_4141_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4141_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4138_0: typing.Union[str, None]
) -> Res_4141_pre:
    cond = ((condition_4104 == True) and (channel_4138_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4141_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4138_0': channel_4138_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4141_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4141_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4141_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4141_post(
    default: List[Dataclass_4141_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4141_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4141_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4141_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4141_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4141_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4141_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4138_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4141(
    default: Dataclass_4141_pre
) -> Dataclass_4141_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4138_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4141_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_genome_bam_index_4158(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4158(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4141_1: typing.Union[str, None],
    channel_4141_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4158:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4141_1 or channel_4141_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4158(
        res=res.get('res')
    )


class Resjoin_4162(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4162(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4138_0: typing.Union[str, None],
    channel_4158: typing.Union[str, None]
) -> Resjoin_4162:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4138_0 is not None) and (channel_4158 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4138_0), json.loads(channel_4158)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4162(
        res=out_channels.get("res")
    )


class Resparams_umitools_dedup_stats_4163(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_umitools_dedup_stats_4163(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> Resparams_umitools_dedup_stats_4163:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"umitools_dedup_stats"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_umitools_dedup_stats_4163(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4165_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4162: str
    channel_4163: str


class Res_4165_pre(NamedTuple):
    default: typing.List[Dataclass_4165_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UMITOOLS_DEDUP_4165_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4162: typing.Union[str, None],
    channel_4163: typing.Union[str, None]
) -> Res_4165_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4162 is not None) and (channel_4163 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4165_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4162': channel_4162, 'channel_4163': channel_4163})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4165_pre(default=result, is_skipped = not cond)

class Respost_adapter_UMITOOLS_DEDUP_4165_post(NamedTuple):
    bam: typing.Union[str, None]
    log: typing.Union[str, None]
    tsv_edit_distance: typing.Union[str, None]
    tsv_per_umi: typing.Union[str, None]
    tsv_umi_per_position: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4165_post:
    bam: str
    log: str
    tsv_edit_distance: str
    tsv_per_umi: str
    tsv_umi_per_position: str
    versions: str

@task(cache=True)
def post_adapter_UMITOOLS_DEDUP_4165_post(
    default: List[Dataclass_4165_post],
    is_skipped: bool,
) -> Respost_adapter_UMITOOLS_DEDUP_4165_post:
    return get_mapper_outputs(Respost_adapter_UMITOOLS_DEDUP_4165_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4165_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4165_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4165_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4165_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4162),json.loads(default.channel_4163)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_DEDUP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_edit_distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_per_umi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_umi_per_position\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UMITOOLS_DEDUP_4165(
    default: Dataclass_4165_pre
) -> Dataclass_4165_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4162),json.loads(default.channel_4163)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UMITOOLS_DEDUP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_edit_distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_per_umi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv_umi_per_position\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UMITOOLS_DEDUP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4165_post(
        bam=out_channels.get(f"bam"),
        log=out_channels.get(f"log"),
        tsv_edit_distance=out_channels.get(f"tsv_edit_distance"),
        tsv_per_umi=out_channels.get(f"tsv_per_umi"),
        tsv_umi_per_position=out_channels.get(f"tsv_umi_per_position"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4168_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4165_0: str


class Res_4168_pre(NamedTuple):
    default: typing.List[Dataclass_4168_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4168_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4165_0: typing.Union[str, None]
) -> Res_4168_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4165_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4168_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4165_0': channel_4165_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4168_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4168_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4168_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4168_post(
    default: List[Dataclass_4168_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4168_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4168_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4168_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4168_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4168_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4168_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4165_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4168(
    default: Dataclass_4168_pre
) -> Dataclass_4168_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4165_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4168_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class Resjoin_4171(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4171(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4165_0: typing.Union[str, None],
    channel_4168_0: typing.Union[str, None]
) -> Resjoin_4171:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4165_0 is not None) and (channel_4168_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4165_0), json.loads(channel_4168_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4171(
        res=out_channels.get("res")
    )


class Resjoin_4172(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4172(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4171: typing.Union[str, None],
    channel_4168_1: typing.Union[str, None]
) -> Resjoin_4172:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4171 is not None) and (channel_4168_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4171), json.loads(channel_4168_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4172(
        res=out_channels.get("res")
    )


class Resmap_4173(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4173(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4172: typing.Union[str, None]
) -> Resmap_4173:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4172 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4172)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4173(
        res=out_channels.get("res")
    )


class Res__________4174(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __________4174(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> Res__________4174:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"MapExpression":[]},{"ListExpression":[]}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__________4174(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4176_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4173: str
    channel_4174: str


class Res_4176_pre(NamedTuple):
    default: typing.List[Dataclass_4176_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4176_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4173: typing.Union[str, None],
    channel_4174: typing.Union[str, None]
) -> Res_4176_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4173 is not None) and (channel_4174 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4176_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4173': channel_4173, 'channel_4174': channel_4174})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4176_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4176_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4176_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4176_post(
    default: List[Dataclass_4176_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4176_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4176_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4176_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4176_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4176_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4176_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4173),json.loads(default.channel_4174)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4176(
    default: Dataclass_4176_pre
) -> Dataclass_4176_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4173),json.loads(default.channel_4174)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4176_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4178_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4173: str


class Res_4178_pre(NamedTuple):
    default: typing.List[Dataclass_4178_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4178_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4173: typing.Union[str, None]
) -> Res_4178_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4173 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4178_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4173': channel_4173})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4178_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4178_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4178_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4178_post(
    default: List[Dataclass_4178_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4178_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4178_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4178_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4178_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4178_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4178_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4173)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4178(
    default: Dataclass_4178_pre
) -> Dataclass_4178_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4173)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4178_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


@dataclass
class Dataclass_4180_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4173: str


class Res_4180_pre(NamedTuple):
    default: typing.List[Dataclass_4180_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4180_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4173: typing.Union[str, None]
) -> Res_4180_pre:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4173 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4180_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4173': channel_4173})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4180_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4180_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4180_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4180_post(
    default: List[Dataclass_4180_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4180_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4180_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4180_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4180_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4180_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4180_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4173)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4180(
    default: Dataclass_4180_pre
) -> Dataclass_4180_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4173)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4180_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4164(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4164(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> ResChannel_empty___4164:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4164(
        res=out_channels.get("res")
    )


class Resfirst_4166(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4166(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4165_5: typing.Union[str, None]
) -> Resfirst_4166:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4165_5 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4165_5)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4166(
        res=out_channels.get("res")
    )


class Resmix_4167(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4167(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4164: typing.Union[str, None],
    channel_4166: typing.Union[str, None]
) -> Resmix_4167:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4164 is not None) and (channel_4166 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4164), json.loads(channel_4166)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4167(
        res=out_channels.get("res")
    )


class Resfirst_4169(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4169(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4168_3: typing.Union[str, None]
) -> Resfirst_4169:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4168_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4168_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4169(
        res=out_channels.get("res")
    )


class Resmix_4170(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4170(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4167: typing.Union[str, None],
    channel_4169: typing.Union[str, None]
) -> Resmix_4170:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4167 is not None) and (channel_4169 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4167), json.loads(channel_4169)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4170(
        res=out_channels.get("res")
    )


class ResChannel_empty___4175(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4175(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None]
) -> ResChannel_empty___4175:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4175(
        res=out_channels.get("res")
    )


class Resmix_4177(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4177(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4175: typing.Union[str, None],
    channel_4176_1: typing.Union[str, None]
) -> Resmix_4177:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4175 is not None) and (channel_4176_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4175), json.loads(channel_4176_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4177(
        res=out_channels.get("res")
    )


class Resmix_4179(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4179(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4177: typing.Union[str, None],
    channel_4178_1: typing.Union[str, None]
) -> Resmix_4179:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4177 is not None) and (channel_4178_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4177), json.loads(channel_4178_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4179(
        res=out_channels.get("res")
    )


class Resmix_4181(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4181(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4179: typing.Union[str, None],
    channel_4180_1: typing.Union[str, None]
) -> Resmix_4181:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4179 is not None) and (channel_4180_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4179), json.loads(channel_4180_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4181(
        res=out_channels.get("res")
    )


class Resmix_4182(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4182(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4170: typing.Union[str, None],
    channel_4181: typing.Union[str, None]
) -> Resmix_4182:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4170 is not None) and (channel_4181 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4170), json.loads(channel_4181)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_dedup_stats_samtools_umitools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4182(
        res=out_channels.get("res")
    )


class ResMerge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4419(NamedTuple):
    bam: typing.Union[str, None]
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    stats: typing.Union[str, None]
    flagstat: typing.Union[str, None]
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@task(cache=True)
def Merge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4419(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4393_0: typing.Union[str, None],
    channel_4396_0: typing.Union[str, None],
    channel_4396_1: typing.Union[str, None],
    channel_4404_0: typing.Union[str, None],
    channel_4406_0: typing.Union[str, None],
    channel_4408_0: typing.Union[str, None],
    channel_4410: typing.Union[str, None],
    channel_4165_0: typing.Union[str, None],
    channel_4168_0: typing.Union[str, None],
    channel_4168_1: typing.Union[str, None],
    channel_4176_0: typing.Union[str, None],
    channel_4178_0: typing.Union[str, None],
    channel_4180_0: typing.Union[str, None],
    channel_4182: typing.Union[str, None]
) -> ResMerge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4419:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'bam': channel_4393_0 or channel_4165_0, 'bai': channel_4396_0 or channel_4168_0, 'csi': channel_4396_1 or channel_4168_1, 'stats': channel_4404_0 or channel_4176_0, 'flagstat': channel_4406_0 or channel_4178_0, 'idxstats': channel_4408_0 or channel_4180_0, 'res': channel_4410 or channel_4182 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4419(
        bam=res.get('bam'),
        bai=res.get('bai'),
        csi=res.get('csi'),
        stats=res.get('stats'),
        flagstat=res.get('flagstat'),
        idxstats=res.get('idxstats'),
        versions=res.get('versions')
    )


class ResMerge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4427(NamedTuple):
    bam: typing.Union[str, None]
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    stats: typing.Union[str, None]
    flagstat: typing.Union[str, None]
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@task(cache=True)
def Merge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4427(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4419_0: typing.Union[str, None],
    channel_4419_1: typing.Union[str, None],
    channel_4165_0: typing.Union[str, None],
    channel_4168_0: typing.Union[str, None],
    channel_4168_1: typing.Union[str, None],
    channel_4176_0: typing.Union[str, None],
    channel_4178_0: typing.Union[str, None],
    channel_4180_0: typing.Union[str, None],
    channel_4182: typing.Union[str, None]
) -> ResMerge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4427:
    cond = True

    if cond:
        res = { 'bam': channel_4419_0 or channel_4419_0 or channel_4419_0 or channel_4419_0 or channel_4419_0 or channel_4419_0 or channel_4165_0, 'bai': channel_4419_1 or channel_4168_0, 'csi': channel_4168_1, 'stats': channel_4176_0, 'flagstat': channel_4178_0, 'idxstats': channel_4180_0, 'res': channel_4182 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_BAM_DEDUP_STATS_SAMTOOLS_UMITOOLS_GENOME_4427(
        bam=res.get('bam'),
        bai=res.get('bai'),
        csi=res.get('csi'),
        stats=res.get('stats'),
        flagstat=res.get('flagstat'),
        idxstats=res.get('idxstats'),
        versions=res.get('versions')
    )


class Resparams_skip_alignment_4461(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4461(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4461:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4461(
        res=out_channels.get("res")
    )


class Resparams_skip_markduplicates_4462(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_markduplicates_4462(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_markduplicates_4462:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_markduplicates"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_markduplicates_4462(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_markduplicates__4463(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_markduplicates__4463(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4461: typing.Union[str, None],
    channel_4462: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_markduplicates__4463:
    cond = ((channel_4461 is not None) and (channel_4462 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4461), json.loads(channel_4462)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_markduplicates__4463(
        res=out_channels.get("res")
    )


class Resparams_with_umi_4464(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_with_umi_4464(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_with_umi_4464:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"with_umi"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_with_umi_4464(
        res=out_channels.get("res")
    )


class Res__params_skip_alignment____params_skip_markduplicates_____params_4465(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_skip_alignment____params_skip_markduplicates_____params_4465(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4463: typing.Union[str, None],
    channel_4464: typing.Union[str, None]
) -> Res__params_skip_alignment____params_skip_markduplicates_____params_4465:
    cond = ((channel_4463 is not None) and (channel_4464 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4463), json.loads(channel_4464)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_skip_alignment____params_skip_markduplicates_____params_4465(
        res=out_channels.get("res")
    )


class Res__params_skip_alignment____params_skip_markduplicates_____params_4466(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_skip_alignment____params_skip_markduplicates_____params_4466(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4465: typing.Union[str, None]
) -> Res__params_skip_alignment____params_skip_markduplicates_____params_4466:
    cond = ((channel_4465 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4465)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_skip_alignment____params_skip_markduplicates_____params_4466(
        res=out_channels.get("res")
    )


class Resconditional___params_skip_alignment____params_skip_markduplicates_____params_4467(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional___params_skip_alignment____params_skip_markduplicates_____params_4467(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4466: typing.Union[str, None]
) -> Resconditional___params_skip_alignment____params_skip_markduplicates_____params_4467:
    cond = ((channel_4466 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4466)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional___params_skip_alignment____params_skip_markduplicates_____params_4467(condition=res)


class Resparams_bam_csi_index_4488(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_bam_csi_index_4488(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None]
) -> Resparams_bam_csi_index_4488:
    cond = ((condition_4467 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"bam_csi_index"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_bam_csi_index_4488(
        res=out_channels.get("res")
    )


class Resconditional_params_bam_csi_index_4489(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_bam_csi_index_4489(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4488: typing.Union[str, None]
) -> Resconditional_params_bam_csi_index_4489:
    cond = ((condition_4467 == True) and (channel_4488 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4488)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_bam_csi_index_4489(condition=res)


class Resparams_skip_alignment_4530(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4530(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4530:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4530(
        res=out_channels.get("res")
    )


class Resparams_skip_bigwig_4531(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_bigwig_4531(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_bigwig_4531:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_bigwig"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_bigwig_4531(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_bigwig__4532(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_bigwig__4532(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4530: typing.Union[str, None],
    channel_4531: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_bigwig__4532:
    cond = ((channel_4530 is not None) and (channel_4531 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4530), json.loads(channel_4531)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_bigwig__4532(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_bigwig__4533(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_bigwig__4533(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4532: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_bigwig__4533:
    cond = ((channel_4532 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4532)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_bigwig__4533(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment____params_skip_bigwig__4534(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment____params_skip_bigwig__4534(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4533: typing.Union[str, None]
) -> Resconditional__params_skip_alignment____params_skip_bigwig__4534:
    cond = ((channel_4533 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4533)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment____params_skip_bigwig__4534(condition=res)


class ResChannel_empty___4546(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4546(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None]
) -> ResChannel_empty___4546:
    cond = ((condition_4534 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4546(
        res=out_channels.get("res")
    )


class Resparams_skip_alignment_4431(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4431(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4431:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4431(
        res=out_channels.get("res")
    )


class Resparams_aligner_contains_star__4432(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_aligner_contains_star__4432(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_aligner_contains_star__4432:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"aligner"}},"method":"contains","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"star"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_aligner_contains_star__4432(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_aligner_contains_star___4433(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_aligner_contains_star___4433(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4431: typing.Union[str, None],
    channel_4432: typing.Union[str, None]
) -> Res_params_skip_alignment____params_aligner_contains_star___4433:
    cond = ((channel_4431 is not None) and (channel_4432 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4431), json.loads(channel_4432)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_aligner_contains_star___4433(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_aligner_contains_star___4434(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_aligner_contains_star___4434(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4433: typing.Union[str, None]
) -> Res_params_skip_alignment____params_aligner_contains_star___4434:
    cond = ((channel_4433 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4433)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_aligner_contains_star___4434(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment____params_aligner_contains_star___4435(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment____params_aligner_contains_star___4435(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4434: typing.Union[str, None]
) -> Resconditional__params_skip_alignment____params_aligner_contains_star___4435:
    cond = ((channel_4434 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4434)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment____params_aligner_contains_star___4435(condition=res)


class ResMerge_ch_genome_bam_4415(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4415(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4393_0: typing.Union[str, None],
    channel_4366_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4415:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4393_0 or channel_4366_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4415(
        res=res.get('res')
    )


class Res_star_rsem_in_prepare_tool_indices__3762(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _star_rsem_in_prepare_tool_indices__3762(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Res_star_rsem_in_prepare_tool_indices__3762:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"star_rsem"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_star_rsem_in_prepare_tool_indices__3762(
        res=out_channels.get("res")
    )


class Res_star_rsem_in_prepare_tool_indices__3763(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _star_rsem_in_prepare_tool_indices__3763(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3762: typing.Union[str, None]
) -> Res_star_rsem_in_prepare_tool_indices__3763:
    cond = ((channel_3762 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3762)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_star_rsem_in_prepare_tool_indices__3763(
        res=out_channels.get("res")
    )


class Resconditional__star_rsem_in_prepare_tool_indices__3764(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__star_rsem_in_prepare_tool_indices__3764(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3763: typing.Union[str, None]
) -> Resconditional__star_rsem_in_prepare_tool_indices__3764:
    cond = ((channel_3763 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3763)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__star_rsem_in_prepare_tool_indices__3764(condition=res)


class Resparams_rsem_index_3586(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_rsem_index_3586(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_rsem_index_3586:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"rsem_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_rsem_index_3586(
        res=out_channels.get("res")
    )


class Resrsem_index_3765(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def rsem_index_3765(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    channel_3586: typing.Union[str, None]
) -> Resrsem_index_3765:
    cond = ((condition_3764 == True) and (channel_3586 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3586)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resrsem_index_3765(
        res=out_channels.get("res")
    )


class Resconditional_rsem_index_3766(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_rsem_index_3766(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    channel_3765: typing.Union[str, None]
) -> Resconditional_rsem_index_3766:
    cond = ((condition_3764 == True) and (channel_3765 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3765)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_rsem_index_3766(condition=res)


class Resrsem_index_endsWith__tar_gz__3767(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def rsem_index_endsWith__tar_gz__3767(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3586: typing.Union[str, None]
) -> Resrsem_index_endsWith__tar_gz__3767:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (channel_3586 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3586)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"rsem_index"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resrsem_index_endsWith__tar_gz__3767(
        res=out_channels.get("res")
    )


class Resrsem_index_endsWith__tar_gz__3768(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def rsem_index_endsWith__tar_gz__3768(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3767: typing.Union[str, None]
) -> Resrsem_index_endsWith__tar_gz__3768:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (channel_3767 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3767)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resrsem_index_endsWith__tar_gz__3768(
        res=out_channels.get("res")
    )


class Resconditional_rsem_index_endsWith__tar_gz__3769(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_rsem_index_endsWith__tar_gz__3769(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3768: typing.Union[str, None]
) -> Resconditional_rsem_index_endsWith__tar_gz__3769:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (channel_3768 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3768)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_rsem_index_endsWith__tar_gz__3769(condition=res)


class Res______rsem_index__3770(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______rsem_index__3770(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    condition_3769: typing.Union[bool, None],
    channel_3586: typing.Union[str, None]
) -> Res______rsem_index__3770:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (condition_3769 == True) and (channel_3586 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3586)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______rsem_index__3770(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3771_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3770: str


class Res_3771_pre(NamedTuple):
    default: typing.List[Dataclass_3771_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_RSEM_INDEX_3771_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    condition_3769: typing.Union[bool, None],
    channel_3770: typing.Union[str, None]
) -> Res_3771_pre:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (condition_3769 == True) and (channel_3770 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3771_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3770': channel_3770})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3771_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_RSEM_INDEX_3771_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3771_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_RSEM_INDEX_3771_post(
    default: List[Dataclass_3771_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_RSEM_INDEX_3771_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_RSEM_INDEX_3771_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3771_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3771_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3771_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3771_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3770)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_RSEM_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_RSEM_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_RSEM_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_RSEM_INDEX_3771(
    default: Dataclass_3771_pre
) -> Dataclass_3771_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3770)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_RSEM_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_RSEM_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_RSEM_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3771_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3772(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3772(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    condition_3769: typing.Union[bool, None],
    channel_3771_0: typing.Union[str, None]
) -> Resmap_3772:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (condition_3769 == True) and (channel_3771_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3771_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3772(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_rsem_index___3774(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_rsem_index___3774(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    condition_3769: typing.Union[bool, None]
) -> ResChannel_value_this_file_rsem_index___3774:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (condition_3769 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"rsem_index"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_rsem_index___3774(
        res=out_channels.get("res")
    )


class ResMerge_ch_rsem_index_3775(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_rsem_index_3775(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3772: typing.Union[str, None],
    channel_3774: typing.Union[str, None]
) -> ResMerge_ch_rsem_index_3775:
    cond = ((condition_3764 == True) and (condition_3766 == True))

    if cond:
        res = { 'res': channel_3772 or channel_3774 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_rsem_index_3775(
        res=res.get('res')
    )


@dataclass
class Dataclass_3777_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3658: str
    channel_3656: str


class Res_3777_pre(NamedTuple):
    default: typing.List[Dataclass_3777_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEM_PREPAREREFERENCE_GENOME_3777_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3658: typing.Union[str, None],
    channel_3656: typing.Union[str, None]
) -> Res_3777_pre:
    cond = ((condition_3764 == True) and (condition_3766 == False) and (channel_3658 is not None) and (channel_3656 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3777_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3658': channel_3658, 'channel_3656': channel_3656})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3777_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEM_PREPAREREFERENCE_GENOME_3777_post(NamedTuple):
    index: typing.Union[str, None]
    transcript_fasta: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3777_post:
    index: str
    transcript_fasta: str
    versions: str

@task(cache=True)
def post_adapter_RSEM_PREPAREREFERENCE_GENOME_3777_post(
    default: List[Dataclass_3777_post],
    is_skipped: bool,
) -> Respost_adapter_RSEM_PREPAREREFERENCE_GENOME_3777_post:
    return get_mapper_outputs(Respost_adapter_RSEM_PREPAREREFERENCE_GENOME_3777_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3777_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3777_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3777_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3777_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3656)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEM_PREPAREREFERENCE_GENOME","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_PREPAREREFERENCE_GENOME\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"transcript_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_PREPAREREFERENCE_GENOME\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_PREPAREREFERENCE_GENOME\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEM_PREPAREREFERENCE_GENOME_3777(
    default: Dataclass_3777_pre
) -> Dataclass_3777_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3658),json.loads(default.channel_3656)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEM_PREPAREREFERENCE_GENOME","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_PREPAREREFERENCE_GENOME\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"transcript_fasta\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_PREPAREREFERENCE_GENOME\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_PREPAREREFERENCE_GENOME\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3777_post(
        index=out_channels.get(f"index"),
        transcript_fasta=out_channels.get(f"transcript_fasta"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_rsem_index_3779(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_rsem_index_3779(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    channel_3775: typing.Union[str, None],
    channel_3777_0: typing.Union[str, None]
) -> ResMerge_ch_rsem_index_3779:
    cond = ((condition_3764 == True))

    if cond:
        res = { 'res': channel_3775 or channel_3777_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_rsem_index_3779(
        res=res.get('res')
    )


class ResChannel_empty___3761(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3761(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3761:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3761(
        res=out_channels.get("res")
    )


class ResMerge_ch_rsem_index_3781(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_rsem_index_3781(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3779: typing.Union[str, None],
    channel_3761: typing.Union[str, None]
) -> ResMerge_ch_rsem_index_3781:
    cond = True

    if cond:
        res = { 'res': channel_3779 or channel_3761 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_rsem_index_3781(
        res=res.get('res')
    )


@dataclass
class Dataclass_4302_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4091: str
    channel_3781: str


class Res_4302_pre(NamedTuple):
    default: typing.List[Dataclass_4302_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEM_CALCULATEEXPRESSION_4302_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4091: typing.Union[str, None],
    channel_3781: typing.Union[str, None]
) -> Res_4302_pre:
    cond = ((condition_4299 == True) and (channel_4091 is not None) and (channel_3781 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4302_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4091': channel_4091, 'channel_3781': channel_3781})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4302_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEM_CALCULATEEXPRESSION_4302_post(NamedTuple):
    counts_gene: typing.Union[str, None]
    counts_transcript: typing.Union[str, None]
    stat: typing.Union[str, None]
    logs: typing.Union[str, None]
    versions: typing.Union[str, None]
    bam_star: typing.Union[str, None]
    bam_genome: typing.Union[str, None]
    bam_transcript: typing.Union[str, None]

@dataclass
class Dataclass_4302_post:
    counts_gene: str
    counts_transcript: str
    stat: str
    logs: str
    versions: str
    bam_star: str
    bam_genome: str
    bam_transcript: str

@task(cache=True)
def post_adapter_RSEM_CALCULATEEXPRESSION_4302_post(
    default: List[Dataclass_4302_post],
    is_skipped: bool,
) -> Respost_adapter_RSEM_CALCULATEEXPRESSION_4302_post:
    return get_mapper_outputs(Respost_adapter_RSEM_CALCULATEEXPRESSION_4302_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4302_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4302_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4302_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4302_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_3781)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_rsem/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_RSEM'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEM_CALCULATEEXPRESSION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"logs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_star\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_genome\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEM_CALCULATEEXPRESSION_4302(
    default: Dataclass_4302_pre
) -> Dataclass_4302_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_3781)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_rsem/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_RSEM'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEM_CALCULATEEXPRESSION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"logs\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_star\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_genome\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_CALCULATEEXPRESSION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4302_post(
        counts_gene=out_channels.get(f"counts_gene"),
        counts_transcript=out_channels.get(f"counts_transcript"),
        stat=out_channels.get(f"stat"),
        logs=out_channels.get(f"logs"),
        versions=out_channels.get(f"versions"),
        bam_star=out_channels.get(f"bam_star"),
        bam_genome=out_channels.get(f"bam_genome"),
        bam_transcript=out_channels.get(f"bam_transcript")
    )


@dataclass
class Dataclass_4306_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4302_5: str


class Res_4306_pre(NamedTuple):
    default: typing.List[Dataclass_4306_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_SORT_4306_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4302_5: typing.Union[str, None]
) -> Res_4306_pre:
    cond = ((condition_4299 == True) and (channel_4302_5 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4306_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4302_5': channel_4302_5})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4306_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_SORT_4306_post(NamedTuple):
    bam: typing.Union[str, None]
    csi: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4306_post:
    bam: str
    csi: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_SORT_4306_post(
    default: List[Dataclass_4306_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_SORT_4306_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_SORT_4306_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4306_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4306_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4306_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4306_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4302_5)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_SORT_4306(
    default: Dataclass_4306_pre
) -> Dataclass_4306_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4302_5)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_SORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_SORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4306_post(
        bam=out_channels.get(f"bam"),
        csi=out_channels.get(f"csi"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_genome_bam_4236(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4236(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4165_0: typing.Union[str, None],
    channel_4138_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4236:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4165_0 or channel_4138_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4236(
        res=res.get('res')
    )


class ResChannel_empty___4092(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4092(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4092:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4092(
        res=out_channels.get("res")
    )


class ResMerge_ch_genome_bam_4291(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4291(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4236: typing.Union[str, None],
    channel_4092: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4291:
    cond = True

    if cond:
        res = { 'res': channel_4236 or channel_4092 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4291(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_4343(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4343(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4306_0: typing.Union[str, None],
    channel_4291: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4343:
    cond = True

    if cond:
        res = { 'res': channel_4306_0 or channel_4291 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4343(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_4422(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4422(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4415: typing.Union[str, None],
    channel_4343: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4422:
    cond = True

    if cond:
        res = { 'res': channel_4415 or channel_4343 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4422(
        res=res.get('res')
    )


class ResMerge_ch_log_final_4132(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_log_final_4132(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4122_1: typing.Union[str, None],
    channel_4125_0: typing.Union[str, None]
) -> ResMerge_ch_log_final_4132:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4122_1 or channel_4125_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_log_final_4132(
        res=res.get('res')
    )


class ResChannel_empty___4097(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4097(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4097:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4097(
        res=out_channels.get("res")
    )


class ResMerge_ch_star_multiqc_4289(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_star_multiqc_4289(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4132: typing.Union[str, None],
    channel_4097: typing.Union[str, None]
) -> ResMerge_ch_star_multiqc_4289:
    cond = True

    if cond:
        res = { 'res': channel_4132 or channel_4097 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_star_multiqc_4289(
        res=res.get('res')
    )


class ResMerge_ch_star_multiqc_4350(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_star_multiqc_4350(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4302_3: typing.Union[str, None],
    channel_4289: typing.Union[str, None]
) -> ResMerge_ch_star_multiqc_4350:
    cond = True

    if cond:
        res = { 'res': channel_4302_3 or channel_4289 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_star_multiqc_4350(
        res=res.get('res')
    )


class Resmap_4436(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4436(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4350: typing.Union[str, None]
) -> Resmap_4436:
    cond = ((condition_4435 == True) and (channel_4350 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4350)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"ListExpression":[{"VariableExpression":"meta"}]},"operation":"+","rightExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"getStarPercentMapped","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"params"},{"VariableExpression":"align_log"}]}}}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["params"]},"labels":[]}},"parameters":["meta","align_log"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4436(
        res=out_channels.get("res")
    )


class Resjoin_4437(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4437(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4422: typing.Union[str, None],
    channel_4436: typing.Union[str, None]
) -> Resjoin_4437:
    cond = ((condition_4435 == True) and (channel_4422 is not None) and (channel_4436 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4422), json.loads(channel_4436)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4437(
        res=out_channels.get("res")
    )


class Resmap_4438(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4438(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4437: typing.Union[str, None]
) -> Resmap_4438:
    cond = ((condition_4435 == True) and (channel_4437 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4437)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"pass"}},"ifBlock":{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"ofile"}]}},"elseBlock":{"ReturnStatement":{"ConstantExpression":null}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","ofile","mapped","pass"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4438(
        res=out_channels.get("res")
    )


class ResMerge_ch_genome_bam_4444(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4444(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4438: typing.Union[str, None],
    channel_4422: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4444:
    cond = True

    if cond:
        res = { 'res': channel_4438 or channel_4422 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4444(
        res=res.get('res')
    )


class Resmap_4468(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4468(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_4468:
    cond = ((condition_4467 == True) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4468(
        res=out_channels.get("res")
    )


class Resmap_4469(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4469(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_3699: typing.Union[str, None]
) -> Resmap_4469:
    cond = ((condition_4467 == True) and (channel_3699 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3699)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4469(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4471_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4444: str
    channel_4468: str
    channel_4469: str


class Res_4471_pre(NamedTuple):
    default: typing.List[Dataclass_4471_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_PICARD_MARKDUPLICATES_4471_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4444: typing.Union[str, None],
    channel_4468: typing.Union[str, None],
    channel_4469: typing.Union[str, None]
) -> Res_4471_pre:
    cond = ((condition_4467 == True) and (channel_4444 is not None) and (channel_4468 is not None) and (channel_4469 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4471_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4444': channel_4444, 'channel_4468': channel_4468, 'channel_4469': channel_4469})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4471_pre(default=result, is_skipped = not cond)

class Respost_adapter_PICARD_MARKDUPLICATES_4471_post(NamedTuple):
    bam: typing.Union[str, None]
    bai: typing.Union[str, None]
    metrics: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4471_post:
    bam: str
    bai: str
    metrics: str
    versions: str

@task(cache=True)
def post_adapter_PICARD_MARKDUPLICATES_4471_post(
    default: List[Dataclass_4471_post],
    is_skipped: bool,
) -> Respost_adapter_PICARD_MARKDUPLICATES_4471_post:
    return get_mapper_outputs(Respost_adapter_PICARD_MARKDUPLICATES_4471_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4471_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4471_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4471_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4471_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4444),json.loads(default.channel_4468),json.loads(default.channel_4469)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_MARKDUPLICATES_PICARD'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PICARD_MARKDUPLICATES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"metrics\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def PICARD_MARKDUPLICATES_4471(
    default: Dataclass_4471_pre
) -> Dataclass_4471_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4444),json.loads(default.channel_4468),json.loads(default.channel_4469)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_MARKDUPLICATES_PICARD'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PICARD_MARKDUPLICATES","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bam\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"metrics\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PICARD_MARKDUPLICATES\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4471_post(
        bam=out_channels.get(f"bam"),
        bai=out_channels.get(f"bai"),
        metrics=out_channels.get(f"metrics"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_genome_bam_4492(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_4492(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4471_0: typing.Union[str, None],
    channel_4444: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_4492:
    cond = True

    if cond:
        res = { 'res': channel_4471_0 or channel_4444 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_4492(
        res=res.get('res')
    )


@dataclass
class Dataclass_4535_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4492: str


class Res_4535_pre(NamedTuple):
    default: typing.List[Dataclass_4535_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_BEDTOOLS_GENOMECOV_4535_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4492: typing.Union[str, None]
) -> Res_4535_pre:
    cond = ((condition_4534 == True) and (channel_4492 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4535_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4492': channel_4492})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4535_pre(default=result, is_skipped = not cond)

class Respost_adapter_BEDTOOLS_GENOMECOV_4535_post(NamedTuple):
    bedgraph_forward: typing.Union[str, None]
    bedgraph_reverse: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4535_post:
    bedgraph_forward: str
    bedgraph_reverse: str
    versions: str

@task(cache=True)
def post_adapter_BEDTOOLS_GENOMECOV_4535_post(
    default: List[Dataclass_4535_post],
    is_skipped: bool,
) -> Respost_adapter_BEDTOOLS_GENOMECOV_4535_post:
    return get_mapper_outputs(Respost_adapter_BEDTOOLS_GENOMECOV_4535_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4535_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4535_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4535_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4535_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BEDTOOLS_GENOMECOV","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph_forward\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BEDTOOLS_GENOMECOV\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph_reverse\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BEDTOOLS_GENOMECOV\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BEDTOOLS_GENOMECOV\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def BEDTOOLS_GENOMECOV_4535(
    default: Dataclass_4535_pre
) -> Dataclass_4535_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"BEDTOOLS_GENOMECOV","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph_forward\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BEDTOOLS_GENOMECOV\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph_reverse\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BEDTOOLS_GENOMECOV\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"BEDTOOLS_GENOMECOV\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4535_post(
        bedgraph_forward=out_channels.get(f"bedgraph_forward"),
        bedgraph_reverse=out_channels.get(f"bedgraph_reverse"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3700(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3700(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3698_0: typing.Union[str, None]
) -> Resmap_3700:
    cond = ((channel_3698_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3698_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3700(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4547_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4535_1: str
    channel_3700: str


class Res_4547_pre(NamedTuple):
    default: typing.List[Dataclass_4547_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UCSC_BEDCLIP_4547_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4535_1: typing.Union[str, None],
    channel_3700: typing.Union[str, None]
) -> Res_4547_pre:
    cond = ((condition_4534 == True) and (channel_4535_1 is not None) and (channel_3700 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4547_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4535_1': channel_4535_1, 'channel_3700': channel_3700})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4547_pre(default=result, is_skipped = not cond)

class Respost_adapter_UCSC_BEDCLIP_4547_post(NamedTuple):
    bedgraph: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4547_post:
    bedgraph: str
    versions: str

@task(cache=True)
def post_adapter_UCSC_BEDCLIP_4547_post(
    default: List[Dataclass_4547_post],
    is_skipped: bool,
) -> Respost_adapter_UCSC_BEDCLIP_4547_post:
    return get_mapper_outputs(Respost_adapter_UCSC_BEDCLIP_4547_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4547_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4547_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4547_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4547_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4535_1),json.loads(default.channel_3700)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDCLIP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UCSC_BEDCLIP_4547(
    default: Dataclass_4547_pre
) -> Dataclass_4547_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4535_1),json.loads(default.channel_3700)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDCLIP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4547_post(
        bedgraph=out_channels.get(f"bedgraph"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4548(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4548(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4547_1: typing.Union[str, None]
) -> Resfirst_4548:
    cond = ((condition_4534 == True) and (channel_4547_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4547_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4548(
        res=out_channels.get("res")
    )


class Resmix_4549(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4549(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4546: typing.Union[str, None],
    channel_4548: typing.Union[str, None]
) -> Resmix_4549:
    cond = ((condition_4534 == True) and (channel_4546 is not None) and (channel_4548 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4546), json.loads(channel_4548)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4549(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4550_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4547_0: str
    channel_3700: str


class Res_4550_pre(NamedTuple):
    default: typing.List[Dataclass_4550_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UCSC_BEDGRAPHTOBIGWIG_4550_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4547_0: typing.Union[str, None],
    channel_3700: typing.Union[str, None]
) -> Res_4550_pre:
    cond = ((condition_4534 == True) and (channel_4547_0 is not None) and (channel_3700 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4550_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4547_0': channel_4547_0, 'channel_3700': channel_3700})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4550_pre(default=result, is_skipped = not cond)

class Respost_adapter_UCSC_BEDGRAPHTOBIGWIG_4550_post(NamedTuple):
    bigwig: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4550_post:
    bigwig: str
    versions: str

@task(cache=True)
def post_adapter_UCSC_BEDGRAPHTOBIGWIG_4550_post(
    default: List[Dataclass_4550_post],
    is_skipped: bool,
) -> Respost_adapter_UCSC_BEDGRAPHTOBIGWIG_4550_post:
    return get_mapper_outputs(Respost_adapter_UCSC_BEDGRAPHTOBIGWIG_4550_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4550_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4550_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4550_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4550_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4547_0),json.loads(default.channel_3700)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDGRAPHTOBIGWIG","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bigwig\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UCSC_BEDGRAPHTOBIGWIG_4550(
    default: Dataclass_4550_pre
) -> Dataclass_4550_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4547_0),json.loads(default.channel_3700)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDGRAPHTOBIGWIG","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bigwig\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4550_post(
        bigwig=out_channels.get(f"bigwig"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4551(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4551(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4550_1: typing.Union[str, None]
) -> Resfirst_4551:
    cond = ((condition_4534 == True) and (channel_4550_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4550_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4551(
        res=out_channels.get("res")
    )


class Resmix_4552(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4552(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4549: typing.Union[str, None],
    channel_4551: typing.Union[str, None]
) -> Resmix_4552:
    cond = ((condition_4534 == True) and (channel_4549 is not None) and (channel_4551 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4549), json.loads(channel_4551)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4552(
        res=out_channels.get("res")
    )


class Resparams_skip_alignment_4565(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4565(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4565:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4565(
        res=out_channels.get("res")
    )


class Resparams_skip_qc_4566(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qc_4566(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_qc_4566:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qc_4566(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_qc__4567(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_qc__4567(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4565: typing.Union[str, None],
    channel_4566: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_qc__4567:
    cond = ((channel_4565 is not None) and (channel_4566 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4565), json.loads(channel_4566)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_qc__4567(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_qc__4568(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_qc__4568(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4567: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_qc__4568:
    cond = ((channel_4567 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4567)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_qc__4568(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment____params_skip_qc__4569(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment____params_skip_qc__4569(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4568: typing.Union[str, None]
) -> Resconditional__params_skip_alignment____params_skip_qc__4569:
    cond = ((channel_4568 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4568)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment____params_skip_qc__4569(condition=res)


class Resparams_skip_rseqc_4587(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_rseqc_4587(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None]
) -> Resparams_skip_rseqc_4587:
    cond = ((condition_4569 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_rseqc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_rseqc_4587(
        res=out_channels.get("res")
    )


class Resrseqc_modules_size___4588(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def rseqc_modules_size___4588(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None]
) -> Resrseqc_modules_size___4588:
    cond = ((condition_4569 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"rseqc_modules"},"method":"size","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resrseqc_modules_size___4588(
        res=out_channels.get("res")
    )


class Res_rseqc_modules_size_____0__4589(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _rseqc_modules_size_____0__4589(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4588: typing.Union[str, None]
) -> Res_rseqc_modules_size_____0__4589:
    cond = ((condition_4569 == True) and (channel_4588 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4588)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":0},{"ConstantExpression":">"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_rseqc_modules_size_____0__4589(
        res=out_channels.get("res")
    )


class Res_params_skip_rseqc_____rseqc_modules_size_____0___4590(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_rseqc_____rseqc_modules_size_____0___4590(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4587: typing.Union[str, None],
    channel_4589: typing.Union[str, None]
) -> Res_params_skip_rseqc_____rseqc_modules_size_____0___4590:
    cond = ((condition_4569 == True) and (channel_4587 is not None) and (channel_4589 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4587), json.loads(channel_4589)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_rseqc_____rseqc_modules_size_____0___4590(
        res=out_channels.get("res")
    )


class Res_params_skip_rseqc_____rseqc_modules_size_____0___4591(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_rseqc_____rseqc_modules_size_____0___4591(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4590: typing.Union[str, None]
) -> Res_params_skip_rseqc_____rseqc_modules_size_____0___4591:
    cond = ((condition_4569 == True) and (channel_4590 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4590)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_rseqc_____rseqc_modules_size_____0___4591(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_rseqc_____rseqc_modules_size_____0___4592(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_rseqc_____rseqc_modules_size_____0___4592(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4591: typing.Union[str, None]
) -> Resconditional__params_skip_rseqc_____rseqc_modules_size_____0___4592:
    cond = ((condition_4569 == True) and (channel_4591 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4591)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_rseqc_____rseqc_modules_size_____0___4592(condition=res)


class Res_inner_distance_in_rseqc_modules__4610(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _inner_distance_in_rseqc_modules__4610(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_inner_distance_in_rseqc_modules__4610:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"inner_distance"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_inner_distance_in_rseqc_modules__4610(
        res=out_channels.get("res")
    )


class Res_inner_distance_in_rseqc_modules__4611(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _inner_distance_in_rseqc_modules__4611(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4610: typing.Union[str, None]
) -> Res_inner_distance_in_rseqc_modules__4611:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4610 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4610)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_inner_distance_in_rseqc_modules__4611(
        res=out_channels.get("res")
    )


class Resconditional__inner_distance_in_rseqc_modules__4612(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__inner_distance_in_rseqc_modules__4612(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4611: typing.Union[str, None]
) -> Resconditional__inner_distance_in_rseqc_modules__4612:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4611 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4611)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__inner_distance_in_rseqc_modules__4612(condition=res)


@dataclass
class Dataclass_4474_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4471_0: str


class Res_4474_pre(NamedTuple):
    default: typing.List[Dataclass_4474_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4474_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4471_0: typing.Union[str, None]
) -> Res_4474_pre:
    cond = ((condition_4467 == True) and (channel_4471_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4474_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4471_0': channel_4471_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4474_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4474_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4474_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4474_post(
    default: List[Dataclass_4474_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4474_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4474_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4474_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4474_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4474_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4474_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4471_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_MARKDUPLICATES_PICARD'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4474(
    default: Dataclass_4474_pre
) -> Dataclass_4474_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4471_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_MARKDUPLICATES_PICARD'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4474_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_genome_bam_index_4490(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4490(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4474_1: typing.Union[str, None],
    channel_4474_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4490:
    cond = ((condition_4467 == True))

    if cond:
        res = { 'res': channel_4474_1 or channel_4474_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4490(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4413(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4413(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4396_1: typing.Union[str, None],
    channel_4396_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4413:
    cond = ((condition_4357 == True) and (condition_4389 == True))

    if cond:
        res = { 'res': channel_4396_1 or channel_4396_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4413(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4416(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4416(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4413: typing.Union[str, None],
    channel_4386: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4416:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4413 or channel_4386 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4416(
        res=res.get('res')
    )


@dataclass
class Dataclass_4309_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4306_0: str


class Res_4309_pre(NamedTuple):
    default: typing.List[Dataclass_4309_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_INDEX_4309_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4306_0: typing.Union[str, None]
) -> Res_4309_pre:
    cond = ((condition_4299 == True) and (channel_4306_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4309_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4306_0': channel_4306_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4309_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_INDEX_4309_post(NamedTuple):
    bai: typing.Union[str, None]
    csi: typing.Union[str, None]
    crai: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4309_post:
    bai: str
    csi: str
    crai: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_INDEX_4309_post(
    default: List[Dataclass_4309_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_INDEX_4309_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_INDEX_4309_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4309_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4309_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4309_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4309_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4306_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_INDEX_4309(
    default: Dataclass_4309_pre
) -> Dataclass_4309_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4306_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_SORT_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"csi\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"crai\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4309_post(
        bai=out_channels.get(f"bai"),
        csi=out_channels.get(f"csi"),
        crai=out_channels.get(f"crai"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_genome_bam_index_4330(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4330(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4309_1: typing.Union[str, None],
    channel_4309_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4330:
    cond = ((condition_4299 == True))

    if cond:
        res = { 'res': channel_4309_1 or channel_4309_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4330(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4185(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4185(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4168_1: typing.Union[str, None],
    channel_4168_0: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4185:
    cond = ((condition_4104 == True) and (condition_4161 == True))

    if cond:
        res = { 'res': channel_4168_1 or channel_4168_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4185(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4233(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4233(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4185: typing.Union[str, None],
    channel_4158: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4233:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4185 or channel_4158 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4233(
        res=res.get('res')
    )


class ResChannel_empty___4093(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4093(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4093:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4093(
        res=out_channels.get("res")
    )


class ResMerge_ch_genome_bam_index_4285(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4285(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4233: typing.Union[str, None],
    channel_4093: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4285:
    cond = True

    if cond:
        res = { 'res': channel_4233 or channel_4093 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4285(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4344(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4344(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4330: typing.Union[str, None],
    channel_4285: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4344:
    cond = True

    if cond:
        res = { 'res': channel_4330 or channel_4285 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4344(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4423(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4423(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4416: typing.Union[str, None],
    channel_4344: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4423:
    cond = True

    if cond:
        res = { 'res': channel_4416 or channel_4344 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4423(
        res=res.get('res')
    )


class Resjoin_4439(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4439(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4423: typing.Union[str, None],
    channel_4436: typing.Union[str, None]
) -> Resjoin_4439:
    cond = ((condition_4435 == True) and (channel_4423 is not None) and (channel_4436 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4423), json.loads(channel_4436)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4439(
        res=out_channels.get("res")
    )


class Resmap_4440(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4440(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4439: typing.Union[str, None]
) -> Resmap_4440:
    cond = ((condition_4435 == True) and (channel_4439 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4439)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"pass"}},"ifBlock":{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"ofile"}]}},"elseBlock":{"ReturnStatement":{"ConstantExpression":null}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","ofile","mapped","pass"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4440(
        res=out_channels.get("res")
    )


class ResMerge_ch_genome_bam_index_4445(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4445(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4440: typing.Union[str, None],
    channel_4423: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4445:
    cond = True

    if cond:
        res = { 'res': channel_4440 or channel_4423 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4445(
        res=res.get('res')
    )


class ResMerge_ch_genome_bam_index_4493(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_genome_bam_index_4493(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4490: typing.Union[str, None],
    channel_4445: typing.Union[str, None]
) -> ResMerge_ch_genome_bam_index_4493:
    cond = True

    if cond:
        res = { 'res': channel_4490 or channel_4445 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_genome_bam_index_4493(
        res=res.get('res')
    )


class Resjoin_4593(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4593(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4492: typing.Union[str, None],
    channel_4493: typing.Union[str, None]
) -> Resjoin_4593:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4492 is not None) and (channel_4493 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4492), json.loads(channel_4493)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4593(
        res=out_channels.get("res")
    )


class Resmap_4595(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4595(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4593: typing.Union[str, None]
) -> Resmap_4595:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4593 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4593)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":0}}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4595(
        res=out_channels.get("res")
    )


class Resparams_gene_bed_3582(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_gene_bed_3582(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_gene_bed_3582:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"gene_bed"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_gene_bed_3582(
        res=out_channels.get("res")
    )


class Resgene_bed_3659(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gene_bed_3659(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3582: typing.Union[str, None]
) -> Resgene_bed_3659:
    cond = ((channel_3582 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3582)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgene_bed_3659(
        res=out_channels.get("res")
    )


class Resconditional_gene_bed_3660(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gene_bed_3660(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3659: typing.Union[str, None]
) -> Resconditional_gene_bed_3660:
    cond = ((channel_3659 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3659)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gene_bed_3660(condition=res)


class Resgene_bed_endsWith__gz__3661(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gene_bed_endsWith__gz__3661(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3582: typing.Union[str, None]
) -> Resgene_bed_endsWith__gz__3661:
    cond = ((condition_3660 == True) and (channel_3582 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3582)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"gene_bed"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgene_bed_endsWith__gz__3661(
        res=out_channels.get("res")
    )


class Resgene_bed_endsWith__gz__3662(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def gene_bed_endsWith__gz__3662(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3661: typing.Union[str, None]
) -> Resgene_bed_endsWith__gz__3662:
    cond = ((condition_3660 == True) and (channel_3661 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3661)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resgene_bed_endsWith__gz__3662(
        res=out_channels.get("res")
    )


class Resconditional_gene_bed_endsWith__gz__3663(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_gene_bed_endsWith__gz__3663(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3662: typing.Union[str, None]
) -> Resconditional_gene_bed_endsWith__gz__3663:
    cond = ((condition_3660 == True) and (channel_3662 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3662)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_gene_bed_endsWith__gz__3663(condition=res)


class Res______gene_bed__3664(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______gene_bed__3664(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    condition_3663: typing.Union[bool, None],
    channel_3582: typing.Union[str, None]
) -> Res______gene_bed__3664:
    cond = ((condition_3660 == True) and (condition_3663 == True) and (channel_3582 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3582)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______gene_bed__3664(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3665_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3664: str


class Res_3665_pre(NamedTuple):
    default: typing.List[Dataclass_3665_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GUNZIP_GENE_BED_3665_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    condition_3663: typing.Union[bool, None],
    channel_3664: typing.Union[str, None]
) -> Res_3665_pre:
    cond = ((condition_3660 == True) and (condition_3663 == True) and (channel_3664 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3665_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3664': channel_3664})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3665_pre(default=result, is_skipped = not cond)

class Respost_adapter_GUNZIP_GENE_BED_3665_post(NamedTuple):
    gunzip: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3665_post:
    gunzip: str
    versions: str

@task(cache=True)
def post_adapter_GUNZIP_GENE_BED_3665_post(
    default: List[Dataclass_3665_post],
    is_skipped: bool,
) -> Respost_adapter_GUNZIP_GENE_BED_3665_post:
    return get_mapper_outputs(Respost_adapter_GUNZIP_GENE_BED_3665_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3665_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3665_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3665_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3665_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3664)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_GENE_BED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GENE_BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GENE_BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GUNZIP_GENE_BED_3665(
    default: Dataclass_3665_pre
) -> Dataclass_3665_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3664)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GUNZIP_GENE_BED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"gunzip\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GENE_BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GUNZIP_GENE_BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3665_post(
        gunzip=out_channels.get(f"gunzip"),
        versions=out_channels.get(f"versions")
    )


class Resmap_3666(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3666(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    condition_3663: typing.Union[bool, None],
    channel_3665_0: typing.Union[str, None]
) -> Resmap_3666:
    cond = ((condition_3660 == True) and (condition_3663 == True) and (channel_3665_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3665_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3666(
        res=out_channels.get("res")
    )


class ResChannel_value_this_file_gene_bed___3668(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_this_file_gene_bed___3668(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    condition_3663: typing.Union[bool, None]
) -> ResChannel_value_this_file_gene_bed___3668:
    cond = ((condition_3660 == True) and (condition_3663 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"gene_bed"}]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_this_file_gene_bed___3668(
        res=out_channels.get("res")
    )


class ResMerge_ch_gene_bed_3669(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gene_bed_3669(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3666: typing.Union[str, None],
    channel_3668: typing.Union[str, None]
) -> ResMerge_ch_gene_bed_3669:
    cond = ((condition_3660 == True))

    if cond:
        res = { 'res': channel_3666 or channel_3668 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gene_bed_3669(
        res=res.get('res')
    )


@dataclass
class Dataclass_3671_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3656: str


class Res_3671_pre(NamedTuple):
    default: typing.List[Dataclass_3671_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_GTF2BED_3671_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Res_3671_pre:
    cond = ((condition_3660 == False) and (channel_3656 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3671_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3656': channel_3656})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3671_pre(default=result, is_skipped = not cond)

class Respost_adapter_GTF2BED_3671_post(NamedTuple):
    bed: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3671_post:
    bed: str
    versions: str

@task(cache=True)
def post_adapter_GTF2BED_3671_post(
    default: List[Dataclass_3671_post],
    is_skipped: bool,
) -> Respost_adapter_GTF2BED_3671_post:
    return get_mapper_outputs(Respost_adapter_GTF2BED_3671_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3671_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3671_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3671_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3671_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3656)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GTF2BED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF2BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF2BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def GTF2BED_3671(
    default: Dataclass_3671_pre
) -> Dataclass_3671_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3656)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"GTF2BED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF2BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"GTF2BED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3671_post(
        bed=out_channels.get(f"bed"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_gene_bed_3673(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_gene_bed_3673(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3669: typing.Union[str, None],
    channel_3671_0: typing.Union[str, None]
) -> ResMerge_ch_gene_bed_3673:
    cond = True

    if cond:
        res = { 'res': channel_3669 or channel_3671_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_gene_bed_3673(
        res=res.get('res')
    )


@dataclass
class Dataclass_4613_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str
    channel_3673: str


class Res_4613_pre(NamedTuple):
    default: typing.List[Dataclass_4613_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_INNERDISTANCE_4613_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4612: typing.Union[bool, None],
    channel_4595: typing.Union[str, None],
    channel_3673: typing.Union[str, None]
) -> Res_4613_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4612 == True) and (channel_4595 is not None) and (channel_3673 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4613_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595, 'channel_3673': channel_3673})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4613_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_INNERDISTANCE_4613_post(NamedTuple):
    distance: typing.Union[str, None]
    freq: typing.Union[str, None]
    mean: typing.Union[str, None]
    pdf: typing.Union[str, None]
    rscript: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4613_post:
    distance: str
    freq: str
    mean: str
    pdf: str
    rscript: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_INNERDISTANCE_4613_post(
    default: List[Dataclass_4613_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_INNERDISTANCE_4613_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_INNERDISTANCE_4613_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4613_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4613_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4613_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4613_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_INNERDISTANCE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"freq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mean\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_INNERDISTANCE_4613(
    default: Dataclass_4613_pre
) -> Dataclass_4613_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_INNERDISTANCE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"distance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"freq\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mean\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INNERDISTANCE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4613_post(
        distance=out_channels.get(f"distance"),
        freq=out_channels.get(f"freq"),
        mean=out_channels.get(f"mean"),
        pdf=out_channels.get(f"pdf"),
        rscript=out_channels.get(f"rscript"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4608(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4608(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4608:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4608(
        res=out_channels.get("res")
    )


class ResMerge_innerdistance_pdf_4616(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_innerdistance_pdf_4616(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4613_3: typing.Union[str, None],
    channel_4608: typing.Union[str, None]
) -> ResMerge_innerdistance_pdf_4616:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4613_3 or channel_4608 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_innerdistance_pdf_4616(
        res=res.get('res')
    )


class ResChannel_empty___4609(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4609(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4609:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4609(
        res=out_channels.get("res")
    )


class ResMerge_innerdistance_rscript_4617(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_innerdistance_rscript_4617(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4613_4: typing.Union[str, None],
    channel_4609: typing.Union[str, None]
) -> ResMerge_innerdistance_rscript_4617:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4613_4 or channel_4609 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_innerdistance_rscript_4617(
        res=res.get('res')
    )


class ResChannel_empty___4607(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4607(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4607:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4607(
        res=out_channels.get("res")
    )


class ResMerge_innerdistance_mean_4618(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_innerdistance_mean_4618(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4613_2: typing.Union[str, None],
    channel_4607: typing.Union[str, None]
) -> ResMerge_innerdistance_mean_4618:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4613_2 or channel_4607 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_innerdistance_mean_4618(
        res=res.get('res')
    )


class ResChannel_empty___4605(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4605(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4605:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4605(
        res=out_channels.get("res")
    )


class ResMerge_innerdistance_distance_4620(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_innerdistance_distance_4620(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4613_0: typing.Union[str, None],
    channel_4605: typing.Union[str, None]
) -> ResMerge_innerdistance_distance_4620:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4613_0 or channel_4605 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_innerdistance_distance_4620(
        res=res.get('res')
    )


class Res_junction_annotation_in_rseqc_modules__4638(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _junction_annotation_in_rseqc_modules__4638(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_junction_annotation_in_rseqc_modules__4638:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"junction_annotation"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_junction_annotation_in_rseqc_modules__4638(
        res=out_channels.get("res")
    )


class Res_junction_annotation_in_rseqc_modules__4639(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _junction_annotation_in_rseqc_modules__4639(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4638: typing.Union[str, None]
) -> Res_junction_annotation_in_rseqc_modules__4639:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4638 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4638)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_junction_annotation_in_rseqc_modules__4639(
        res=out_channels.get("res")
    )


class Resconditional__junction_annotation_in_rseqc_modules__4640(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__junction_annotation_in_rseqc_modules__4640(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4639: typing.Union[str, None]
) -> Resconditional__junction_annotation_in_rseqc_modules__4640:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4639 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4639)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__junction_annotation_in_rseqc_modules__4640(condition=res)


@dataclass
class Dataclass_4641_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str
    channel_3673: str


class Res_4641_pre(NamedTuple):
    default: typing.List[Dataclass_4641_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_JUNCTIONANNOTATION_4641_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4640: typing.Union[bool, None],
    channel_4595: typing.Union[str, None],
    channel_3673: typing.Union[str, None]
) -> Res_4641_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4640 == True) and (channel_4595 is not None) and (channel_3673 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4641_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595, 'channel_3673': channel_3673})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4641_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_JUNCTIONANNOTATION_4641_post(NamedTuple):
    xls: typing.Union[str, None]
    rscript: typing.Union[str, None]
    log: typing.Union[str, None]
    bed: typing.Union[str, None]
    interact_bed: typing.Union[str, None]
    pdf: typing.Union[str, None]
    events_pdf: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4641_post:
    xls: str
    rscript: str
    log: str
    bed: str
    interact_bed: str
    pdf: str
    events_pdf: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_JUNCTIONANNOTATION_4641_post(
    default: List[Dataclass_4641_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_JUNCTIONANNOTATION_4641_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_JUNCTIONANNOTATION_4641_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4641_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4641_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4641_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4641_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_JUNCTIONANNOTATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"interact_bed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"events_pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_JUNCTIONANNOTATION_4641(
    default: Dataclass_4641_pre
) -> Dataclass_4641_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_JUNCTIONANNOTATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"interact_bed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"events_pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONANNOTATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4641_post(
        xls=out_channels.get(f"xls"),
        rscript=out_channels.get(f"rscript"),
        log=out_channels.get(f"log"),
        bed=out_channels.get(f"bed"),
        interact_bed=out_channels.get(f"interact_bed"),
        pdf=out_channels.get(f"pdf"),
        events_pdf=out_channels.get(f"events_pdf"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4636(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4636(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4636:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4636(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_rscript_4644(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_rscript_4644(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_1: typing.Union[str, None],
    channel_4636: typing.Union[str, None]
) -> ResMerge_junctionannotation_rscript_4644:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_1 or channel_4636 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_rscript_4644(
        res=res.get('res')
    )


class ResChannel_empty___4635(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4635(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4635:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4635(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_events_pdf_4646(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_events_pdf_4646(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_6: typing.Union[str, None],
    channel_4635: typing.Union[str, None]
) -> ResMerge_junctionannotation_events_pdf_4646:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_6 or channel_4635 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_events_pdf_4646(
        res=res.get('res')
    )


class ResChannel_empty___4633(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4633(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4633:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4633(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_xls_4647(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_xls_4647(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_0: typing.Union[str, None],
    channel_4633: typing.Union[str, None]
) -> ResMerge_junctionannotation_xls_4647:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_0 or channel_4633 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_xls_4647(
        res=res.get('res')
    )


class ResChannel_empty___4631(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4631(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4631:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4631(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_bed_4648(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_bed_4648(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_3: typing.Union[str, None],
    channel_4631: typing.Union[str, None]
) -> ResMerge_junctionannotation_bed_4648:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_3 or channel_4631 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_bed_4648(
        res=res.get('res')
    )


class ResChannel_empty___4632(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4632(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4632:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4632(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_interact_bed_4649(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_interact_bed_4649(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_4: typing.Union[str, None],
    channel_4632: typing.Union[str, None]
) -> ResMerge_junctionannotation_interact_bed_4649:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_4 or channel_4632 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_interact_bed_4649(
        res=res.get('res')
    )


class ResChannel_empty___4634(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4634(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4634:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4634(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_pdf_4650(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_pdf_4650(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_5: typing.Union[str, None],
    channel_4634: typing.Union[str, None]
) -> ResMerge_junctionannotation_pdf_4650:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_5 or channel_4634 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_pdf_4650(
        res=res.get('res')
    )


class Res_junction_saturation_in_rseqc_modules__4654(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _junction_saturation_in_rseqc_modules__4654(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_junction_saturation_in_rseqc_modules__4654:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"junction_saturation"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_junction_saturation_in_rseqc_modules__4654(
        res=out_channels.get("res")
    )


class Res_junction_saturation_in_rseqc_modules__4655(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _junction_saturation_in_rseqc_modules__4655(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4654: typing.Union[str, None]
) -> Res_junction_saturation_in_rseqc_modules__4655:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4654 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4654)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_junction_saturation_in_rseqc_modules__4655(
        res=out_channels.get("res")
    )


class Resconditional__junction_saturation_in_rseqc_modules__4656(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__junction_saturation_in_rseqc_modules__4656(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4655: typing.Union[str, None]
) -> Resconditional__junction_saturation_in_rseqc_modules__4656:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4655 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4655)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__junction_saturation_in_rseqc_modules__4656(condition=res)


@dataclass
class Dataclass_4657_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str
    channel_3673: str


class Res_4657_pre(NamedTuple):
    default: typing.List[Dataclass_4657_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_JUNCTIONSATURATION_4657_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4656: typing.Union[bool, None],
    channel_4595: typing.Union[str, None],
    channel_3673: typing.Union[str, None]
) -> Res_4657_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4656 == True) and (channel_4595 is not None) and (channel_3673 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4657_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595, 'channel_3673': channel_3673})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4657_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_JUNCTIONSATURATION_4657_post(NamedTuple):
    pdf: typing.Union[str, None]
    rscript: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4657_post:
    pdf: str
    rscript: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_JUNCTIONSATURATION_4657_post(
    default: List[Dataclass_4657_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_JUNCTIONSATURATION_4657_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_JUNCTIONSATURATION_4657_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4657_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4657_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4657_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4657_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_JUNCTIONSATURATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONSATURATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONSATURATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONSATURATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_JUNCTIONSATURATION_4657(
    default: Dataclass_4657_pre
) -> Dataclass_4657_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_JUNCTIONSATURATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONSATURATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONSATURATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_JUNCTIONSATURATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4657_post(
        pdf=out_channels.get(f"pdf"),
        rscript=out_channels.get(f"rscript"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4652(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4652(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4652:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4652(
        res=out_channels.get("res")
    )


class ResMerge_junctionsaturation_pdf_4661(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionsaturation_pdf_4661(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4657_0: typing.Union[str, None],
    channel_4652: typing.Union[str, None]
) -> ResMerge_junctionsaturation_pdf_4661:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4657_0 or channel_4652 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionsaturation_pdf_4661(
        res=res.get('res')
    )


class Res_read_duplication_in_rseqc_modules__4676(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _read_duplication_in_rseqc_modules__4676(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_read_duplication_in_rseqc_modules__4676:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"read_duplication"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_read_duplication_in_rseqc_modules__4676(
        res=out_channels.get("res")
    )


class Res_read_duplication_in_rseqc_modules__4677(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _read_duplication_in_rseqc_modules__4677(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4676: typing.Union[str, None]
) -> Res_read_duplication_in_rseqc_modules__4677:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4676 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4676)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_read_duplication_in_rseqc_modules__4677(
        res=out_channels.get("res")
    )


class Resconditional__read_duplication_in_rseqc_modules__4678(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__read_duplication_in_rseqc_modules__4678(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4677: typing.Union[str, None]
) -> Resconditional__read_duplication_in_rseqc_modules__4678:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4677 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4677)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__read_duplication_in_rseqc_modules__4678(condition=res)


@dataclass
class Dataclass_4679_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str


class Res_4679_pre(NamedTuple):
    default: typing.List[Dataclass_4679_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_READDUPLICATION_4679_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4678: typing.Union[bool, None],
    channel_4595: typing.Union[str, None]
) -> Res_4679_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4678 == True) and (channel_4595 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4679_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4679_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_READDUPLICATION_4679_post(NamedTuple):
    seq_xls: typing.Union[str, None]
    pos_xls: typing.Union[str, None]
    pdf: typing.Union[str, None]
    rscript: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4679_post:
    seq_xls: str
    pos_xls: str
    pdf: str
    rscript: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_READDUPLICATION_4679_post(
    default: List[Dataclass_4679_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_READDUPLICATION_4679_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_READDUPLICATION_4679_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4679_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4679_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4679_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4679_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_READDUPLICATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"seq_xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pos_xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_READDUPLICATION_4679(
    default: Dataclass_4679_pre
) -> Dataclass_4679_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_READDUPLICATION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"seq_xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pos_xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rscript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDUPLICATION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4679_post(
        seq_xls=out_channels.get(f"seq_xls"),
        pos_xls=out_channels.get(f"pos_xls"),
        pdf=out_channels.get(f"pdf"),
        rscript=out_channels.get(f"rscript"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___4674(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4674(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4674:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4674(
        res=out_channels.get("res")
    )


class ResMerge_readduplication_pdf_4682(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_readduplication_pdf_4682(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4679_2: typing.Union[str, None],
    channel_4674: typing.Union[str, None]
) -> ResMerge_readduplication_pdf_4682:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4679_2 or channel_4674 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_readduplication_pdf_4682(
        res=res.get('res')
    )


class ResChannel_empty___4672(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4672(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4672:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4672(
        res=out_channels.get("res")
    )


class ResMerge_readduplication_seq_xls_4683(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_readduplication_seq_xls_4683(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4679_0: typing.Union[str, None],
    channel_4672: typing.Union[str, None]
) -> ResMerge_readduplication_seq_xls_4683:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4679_0 or channel_4672 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_readduplication_seq_xls_4683(
        res=res.get('res')
    )


class ResChannel_empty___4675(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4675(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4675:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4675(
        res=out_channels.get("res")
    )


class ResMerge_readduplication_rscript_4685(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_readduplication_rscript_4685(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4679_3: typing.Union[str, None],
    channel_4675: typing.Union[str, None]
) -> ResMerge_readduplication_rscript_4685:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4679_3 or channel_4675 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_readduplication_rscript_4685(
        res=res.get('res')
    )


class Resparams_skip_pseudo_alignment_4725(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_pseudo_alignment_4725(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_pseudo_alignment_4725:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_pseudo_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_pseudo_alignment_4725(
        res=out_channels.get("res")
    )


class Res_params_skip_pseudo_alignment____params_pseudo_aligner__4726(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_pseudo_alignment____params_pseudo_aligner__4726(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4725: typing.Union[str, None]
) -> Res_params_skip_pseudo_alignment____params_pseudo_aligner__4726:
    cond = ((channel_4725 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4725)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"pseudo_aligner"}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_pseudo_alignment____params_pseudo_aligner__4726(
        res=out_channels.get("res")
    )


class Res_params_skip_pseudo_alignment____params_pseudo_aligner__4727(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_pseudo_alignment____params_pseudo_aligner__4727(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4726: typing.Union[str, None]
) -> Res_params_skip_pseudo_alignment____params_pseudo_aligner__4727:
    cond = ((channel_4726 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4726)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_pseudo_alignment____params_pseudo_aligner__4727(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_pseudo_alignment____params_pseudo_aligner__4728(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_pseudo_alignment____params_pseudo_aligner__4728(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4727: typing.Union[str, None]
) -> Resconditional__params_skip_pseudo_alignment____params_pseudo_aligner__4728:
    cond = ((channel_4727 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4727)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_pseudo_alignment____params_pseudo_aligner__4728(condition=res)


class Res_params_pseudo_aligner____salmon__4729(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_pseudo_aligner____salmon__4729(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Res_params_pseudo_aligner____salmon__4729:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"BinaryExpression":{"leftExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"pseudo_aligner"}},"operation":"==","rightExpression":{"ConstantExpression":"salmon"}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_pseudo_aligner____salmon__4729(
        res=out_channels.get("res")
    )


class Res_params_pseudo_aligner____salmon__4730(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_pseudo_aligner____salmon__4730(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4729: typing.Union[str, None]
) -> Res_params_pseudo_aligner____salmon__4730:
    cond = ((condition_4728 == True) and (channel_4729 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4729)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_pseudo_aligner____salmon__4730(
        res=out_channels.get("res")
    )


class Resconditional__params_pseudo_aligner____salmon__4731(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_pseudo_aligner____salmon__4731(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4730: typing.Union[str, None]
) -> Resconditional__params_pseudo_aligner____salmon__4731:
    cond = ((condition_4728 == True) and (channel_4730 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4730)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_pseudo_aligner____salmon__4731(condition=res)


class Resfalse_4734(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def false_4734(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Resfalse_4734:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":false}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfalse_4734(
        res=out_channels.get("res")
    )


class Res_pseudo_aligner____salmon__4739(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _pseudo_aligner____salmon__4739(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4734: typing.Union[str, None]
) -> Res_pseudo_aligner____salmon__4739:
    cond = ((condition_4728 == True) and (channel_4734 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4734)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"salmon"},{"ConstantExpression":"=="}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_pseudo_aligner____salmon__4739(
        res=out_channels.get("res")
    )


class Res_pseudo_aligner____salmon__4740(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _pseudo_aligner____salmon__4740(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4739: typing.Union[str, None]
) -> Res_pseudo_aligner____salmon__4740:
    cond = ((condition_4728 == True) and (channel_4739 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4739)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_pseudo_aligner____salmon__4740(
        res=out_channels.get("res")
    )


class Resconditional__pseudo_aligner____salmon__4741(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__pseudo_aligner____salmon__4741(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4740: typing.Union[str, None]
) -> Resconditional__pseudo_aligner____salmon__4741:
    cond = ((condition_4728 == True) and (channel_4740 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4740)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__pseudo_aligner____salmon__4741(condition=res)


class Resparams_kallisto_index_3588(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_kallisto_index_3588(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_kallisto_index_3588:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"kallisto_index"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_kallisto_index_3588(
        res=out_channels.get("res")
    )


class Reskallisto_index_3844(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def kallisto_index_3844(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3588: typing.Union[str, None]
) -> Reskallisto_index_3844:
    cond = ((channel_3588 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3588)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Reskallisto_index_3844(
        res=out_channels.get("res")
    )


class Resconditional_kallisto_index_3845(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_kallisto_index_3845(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3844: typing.Union[str, None]
) -> Resconditional_kallisto_index_3845:
    cond = ((channel_3844 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3844)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_kallisto_index_3845(condition=res)


class Reskallisto_index_endsWith__tar_gz__3846(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def kallisto_index_endsWith__tar_gz__3846(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3588: typing.Union[str, None]
) -> Reskallisto_index_endsWith__tar_gz__3846:
    cond = ((condition_3845 == True) and (channel_3588 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3588)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"kallisto_index"},"method":"endsWith","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":".tar.gz"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Reskallisto_index_endsWith__tar_gz__3846(
        res=out_channels.get("res")
    )


class Reskallisto_index_endsWith__tar_gz__3847(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def kallisto_index_endsWith__tar_gz__3847(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3846: typing.Union[str, None]
) -> Reskallisto_index_endsWith__tar_gz__3847:
    cond = ((condition_3845 == True) and (channel_3846 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3846)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Reskallisto_index_endsWith__tar_gz__3847(
        res=out_channels.get("res")
    )


class Resconditional_kallisto_index_endsWith__tar_gz__3848(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_kallisto_index_endsWith__tar_gz__3848(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3847: typing.Union[str, None]
) -> Resconditional_kallisto_index_endsWith__tar_gz__3848:
    cond = ((condition_3845 == True) and (channel_3847 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3847)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_kallisto_index_endsWith__tar_gz__3848(condition=res)


class Res______kallisto_index__3849(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ______kallisto_index__3849(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3848: typing.Union[bool, None],
    channel_3588: typing.Union[str, None]
) -> Res______kallisto_index__3849:
    cond = ((condition_3845 == True) and (condition_3848 == True) and (channel_3588 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3588)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res______kallisto_index__3849(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3850_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3849: str


class Res_3850_pre(NamedTuple):
    default: typing.List[Dataclass_3850_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UNTAR_KALLISTO_INDEX_3850_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3848: typing.Union[bool, None],
    channel_3849: typing.Union[str, None]
) -> Res_3850_pre:
    cond = ((condition_3845 == True) and (condition_3848 == True) and (channel_3849 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3850_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3849': channel_3849})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3850_pre(default=result, is_skipped = not cond)

class Respost_adapter_UNTAR_KALLISTO_INDEX_3850_post(NamedTuple):
    untar: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3850_post:
    untar: str
    versions: str

@task(cache=True)
def post_adapter_UNTAR_KALLISTO_INDEX_3850_post(
    default: List[Dataclass_3850_post],
    is_skipped: bool,
) -> Respost_adapter_UNTAR_KALLISTO_INDEX_3850_post:
    return get_mapper_outputs(Respost_adapter_UNTAR_KALLISTO_INDEX_3850_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3850_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3850_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3850_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3850_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3849)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_KALLISTO_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UNTAR_KALLISTO_INDEX_3850(
    default: Dataclass_3850_pre
) -> Dataclass_3850_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3849)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UNTAR_KALLISTO_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"untar\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UNTAR_KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3850_post(
        untar=out_channels.get(f"untar"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_value_______this_file_kallisto_index____3852(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_______this_file_kallisto_index____3852(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3848: typing.Union[bool, None]
) -> ResChannel_value_______this_file_kallisto_index____3852:
    cond = ((condition_3845 == True) and (condition_3848 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"MapExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"file","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"kallisto_index"}]}}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_______this_file_kallisto_index____3852(
        res=out_channels.get("res")
    )


class ResMerge_ch_kallisto_index_3853(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_kallisto_index_3853(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3850_0: typing.Union[str, None],
    channel_3852: typing.Union[str, None]
) -> ResMerge_ch_kallisto_index_3853:
    cond = ((condition_3845 == True))

    if cond:
        res = { 'res': channel_3850_0 or channel_3852 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_kallisto_index_3853(
        res=res.get('res')
    )


class Res_kallisto_in_prepare_tool_indices__3855(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _kallisto_in_prepare_tool_indices__3855(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None]
) -> Res_kallisto_in_prepare_tool_indices__3855:
    cond = ((condition_3845 == False))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"kallisto"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_kallisto_in_prepare_tool_indices__3855(
        res=out_channels.get("res")
    )


class Res_kallisto_in_prepare_tool_indices__3856(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _kallisto_in_prepare_tool_indices__3856(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3855: typing.Union[str, None]
) -> Res_kallisto_in_prepare_tool_indices__3856:
    cond = ((condition_3845 == False) and (channel_3855 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3855)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_kallisto_in_prepare_tool_indices__3856(
        res=out_channels.get("res")
    )


class Resconditional__kallisto_in_prepare_tool_indices__3857(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__kallisto_in_prepare_tool_indices__3857(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3856: typing.Union[str, None]
) -> Resconditional__kallisto_in_prepare_tool_indices__3857:
    cond = ((condition_3845 == False) and (channel_3856 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3856)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__kallisto_in_prepare_tool_indices__3857(condition=res)


class Resmap_3858(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3858(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3857: typing.Union[bool, None],
    channel_3695: typing.Union[str, None]
) -> Resmap_3858:
    cond = ((condition_3845 == False) and (condition_3857 == True) and (channel_3695 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3695)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3858(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_3859_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_3858: str


class Res_3859_pre(NamedTuple):
    default: typing.List[Dataclass_3859_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_KALLISTO_INDEX_3859_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3857: typing.Union[bool, None],
    channel_3858: typing.Union[str, None]
) -> Res_3859_pre:
    cond = ((condition_3845 == False) and (condition_3857 == True) and (channel_3858 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_3859_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_3858': channel_3858})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_3859_pre(default=result, is_skipped = not cond)

class Respost_adapter_KALLISTO_INDEX_3859_post(NamedTuple):
    index: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_3859_post:
    index: str
    versions: str

@task(cache=True)
def post_adapter_KALLISTO_INDEX_3859_post(
    default: List[Dataclass_3859_post],
    is_skipped: bool,
) -> Respost_adapter_KALLISTO_INDEX_3859_post:
    return get_mapper_outputs(Respost_adapter_KALLISTO_INDEX_3859_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_3859_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_3859_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_3859_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_3859_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3858)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"KALLISTO_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def KALLISTO_INDEX_3859(
    default: Dataclass_3859_pre
) -> Dataclass_3859_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_3858)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/prepare_genome/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','PREPARE_GENOME'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"KALLISTO_INDEX","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"index\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_INDEX\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_3859_post(
        index=out_channels.get(f"index"),
        versions=out_channels.get(f"versions")
    )


class ResChannel_empty___3843(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3843(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3843:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3843(
        res=out_channels.get("res")
    )


class ResMerge_ch_kallisto_index_3861(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_kallisto_index_3861(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3859_0: typing.Union[str, None],
    channel_3843: typing.Union[str, None]
) -> ResMerge_ch_kallisto_index_3861:
    cond = ((condition_3845 == False))

    if cond:
        res = { 'res': channel_3859_0 or channel_3843 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_kallisto_index_3861(
        res=res.get('res')
    )


class ResMerge_ch_kallisto_index_3863(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_kallisto_index_3863(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3853: typing.Union[str, None],
    channel_3861: typing.Union[str, None]
) -> ResMerge_ch_kallisto_index_3863:
    cond = True

    if cond:
        res = { 'res': channel_3853 or channel_3861 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_kallisto_index_3863(
        res=res.get('res')
    )


class ResMerge_ch_pseudo_index_4732(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudo_index_4732(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_3841: typing.Union[str, None],
    channel_3863: typing.Union[str, None]
) -> ResMerge_ch_pseudo_index_4732:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_3841 or channel_3863 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudo_index_4732(
        res=res.get('res')
    )


class Resparams_pseudo_aligner_4733(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_pseudo_aligner_4733(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Resparams_pseudo_aligner_4733:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"pseudo_aligner"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_pseudo_aligner_4733(
        res=out_channels.get("res")
    )


class Res_params_salmon_quant_libtype____params_salmon_quant_libtype____4735(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_salmon_quant_libtype____params_salmon_quant_libtype____4735(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Res_params_salmon_quant_libtype____params_salmon_quant_libtype____4735:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"TernaryExpression":{"booleanExpression":{"BooleanExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"salmon_quant_libtype"}}},"trueExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"salmon_quant_libtype"}},"falseExpression":{"ConstantExpression":""}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_salmon_quant_libtype____params_salmon_quant_libtype____4735(
        res=out_channels.get("res")
    )


class Resparams_kallisto_quant_fraglen_4736(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_kallisto_quant_fraglen_4736(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Resparams_kallisto_quant_fraglen_4736:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"kallisto_quant_fraglen"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_kallisto_quant_fraglen_4736(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4742_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4091: str
    channel_4732: str
    channel_4733: str
    channel_3656: str
    channel_4735: str
    channel_4736: str


class Res_4742_pre(NamedTuple):
    default: typing.List[Dataclass_4742_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SALMON_QUANT_4742_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4741: typing.Union[bool, None],
    channel_4091: typing.Union[str, None],
    channel_4732: typing.Union[str, None],
    channel_4733: typing.Union[str, None],
    channel_3656: typing.Union[str, None],
    channel_4735: typing.Union[str, None],
    channel_4736: typing.Union[str, None]
) -> Res_4742_pre:
    cond = ((condition_4728 == True) and (condition_4741 == True) and (channel_4091 is not None) and (channel_4732 is not None) and (channel_4733 is not None) and (channel_3656 is not None) and (channel_4735 is not None) and (channel_4736 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4742_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4091': channel_4091, 'channel_4732': channel_4732, 'channel_4733': channel_4733, 'channel_3656': channel_3656, 'channel_4735': channel_4735, 'channel_4736': channel_4736})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4742_pre(default=result, is_skipped = not cond)

class Respost_adapter_SALMON_QUANT_4742_post(NamedTuple):
    results: typing.Union[str, None]
    json_info: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4742_post:
    results: str
    json_info: str
    versions: str

@task(cache=True)
def post_adapter_SALMON_QUANT_4742_post(
    default: List[Dataclass_4742_post],
    is_skipped: bool,
) -> Respost_adapter_SALMON_QUANT_4742_post:
    return get_mapper_outputs(Respost_adapter_SALMON_QUANT_4742_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4742_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4742_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4742_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4742_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4732),json.loads(default.channel_4733),json.loads(default.channel_3656),json.loads(default.channel_4735),json.loads(default.channel_4736)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SALMON_QUANT_4742(
    default: Dataclass_4742_pre
) -> Dataclass_4742_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4732),json.loads(default.channel_4733),json.loads(default.channel_3656),json.loads(default.channel_4735),json.loads(default.channel_4736)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SALMON_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SALMON_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4742_post(
        results=out_channels.get(f"results"),
        json_info=out_channels.get(f"json_info"),
        versions=out_channels.get(f"versions")
    )


class Resparams_kallisto_quant_fraglen_sd_4737(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_kallisto_quant_fraglen_sd_4737(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Resparams_kallisto_quant_fraglen_sd_4737:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"kallisto_quant_fraglen_sd"}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_kallisto_quant_fraglen_sd_4737(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4745_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4091: str
    channel_4732: str
    channel_4733: str
    channel_4737: str


class Res_4745_pre(NamedTuple):
    default: typing.List[Dataclass_4745_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_KALLISTO_QUANT_4745_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4741: typing.Union[bool, None],
    channel_4091: typing.Union[str, None],
    channel_4732: typing.Union[str, None],
    channel_4733: typing.Union[str, None],
    channel_4737: typing.Union[str, None]
) -> Res_4745_pre:
    cond = ((condition_4728 == True) and (condition_4741 == False) and (channel_4091 is not None) and (channel_4732 is not None) and (channel_4733 is not None) and (channel_4737 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4745_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4091': channel_4091, 'channel_4732': channel_4732, 'channel_4733': channel_4733, 'channel_4737': channel_4737})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4745_pre(default=result, is_skipped = not cond)

class Respost_adapter_KALLISTO_QUANT_4745_post(NamedTuple):
    results: typing.Union[str, None]
    json_info: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4745_post:
    results: str
    json_info: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_KALLISTO_QUANT_4745_post(
    default: List[Dataclass_4745_post],
    is_skipped: bool,
) -> Respost_adapter_KALLISTO_QUANT_4745_post:
    return get_mapper_outputs(Respost_adapter_KALLISTO_QUANT_4745_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4745_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4745_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4745_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4745_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4732),json.loads(default.channel_4733),json.loads(default.channel_4737)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"KALLISTO_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def KALLISTO_QUANT_4745(
    default: Dataclass_4745_pre
) -> Dataclass_4745_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4091),json.loads(default.channel_4732),json.loads(default.channel_4733),json.loads(default.channel_4737)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"KALLISTO_QUANT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ListExpression":[]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"json_info\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"KALLISTO_QUANT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4745_post(
        results=out_channels.get(f"results"),
        json_info=out_channels.get(f"json_info"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class ResMerge_ch_pseudo_results_4749(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudo_results_4749(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4742_0: typing.Union[str, None],
    channel_4745_0: typing.Union[str, None]
) -> ResMerge_ch_pseudo_results_4749:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_4742_0 or channel_4745_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudo_results_4749(
        res=res.get('res')
    )


class Rescollect_4754(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4754(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4749: typing.Union[str, None]
) -> Rescollect_4754:
    cond = ((condition_4728 == True) and (channel_4749 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4749)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4754(
        res=out_channels.get("res")
    )


class Rescollect_4751(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4751(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4749: typing.Union[str, None]
) -> Rescollect_4751:
    cond = ((condition_4728 == True) and (channel_4749 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4749)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4751(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4752_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4751: str
    channel_4734: str
    channel_4733: str


class Res_4752_pre(NamedTuple):
    default: typing.List[Dataclass_4752_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_TX2GENE_4752_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4751: typing.Union[str, None],
    channel_4734: typing.Union[str, None],
    channel_4733: typing.Union[str, None]
) -> Res_4752_pre:
    cond = ((condition_4728 == True) and (channel_4751 is not None) and (channel_4734 is not None) and (channel_4733 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4752_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4751': channel_4751, 'channel_4734': channel_4734, 'channel_4733': channel_4733})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4752_pre(default=result, is_skipped = not cond)

class Respost_adapter_TX2GENE_4752_post(NamedTuple):
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4752_post:
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_TX2GENE_4752_post(
    default: List[Dataclass_4752_post],
    is_skipped: bool,
) -> Respost_adapter_TX2GENE_4752_post:
    return get_mapper_outputs(Respost_adapter_TX2GENE_4752_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4752_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4752_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4752_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4752_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4751),json.loads(default.channel_4734),json.loads(default.channel_4733)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TX2GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def TX2GENE_4752(
    default: Dataclass_4752_pre
) -> Dataclass_4752_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4751),json.loads(default.channel_4734),json.loads(default.channel_4733)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TX2GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TX2GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4752_post(
        tsv=out_channels.get(f"tsv"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4755(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4755(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4752_0: typing.Union[str, None]
) -> Rescollect_4755:
    cond = ((condition_4728 == True) and (channel_4752_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4752_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4755(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4756_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4754: str
    channel_4755: str
    channel_4734: str


class Res_4756_pre(NamedTuple):
    default: typing.List[Dataclass_4756_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_TXIMPORT_4756_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4754: typing.Union[str, None],
    channel_4755: typing.Union[str, None],
    channel_4734: typing.Union[str, None]
) -> Res_4756_pre:
    cond = ((condition_4728 == True) and (channel_4754 is not None) and (channel_4755 is not None) and (channel_4734 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4756_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4754': channel_4754, 'channel_4755': channel_4755, 'channel_4734': channel_4734})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4756_pre(default=result, is_skipped = not cond)

class Respost_adapter_TXIMPORT_4756_post(NamedTuple):
    tpm_gene: typing.Union[str, None]
    counts_gene: typing.Union[str, None]
    counts_gene_length_scaled: typing.Union[str, None]
    counts_gene_scaled: typing.Union[str, None]
    lengths_gene: typing.Union[str, None]
    tpm_transcript: typing.Union[str, None]
    counts_transcript: typing.Union[str, None]
    lengths_transcript: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4756_post:
    tpm_gene: str
    counts_gene: str
    counts_gene_length_scaled: str
    counts_gene_scaled: str
    lengths_gene: str
    tpm_transcript: str
    counts_transcript: str
    lengths_transcript: str
    versions: str

@task(cache=True)
def post_adapter_TXIMPORT_4756_post(
    default: List[Dataclass_4756_post],
    is_skipped: bool,
) -> Respost_adapter_TXIMPORT_4756_post:
    return get_mapper_outputs(Respost_adapter_TXIMPORT_4756_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4756_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4756_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4756_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4756_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4754),json.loads(default.channel_4755),json.loads(default.channel_4734)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TXIMPORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_length_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def TXIMPORT_4756(
    default: Dataclass_4756_pre
) -> Dataclass_4756_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4754),json.loads(default.channel_4755),json.loads(default.channel_4734)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"TXIMPORT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_length_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene_scaled\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lengths_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"TXIMPORT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4756_post(
        tpm_gene=out_channels.get(f"tpm_gene"),
        counts_gene=out_channels.get(f"counts_gene"),
        counts_gene_length_scaled=out_channels.get(f"counts_gene_length_scaled"),
        counts_gene_scaled=out_channels.get(f"counts_gene_scaled"),
        lengths_gene=out_channels.get(f"lengths_gene"),
        tpm_transcript=out_channels.get(f"tpm_transcript"),
        counts_transcript=out_channels.get(f"counts_transcript"),
        lengths_transcript=out_channels.get(f"lengths_transcript"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4761(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4761(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4752_0: typing.Union[str, None]
) -> Rescollect_4761:
    cond = ((condition_4728 == True) and (channel_4752_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4752_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4761(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4762_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4756_2: str
    channel_4756_0: str
    channel_4761: str


class Res_4762_pre(NamedTuple):
    default: typing.List[Dataclass_4762_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_GENE_LENGTH_SCALED_4762_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4756_2: typing.Union[str, None],
    channel_4756_0: typing.Union[str, None],
    channel_4761: typing.Union[str, None]
) -> Res_4762_pre:
    cond = ((condition_4728 == True) and (channel_4756_2 is not None) and (channel_4756_0 is not None) and (channel_4761 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4762_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4756_2': channel_4756_2, 'channel_4756_0': channel_4756_0, 'channel_4761': channel_4761})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4762_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_GENE_LENGTH_SCALED_4762_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4762_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_GENE_LENGTH_SCALED_4762_post(
    default: List[Dataclass_4762_post],
    is_skipped: bool,
) -> Respost_adapter_SE_GENE_LENGTH_SCALED_4762_post:
    return get_mapper_outputs(Respost_adapter_SE_GENE_LENGTH_SCALED_4762_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4762_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4762_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4762_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4762_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_2),json.loads(default.channel_4756_0),json.loads(default.channel_4761)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_LENGTH_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_GENE_LENGTH_SCALED_4762(
    default: Dataclass_4762_pre
) -> Dataclass_4762_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_2),json.loads(default.channel_4756_0),json.loads(default.channel_4761)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_LENGTH_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_LENGTH_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4762_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4763(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4763(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4752_0: typing.Union[str, None]
) -> Rescollect_4763:
    cond = ((condition_4728 == True) and (channel_4752_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4752_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4763(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4764_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4756_3: str
    channel_4756_0: str
    channel_4763: str


class Res_4764_pre(NamedTuple):
    default: typing.List[Dataclass_4764_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_GENE_SCALED_4764_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4756_3: typing.Union[str, None],
    channel_4756_0: typing.Union[str, None],
    channel_4763: typing.Union[str, None]
) -> Res_4764_pre:
    cond = ((condition_4728 == True) and (channel_4756_3 is not None) and (channel_4756_0 is not None) and (channel_4763 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4764_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4756_3': channel_4756_3, 'channel_4756_0': channel_4756_0, 'channel_4763': channel_4763})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4764_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_GENE_SCALED_4764_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4764_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_GENE_SCALED_4764_post(
    default: List[Dataclass_4764_post],
    is_skipped: bool,
) -> Respost_adapter_SE_GENE_SCALED_4764_post:
    return get_mapper_outputs(Respost_adapter_SE_GENE_SCALED_4764_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4764_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4764_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4764_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4764_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_3),json.loads(default.channel_4756_0),json.loads(default.channel_4763)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_GENE_SCALED_4764(
    default: Dataclass_4764_pre
) -> Dataclass_4764_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_3),json.loads(default.channel_4756_0),json.loads(default.channel_4763)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE_SCALED","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE_SCALED\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4764_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4765(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4765(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4752_0: typing.Union[str, None]
) -> Rescollect_4765:
    cond = ((condition_4728 == True) and (channel_4752_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4752_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4765(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4766_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4756_6: str
    channel_4756_5: str
    channel_4765: str


class Res_4766_pre(NamedTuple):
    default: typing.List[Dataclass_4766_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_TRANSCRIPT_4766_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4756_6: typing.Union[str, None],
    channel_4756_5: typing.Union[str, None],
    channel_4765: typing.Union[str, None]
) -> Res_4766_pre:
    cond = ((condition_4728 == True) and (channel_4756_6 is not None) and (channel_4756_5 is not None) and (channel_4765 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4766_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4756_6': channel_4756_6, 'channel_4756_5': channel_4756_5, 'channel_4765': channel_4765})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4766_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_TRANSCRIPT_4766_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4766_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_TRANSCRIPT_4766_post(
    default: List[Dataclass_4766_post],
    is_skipped: bool,
) -> Respost_adapter_SE_TRANSCRIPT_4766_post:
    return get_mapper_outputs(Respost_adapter_SE_TRANSCRIPT_4766_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4766_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4766_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4766_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4766_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_6),json.loads(default.channel_4756_5),json.loads(default.channel_4765)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_TRANSCRIPT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_TRANSCRIPT_4766(
    default: Dataclass_4766_pre
) -> Dataclass_4766_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_6),json.loads(default.channel_4756_5),json.loads(default.channel_4765)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_TRANSCRIPT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_TRANSCRIPT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4766_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Resparams_skip_multiqc_4785(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_multiqc_4785(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_multiqc_4785:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_multiqc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_multiqc_4785(
        res=out_channels.get("res")
    )


class Resparams_skip_multiqc_4786(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_multiqc_4786(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4785: typing.Union[str, None]
) -> Resparams_skip_multiqc_4786:
    cond = ((channel_4785 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4785)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_multiqc_4786(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_multiqc_4787(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_multiqc_4787(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4786: typing.Union[str, None]
) -> Resconditional_params_skip_multiqc_4787:
    cond = ((channel_4786 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4786)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_multiqc_4787(condition=res)


class ResWorkflowRnaseq_paramsSummaryMultiqc_workflow__summary_params__4788(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def WorkflowRnaseq_paramsSummaryMultiqc_workflow__summary_params__4788(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None]
) -> ResWorkflowRnaseq_paramsSummaryMultiqc_workflow__summary_params__4788:
    cond = ((condition_4787 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"WorkflowRnaseq"},"method":"paramsSummaryMultiqc","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"workflow"},{"VariableExpression":"summary_params"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResWorkflowRnaseq_paramsSummaryMultiqc_workflow__summary_params__4788(
        res=out_channels.get("res")
    )


class ResWorkflowRnaseq_methodsDescriptionText_workflow__ch_multiqc_custo_4790(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def WorkflowRnaseq_methodsDescriptionText_workflow__ch_multiqc_custo_4790(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None]
) -> ResWorkflowRnaseq_methodsDescriptionText_workflow__ch_multiqc_custo_4790:
    cond = ((condition_4787 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"WorkflowRnaseq"},"method":"methodsDescriptionText","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"workflow"},{"VariableExpression":"ch_multiqc_custom_methods_description"},{"VariableExpression":"params"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResWorkflowRnaseq_methodsDescriptionText_workflow__ch_multiqc_custo_4790(
        res=out_channels.get("res")
    )


class Rescollect_4792(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4792(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None]
) -> Rescollect_4792:
    cond = ((condition_4787 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4792(
        res=out_channels.get("res")
    )


class ResifEmpty_4793(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4793(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4792: typing.Union[str, None]
) -> ResifEmpty_4793:
    cond = ((condition_4787 == True) and (channel_4792 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4792)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4793(
        res=out_channels.get("res")
    )


class Resparams_skip_qc_4768(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qc_4768(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Resparams_skip_qc_4768:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qc_4768(
        res=out_channels.get("res")
    )


class Resparams_skip_deseq2_qc_4769(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_deseq2_qc_4769(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> Resparams_skip_deseq2_qc_4769:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_deseq2_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_deseq2_qc_4769(
        res=out_channels.get("res")
    )


class Res_params_skip_qc____params_skip_deseq2_qc__4770(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_qc____params_skip_deseq2_qc__4770(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4768: typing.Union[str, None],
    channel_4769: typing.Union[str, None]
) -> Res_params_skip_qc____params_skip_deseq2_qc__4770:
    cond = ((condition_4728 == True) and (channel_4768 is not None) and (channel_4769 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4768), json.loads(channel_4769)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_qc____params_skip_deseq2_qc__4770(
        res=out_channels.get("res")
    )


class Res_params_skip_qc____params_skip_deseq2_qc__4771(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_qc____params_skip_deseq2_qc__4771(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4770: typing.Union[str, None]
) -> Res_params_skip_qc____params_skip_deseq2_qc__4771:
    cond = ((condition_4728 == True) and (channel_4770 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4770)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_qc____params_skip_deseq2_qc__4771(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_qc____params_skip_deseq2_qc__4772(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_qc____params_skip_deseq2_qc__4772(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4771: typing.Union[str, None]
) -> Resconditional__params_skip_qc____params_skip_deseq2_qc__4772:
    cond = ((condition_4728 == True) and (channel_4771 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4771)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_qc____params_skip_deseq2_qc__4772(condition=res)


class Resparams_skip_dupradar_4579(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_dupradar_4579(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None]
) -> Resparams_skip_dupradar_4579:
    cond = ((condition_4569 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_dupradar"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_dupradar_4579(
        res=out_channels.get("res")
    )


class Resparams_skip_dupradar_4580(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_dupradar_4580(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4579: typing.Union[str, None]
) -> Resparams_skip_dupradar_4580:
    cond = ((condition_4569 == True) and (channel_4579 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4579)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_dupradar_4580(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_dupradar_4581(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_dupradar_4581(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4580: typing.Union[str, None]
) -> Resconditional_params_skip_dupradar_4581:
    cond = ((condition_4569 == True) and (channel_4580 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4580)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_dupradar_4581(condition=res)


class Resparams_skip_qualimap_4570(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qualimap_4570(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None]
) -> Resparams_skip_qualimap_4570:
    cond = ((condition_4569 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qualimap"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qualimap_4570(
        res=out_channels.get("res")
    )


class Resparams_skip_qualimap_4571(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qualimap_4571(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4570: typing.Union[str, None]
) -> Resparams_skip_qualimap_4571:
    cond = ((condition_4569 == True) and (channel_4570 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4570)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qualimap_4571(
        res=out_channels.get("res")
    )


class Resconditional_params_skip_qualimap_4572(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional_params_skip_qualimap_4572(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4571: typing.Union[str, None]
) -> Resconditional_params_skip_qualimap_4572:
    cond = ((condition_4569 == True) and (channel_4571 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4571)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional_params_skip_qualimap_4572(condition=res)


class Resparams_skip_alignment_4509(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4509(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4509:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4509(
        res=out_channels.get("res")
    )


class Resparams_skip_qc_4510(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qc_4510(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_qc_4510:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qc_4510(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_qc__4511(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_qc__4511(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4509: typing.Union[str, None],
    channel_4510: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_qc__4511:
    cond = ((channel_4509 is not None) and (channel_4510 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4509), json.loads(channel_4510)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_qc__4511(
        res=out_channels.get("res")
    )


class Resparams_skip_biotype_qc_4512(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_biotype_qc_4512(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_biotype_qc_4512:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_biotype_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_biotype_qc_4512(
        res=out_channels.get("res")
    )


class Res__params_skip_alignment____params_skip_qc_____params_skip_biotyp_4513(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_skip_alignment____params_skip_qc_____params_skip_biotyp_4513(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4511: typing.Union[str, None],
    channel_4512: typing.Union[str, None]
) -> Res__params_skip_alignment____params_skip_qc_____params_skip_biotyp_4513:
    cond = ((channel_4511 is not None) and (channel_4512 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4511), json.loads(channel_4512)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_skip_alignment____params_skip_qc_____params_skip_biotyp_4513(
        res=out_channels.get("res")
    )


class Res___params_skip_alignment____params_skip_qc_____params_skip_bioty_4514(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___params_skip_alignment____params_skip_qc_____params_skip_bioty_4514(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4513: typing.Union[str, None],
    channel_3576: typing.Union[str, None]
) -> Res___params_skip_alignment____params_skip_qc_____params_skip_bioty_4514:
    cond = ((channel_4513 is not None) and (channel_3576 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4513), json.loads(channel_3576)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res___params_skip_alignment____params_skip_qc_____params_skip_bioty_4514(
        res=out_channels.get("res")
    )


class Res___params_skip_alignment____params_skip_qc_____params_skip_bioty_4515(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ___params_skip_alignment____params_skip_qc_____params_skip_bioty_4515(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4514: typing.Union[str, None]
) -> Res___params_skip_alignment____params_skip_qc_____params_skip_bioty_4515:
    cond = ((channel_4514 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4514)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res___params_skip_alignment____params_skip_qc_____params_skip_bioty_4515(
        res=out_channels.get("res")
    )


class Resconditional____params_skip_alignment____params_skip_qc_____params_skip_bioty_4516(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional____params_skip_alignment____params_skip_qc_____params_skip_bioty_4516(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4515: typing.Union[str, None]
) -> Resconditional____params_skip_alignment____params_skip_qc_____params_skip_bioty_4516:
    cond = ((channel_4515 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4515)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional____params_skip_alignment____params_skip_qc_____params_skip_bioty_4516(condition=res)


class Resparams_skip_alignment_4499(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4499(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4499:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4499(
        res=out_channels.get("res")
    )


class Resparams_skip_stringtie_4500(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_stringtie_4500(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_stringtie_4500:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_stringtie"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_stringtie_4500(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_stringtie__4501(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_stringtie__4501(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4499: typing.Union[str, None],
    channel_4500: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_stringtie__4501:
    cond = ((channel_4499 is not None) and (channel_4500 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4499), json.loads(channel_4500)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_stringtie__4501(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_stringtie__4502(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_stringtie__4502(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4501: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_stringtie__4502:
    cond = ((channel_4501 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4501)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_stringtie__4502(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_alignment____params_skip_stringtie__4503(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_alignment____params_skip_stringtie__4503(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4502: typing.Union[str, None]
) -> Resconditional__params_skip_alignment____params_skip_stringtie__4503:
    cond = ((channel_4502 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4502)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_alignment____params_skip_stringtie__4503(condition=res)


class Resparams_skip_alignment_4448(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_alignment_4448(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_alignment_4448:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_alignment"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_alignment_4448(
        res=out_channels.get("res")
    )


class Resparams_skip_qc_4449(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qc_4449(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_qc_4449:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qc_4449(
        res=out_channels.get("res")
    )


class Res_params_skip_alignment____params_skip_qc__4450(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_alignment____params_skip_qc__4450(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4448: typing.Union[str, None],
    channel_4449: typing.Union[str, None]
) -> Res_params_skip_alignment____params_skip_qc__4450:
    cond = ((channel_4448 is not None) and (channel_4449 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4448), json.loads(channel_4449)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_alignment____params_skip_qc__4450(
        res=out_channels.get("res")
    )


class Resparams_skip_preseq_4451(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_preseq_4451(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> Resparams_skip_preseq_4451:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_preseq"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_preseq_4451(
        res=out_channels.get("res")
    )


class Res__params_skip_alignment____params_skip_qc_____params_skip_preseq_4452(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_skip_alignment____params_skip_qc_____params_skip_preseq_4452(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4450: typing.Union[str, None],
    channel_4451: typing.Union[str, None]
) -> Res__params_skip_alignment____params_skip_qc_____params_skip_preseq_4452:
    cond = ((channel_4450 is not None) and (channel_4451 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4450), json.loads(channel_4451)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_skip_alignment____params_skip_qc_____params_skip_preseq_4452(
        res=out_channels.get("res")
    )


class Res__params_skip_alignment____params_skip_qc_____params_skip_preseq_4453(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def __params_skip_alignment____params_skip_qc_____params_skip_preseq_4453(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4452: typing.Union[str, None]
) -> Res__params_skip_alignment____params_skip_qc_____params_skip_preseq_4453:
    cond = ((channel_4452 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4452)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res__params_skip_alignment____params_skip_qc_____params_skip_preseq_4453(
        res=out_channels.get("res")
    )


class Resconditional___params_skip_alignment____params_skip_qc_____params_skip_preseq_4454(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional___params_skip_alignment____params_skip_qc_____params_skip_preseq_4454(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4453: typing.Union[str, None]
) -> Resconditional___params_skip_alignment____params_skip_qc_____params_skip_preseq_4454:
    cond = ((channel_4453 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4453)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional___params_skip_alignment____params_skip_qc_____params_skip_preseq_4454(condition=res)


class Resparams_skip_qc_4332(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qc_4332(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None]
) -> Resparams_skip_qc_4332:
    cond = ((condition_4299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qc_4332(
        res=out_channels.get("res")
    )


class Resparams_skip_deseq2_qc_4333(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_deseq2_qc_4333(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None]
) -> Resparams_skip_deseq2_qc_4333:
    cond = ((condition_4299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_deseq2_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_deseq2_qc_4333(
        res=out_channels.get("res")
    )


class Res_params_skip_qc____params_skip_deseq2_qc__4334(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_qc____params_skip_deseq2_qc__4334(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4332: typing.Union[str, None],
    channel_4333: typing.Union[str, None]
) -> Res_params_skip_qc____params_skip_deseq2_qc__4334:
    cond = ((condition_4299 == True) and (channel_4332 is not None) and (channel_4333 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4332), json.loads(channel_4333)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_qc____params_skip_deseq2_qc__4334(
        res=out_channels.get("res")
    )


class Res_params_skip_qc____params_skip_deseq2_qc__4335(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_qc____params_skip_deseq2_qc__4335(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4334: typing.Union[str, None]
) -> Res_params_skip_qc____params_skip_deseq2_qc__4335:
    cond = ((condition_4299 == True) and (channel_4334 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4334)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_qc____params_skip_deseq2_qc__4335(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_qc____params_skip_deseq2_qc__4336(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_qc____params_skip_deseq2_qc__4336(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4335: typing.Union[str, None]
) -> Resconditional__params_skip_qc____params_skip_deseq2_qc__4336:
    cond = ((condition_4299 == True) and (channel_4335 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4335)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_qc____params_skip_deseq2_qc__4336(condition=res)


class Resparams_skip_qc_4275(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_qc_4275(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_skip_qc_4275:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_qc_4275(
        res=out_channels.get("res")
    )


class Resparams_skip_deseq2_qc_4276(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def params_skip_deseq2_qc_4276(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> Resparams_skip_deseq2_qc_4276:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"NotExpression":{"NotExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"skip_deseq2_qc"}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resparams_skip_deseq2_qc_4276(
        res=out_channels.get("res")
    )


class Res_params_skip_qc____params_skip_deseq2_qc__4277(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_qc____params_skip_deseq2_qc__4277(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4275: typing.Union[str, None],
    channel_4276: typing.Union[str, None]
) -> Res_params_skip_qc____params_skip_deseq2_qc__4277:
    cond = ((condition_4104 == True) and (channel_4275 is not None) and (channel_4276 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4275), json.loads(channel_4276)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"ConstantExpression":"&&"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_qc____params_skip_deseq2_qc__4277(
        res=out_channels.get("res")
    )


class Res_params_skip_qc____params_skip_deseq2_qc__4278(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _params_skip_qc____params_skip_deseq2_qc__4278(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4277: typing.Union[str, None]
) -> Res_params_skip_qc____params_skip_deseq2_qc__4278:
    cond = ((condition_4104 == True) and (channel_4277 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4277)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_params_skip_qc____params_skip_deseq2_qc__4278(
        res=out_channels.get("res")
    )


class Resconditional__params_skip_qc____params_skip_deseq2_qc__4279(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__params_skip_qc____params_skip_deseq2_qc__4279(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4278: typing.Union[str, None]
) -> Resconditional__params_skip_qc____params_skip_deseq2_qc__4279:
    cond = ((condition_4104 == True) and (channel_4278 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4278)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__params_skip_qc____params_skip_deseq2_qc__4279(condition=res)


class ResChannel_empty___3575(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3575(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3575:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3575(
        res=out_channels.get("res")
    )


class ResChannel_empty___3592(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3592(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3592:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3592(
        res=out_channels.get("res")
    )


class Resmix_3599(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3599(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3595: typing.Union[bool, None],
    channel_3592: typing.Union[str, None],
    channel_3597_1: typing.Union[str, None]
) -> Resmix_3599:
    cond = ((condition_3595 == True) and (channel_3592 is not None) and (channel_3597_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3592), json.loads(channel_3597_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3599(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3602(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3602(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3599: typing.Union[str, None],
    channel_3592: typing.Union[str, None]
) -> ResMerge_ch_versions_3602:
    cond = True

    if cond:
        res = { 'res': channel_3599 or channel_3592 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3602(
        res=res.get('res')
    )


class Resmix_3614(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3614(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3610: typing.Union[bool, None],
    channel_3602: typing.Union[str, None],
    channel_3612_1: typing.Union[str, None]
) -> Resmix_3614:
    cond = ((condition_3605 == True) and (condition_3607 == True) and (condition_3610 == True) and (channel_3602 is not None) and (channel_3612_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3602), json.loads(channel_3612_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3614(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3617(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3617(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3614: typing.Union[str, None],
    channel_3602: typing.Union[str, None]
) -> ResMerge_ch_versions_3617:
    cond = ((condition_3605 == True) and (condition_3607 == True))

    if cond:
        res = { 'res': channel_3614 or channel_3602 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3617(
        res=res.get('res')
    )


class Resmix_3626(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3626(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    condition_3622: typing.Union[bool, None],
    channel_3602: typing.Union[str, None],
    channel_3624_1: typing.Union[str, None]
) -> Resmix_3626:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (condition_3622 == True) and (channel_3602 is not None) and (channel_3624_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3602), json.loads(channel_3624_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3626(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3629(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3629(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3626: typing.Union[str, None],
    channel_3602: typing.Union[str, None]
) -> ResMerge_ch_versions_3629:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True))

    if cond:
        res = { 'res': channel_3626 or channel_3602 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3629(
        res=res.get('res')
    )


class Resmix_3631(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3631(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    condition_3619: typing.Union[bool, None],
    channel_3629: typing.Union[str, None],
    channel_3630_1: typing.Union[str, None]
) -> Resmix_3631:
    cond = ((condition_3605 == True) and (condition_3607 == False) and (condition_3619 == True) and (channel_3629 is not None) and (channel_3630_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3629), json.loads(channel_3630_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3631(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3632(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3632(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3607: typing.Union[bool, None],
    channel_3631: typing.Union[str, None],
    channel_3602: typing.Union[str, None]
) -> ResMerge_ch_versions_3632:
    cond = ((condition_3605 == True) and (condition_3607 == False))

    if cond:
        res = { 'res': channel_3631 or channel_3602 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3632(
        res=res.get('res')
    )


class ResMerge_ch_versions_3634(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3634(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3617: typing.Union[str, None],
    channel_3632: typing.Union[str, None]
) -> ResMerge_ch_versions_3634:
    cond = ((condition_3605 == True))

    if cond:
        res = { 'res': channel_3617 or channel_3632 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3634(
        res=res.get('res')
    )


class Resmix_3638(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3638(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    condition_3636: typing.Union[bool, None],
    channel_3634: typing.Union[str, None],
    channel_3637_1: typing.Union[str, None]
) -> Resmix_3638:
    cond = ((condition_3605 == True) and (condition_3636 == True) and (channel_3634 is not None) and (channel_3637_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3634), json.loads(channel_3637_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3638(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3640(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3640(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3605: typing.Union[bool, None],
    channel_3638: typing.Union[str, None],
    channel_3634: typing.Union[str, None]
) -> ResMerge_ch_versions_3640:
    cond = ((condition_3605 == True))

    if cond:
        res = { 'res': channel_3638 or channel_3634 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3640(
        res=res.get('res')
    )


class ResMerge_ch_versions_3641(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3641(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3640: typing.Union[str, None],
    channel_3602: typing.Union[str, None]
) -> ResMerge_ch_versions_3641:
    cond = True

    if cond:
        res = { 'res': channel_3640 or channel_3602 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3641(
        res=res.get('res')
    )


class Resmix_3650(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3650(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    condition_3646: typing.Union[bool, None],
    channel_3641: typing.Union[str, None],
    channel_3648_1: typing.Union[str, None]
) -> Resmix_3650:
    cond = ((condition_3643 == True) and (condition_3646 == True) and (channel_3641 is not None) and (channel_3648_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3641), json.loads(channel_3648_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3650(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3653(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3653(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3650: typing.Union[str, None],
    channel_3641: typing.Union[str, None]
) -> ResMerge_ch_versions_3653:
    cond = ((condition_3643 == True))

    if cond:
        res = { 'res': channel_3650 or channel_3641 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3653(
        res=res.get('res')
    )


class Resmix_3655(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3655(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3643: typing.Union[bool, None],
    channel_3653: typing.Union[str, None],
    channel_3654_2: typing.Union[str, None]
) -> Resmix_3655:
    cond = ((condition_3643 == True) and (channel_3653 is not None) and (channel_3654_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3653), json.loads(channel_3654_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3655(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3657(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3657(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3655: typing.Union[str, None],
    channel_3641: typing.Union[str, None]
) -> ResMerge_ch_versions_3657:
    cond = True

    if cond:
        res = { 'res': channel_3655 or channel_3641 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3657(
        res=res.get('res')
    )


class Resmix_3667(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3667(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    condition_3663: typing.Union[bool, None],
    channel_3657: typing.Union[str, None],
    channel_3665_1: typing.Union[str, None]
) -> Resmix_3667:
    cond = ((condition_3660 == True) and (condition_3663 == True) and (channel_3657 is not None) and (channel_3665_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3657), json.loads(channel_3665_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3667(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3670(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3670(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3667: typing.Union[str, None],
    channel_3657: typing.Union[str, None]
) -> ResMerge_ch_versions_3670:
    cond = ((condition_3660 == True))

    if cond:
        res = { 'res': channel_3667 or channel_3657 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3670(
        res=res.get('res')
    )


class Resmix_3672(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3672(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3660: typing.Union[bool, None],
    channel_3657: typing.Union[str, None],
    channel_3671_1: typing.Union[str, None]
) -> Resmix_3672:
    cond = ((condition_3660 == False) and (channel_3657 is not None) and (channel_3671_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3657), json.loads(channel_3671_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3672(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3674(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3674(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3670: typing.Union[str, None],
    channel_3672: typing.Union[str, None]
) -> ResMerge_ch_versions_3674:
    cond = True

    if cond:
        res = { 'res': channel_3670 or channel_3672 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3674(
        res=res.get('res')
    )


class Resmix_3683(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3683(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3679: typing.Union[bool, None],
    channel_3674: typing.Union[str, None],
    channel_3681_1: typing.Union[str, None]
) -> Resmix_3683:
    cond = ((condition_3676 == True) and (condition_3679 == True) and (channel_3674 is not None) and (channel_3681_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3674), json.loads(channel_3681_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3683(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3686(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3686(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3683: typing.Union[str, None],
    channel_3674: typing.Union[str, None]
) -> ResMerge_ch_versions_3686:
    cond = ((condition_3676 == True))

    if cond:
        res = { 'res': channel_3683 or channel_3674 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3686(
        res=res.get('res')
    )


class Resmix_3690(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3690(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    condition_3688: typing.Union[bool, None],
    channel_3686: typing.Union[str, None],
    channel_3689_1: typing.Union[str, None]
) -> Resmix_3690:
    cond = ((condition_3676 == True) and (condition_3688 == True) and (channel_3686 is not None) and (channel_3689_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3686), json.loads(channel_3689_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3690(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3692(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3692(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3690: typing.Union[str, None],
    channel_3686: typing.Union[str, None]
) -> ResMerge_ch_versions_3692:
    cond = ((condition_3676 == True))

    if cond:
        res = { 'res': channel_3690 or channel_3686 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3692(
        res=res.get('res')
    )


class Resmix_3694(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3694(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3676: typing.Union[bool, None],
    channel_3674: typing.Union[str, None],
    channel_3693_2: typing.Union[str, None]
) -> Resmix_3694:
    cond = ((condition_3676 == False) and (channel_3674 is not None) and (channel_3693_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3674), json.loads(channel_3693_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3694(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3696(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3696(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3692: typing.Union[str, None],
    channel_3694: typing.Union[str, None]
) -> ResMerge_ch_versions_3696:
    cond = True

    if cond:
        res = { 'res': channel_3692 or channel_3694 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3696(
        res=res.get('res')
    )


class Resmix_3701(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3701(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3696: typing.Union[str, None],
    channel_3698_3: typing.Union[str, None]
) -> Resmix_3701:
    cond = ((channel_3696 is not None) and (channel_3698_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3696), json.loads(channel_3698_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3701(
        res=out_channels.get("res")
    )


class Resmix_3714(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3714(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    condition_3710: typing.Union[bool, None],
    channel_3701: typing.Union[str, None],
    channel_3712_1: typing.Union[str, None]
) -> Resmix_3714:
    cond = ((condition_3705 == True) and (condition_3707 == True) and (condition_3710 == True) and (channel_3701 is not None) and (channel_3712_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3701), json.loads(channel_3712_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3714(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3717(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3717(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3714: typing.Union[str, None],
    channel_3701: typing.Union[str, None]
) -> ResMerge_ch_versions_3717:
    cond = ((condition_3705 == True) and (condition_3707 == True))

    if cond:
        res = { 'res': channel_3714 or channel_3701 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3717(
        res=res.get('res')
    )


class Resmix_3725(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3725(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    condition_3707: typing.Union[bool, None],
    channel_3701: typing.Union[str, None],
    channel_3724_4: typing.Union[str, None]
) -> Resmix_3725:
    cond = ((condition_3705 == True) and (condition_3707 == False) and (channel_3701 is not None) and (channel_3724_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3701), json.loads(channel_3724_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3725(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3727(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3727(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3705: typing.Union[bool, None],
    channel_3717: typing.Union[str, None],
    channel_3725: typing.Union[str, None]
) -> ResMerge_ch_versions_3727:
    cond = ((condition_3705 == True))

    if cond:
        res = { 'res': channel_3717 or channel_3725 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3727(
        res=res.get('res')
    )


class ResMerge_ch_versions_3729(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3729(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3727: typing.Union[str, None],
    channel_3701: typing.Union[str, None]
) -> ResMerge_ch_versions_3729:
    cond = True

    if cond:
        res = { 'res': channel_3727 or channel_3701 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3729(
        res=res.get('res')
    )


class Resmix_3742(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3742(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3738: typing.Union[bool, None],
    channel_3729: typing.Union[str, None],
    channel_3740_1: typing.Union[str, None]
) -> Resmix_3742:
    cond = ((condition_3733 == True) and (condition_3735 == True) and (condition_3738 == True) and (channel_3729 is not None) and (channel_3740_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3729), json.loads(channel_3740_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3742(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3745(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3745(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3742: typing.Union[str, None],
    channel_3729: typing.Union[str, None]
) -> ResMerge_ch_versions_3745:
    cond = ((condition_3733 == True) and (condition_3735 == True))

    if cond:
        res = { 'res': channel_3742 or channel_3729 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3745(
        res=res.get('res')
    )


class Resmix_3749(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3749(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3729: typing.Union[str, None],
    channel_3748_1: typing.Union[str, None]
) -> Resmix_3749:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == True) and (channel_3729 is not None) and (channel_3748_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3729), json.loads(channel_3748_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3749(
        res=out_channels.get("res")
    )


class Resmix_3754(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3754(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    condition_3747: typing.Union[bool, None],
    channel_3729: typing.Union[str, None],
    channel_3752_1: typing.Union[str, None]
) -> Resmix_3754:
    cond = ((condition_3733 == True) and (condition_3735 == False) and (condition_3747 == False) and (channel_3729 is not None) and (channel_3752_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3729), json.loads(channel_3752_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3754(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3756(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3756(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    condition_3735: typing.Union[bool, None],
    channel_3749: typing.Union[str, None],
    channel_3754: typing.Union[str, None]
) -> ResMerge_ch_versions_3756:
    cond = ((condition_3733 == True) and (condition_3735 == False))

    if cond:
        res = { 'res': channel_3749 or channel_3754 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3756(
        res=res.get('res')
    )


class ResMerge_ch_versions_3758(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3758(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3733: typing.Union[bool, None],
    channel_3745: typing.Union[str, None],
    channel_3756: typing.Union[str, None]
) -> ResMerge_ch_versions_3758:
    cond = ((condition_3733 == True))

    if cond:
        res = { 'res': channel_3745 or channel_3756 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3758(
        res=res.get('res')
    )


class ResMerge_ch_versions_3760(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3760(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3758: typing.Union[str, None],
    channel_3729: typing.Union[str, None]
) -> ResMerge_ch_versions_3760:
    cond = True

    if cond:
        res = { 'res': channel_3758 or channel_3729 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3760(
        res=res.get('res')
    )


class Resmix_3773(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3773(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    condition_3769: typing.Union[bool, None],
    channel_3760: typing.Union[str, None],
    channel_3771_1: typing.Union[str, None]
) -> Resmix_3773:
    cond = ((condition_3764 == True) and (condition_3766 == True) and (condition_3769 == True) and (channel_3760 is not None) and (channel_3771_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3760), json.loads(channel_3771_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3773(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3776(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3776(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3773: typing.Union[str, None],
    channel_3760: typing.Union[str, None]
) -> ResMerge_ch_versions_3776:
    cond = ((condition_3764 == True) and (condition_3766 == True))

    if cond:
        res = { 'res': channel_3773 or channel_3760 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3776(
        res=res.get('res')
    )


class Resmix_3778(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3778(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    condition_3766: typing.Union[bool, None],
    channel_3760: typing.Union[str, None],
    channel_3777_2: typing.Union[str, None]
) -> Resmix_3778:
    cond = ((condition_3764 == True) and (condition_3766 == False) and (channel_3760 is not None) and (channel_3777_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3760), json.loads(channel_3777_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3778(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3780(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3780(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3764: typing.Union[bool, None],
    channel_3776: typing.Union[str, None],
    channel_3778: typing.Union[str, None]
) -> ResMerge_ch_versions_3780:
    cond = ((condition_3764 == True))

    if cond:
        res = { 'res': channel_3776 or channel_3778 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3780(
        res=res.get('res')
    )


class ResMerge_ch_versions_3782(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3782(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3780: typing.Union[str, None],
    channel_3760: typing.Union[str, None]
) -> ResMerge_ch_versions_3782:
    cond = True

    if cond:
        res = { 'res': channel_3780 or channel_3760 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3782(
        res=res.get('res')
    )


class Resmix_3794(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3794(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3790: typing.Union[bool, None],
    channel_3782: typing.Union[str, None],
    channel_3792_1: typing.Union[str, None]
) -> Resmix_3794:
    cond = ((condition_3787 == True) and (condition_3790 == True) and (channel_3782 is not None) and (channel_3792_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3782), json.loads(channel_3792_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3794(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3797(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3797(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3794: typing.Union[str, None],
    channel_3782: typing.Union[str, None]
) -> ResMerge_ch_versions_3797:
    cond = ((condition_3787 == True))

    if cond:
        res = { 'res': channel_3794 or channel_3782 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3797(
        res=res.get('res')
    )


class Resmix_3806(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3806(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    condition_3802: typing.Union[bool, None],
    channel_3797: typing.Union[str, None],
    channel_3804_1: typing.Union[str, None]
) -> Resmix_3806:
    cond = ((condition_3787 == True) and (condition_3799 == True) and (condition_3802 == True) and (channel_3797 is not None) and (channel_3804_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3797), json.loads(channel_3804_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3806(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3809(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3809(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3806: typing.Union[str, None],
    channel_3797: typing.Union[str, None]
) -> ResMerge_ch_versions_3809:
    cond = ((condition_3787 == True) and (condition_3799 == True))

    if cond:
        res = { 'res': channel_3806 or channel_3797 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3809(
        res=res.get('res')
    )


class Resmix_3815(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3815(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    condition_3799: typing.Union[bool, None],
    channel_3797: typing.Union[str, None],
    channel_3813_1: typing.Union[str, None]
) -> Resmix_3815:
    cond = ((condition_3787 == True) and (condition_3799 == False) and (channel_3797 is not None) and (channel_3813_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3797), json.loads(channel_3813_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3815(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3817(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3817(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3787: typing.Union[bool, None],
    channel_3809: typing.Union[str, None],
    channel_3815: typing.Union[str, None]
) -> ResMerge_ch_versions_3817:
    cond = ((condition_3787 == True))

    if cond:
        res = { 'res': channel_3809 or channel_3815 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3817(
        res=res.get('res')
    )


class ResMerge_ch_versions_3820(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3820(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3817: typing.Union[str, None],
    channel_3782: typing.Union[str, None]
) -> ResMerge_ch_versions_3820:
    cond = True

    if cond:
        res = { 'res': channel_3817 or channel_3782 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3820(
        res=res.get('res')
    )


class Resmix_3830(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3830(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3826: typing.Union[bool, None],
    channel_3820: typing.Union[str, None],
    channel_3828_1: typing.Union[str, None]
) -> Resmix_3830:
    cond = ((condition_3823 == True) and (condition_3826 == True) and (channel_3820 is not None) and (channel_3828_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3820), json.loads(channel_3828_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3830(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3833(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3833(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3830: typing.Union[str, None],
    channel_3820: typing.Union[str, None]
) -> ResMerge_ch_versions_3833:
    cond = ((condition_3823 == True))

    if cond:
        res = { 'res': channel_3830 or channel_3820 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3833(
        res=res.get('res')
    )


class Resmix_3838(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3838(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    condition_3836: typing.Union[bool, None],
    channel_3820: typing.Union[str, None],
    channel_3837_1: typing.Union[str, None]
) -> Resmix_3838:
    cond = ((condition_3823 == False) and (condition_3836 == True) and (channel_3820 is not None) and (channel_3837_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3820), json.loads(channel_3837_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3838(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3840(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3840(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3823: typing.Union[bool, None],
    channel_3838: typing.Union[str, None],
    channel_3820: typing.Union[str, None]
) -> ResMerge_ch_versions_3840:
    cond = ((condition_3823 == False))

    if cond:
        res = { 'res': channel_3838 or channel_3820 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3840(
        res=res.get('res')
    )


class ResMerge_ch_versions_3842(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3842(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3833: typing.Union[str, None],
    channel_3840: typing.Union[str, None]
) -> ResMerge_ch_versions_3842:
    cond = True

    if cond:
        res = { 'res': channel_3833 or channel_3840 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3842(
        res=res.get('res')
    )


class Resmix_3851(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3851(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3848: typing.Union[bool, None],
    channel_3842: typing.Union[str, None],
    channel_3850_1: typing.Union[str, None]
) -> Resmix_3851:
    cond = ((condition_3845 == True) and (condition_3848 == True) and (channel_3842 is not None) and (channel_3850_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3842), json.loads(channel_3850_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3851(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3854(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3854(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3851: typing.Union[str, None],
    channel_3842: typing.Union[str, None]
) -> ResMerge_ch_versions_3854:
    cond = ((condition_3845 == True))

    if cond:
        res = { 'res': channel_3851 or channel_3842 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3854(
        res=res.get('res')
    )


class Resmix_3860(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3860(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    condition_3857: typing.Union[bool, None],
    channel_3842: typing.Union[str, None],
    channel_3859_1: typing.Union[str, None]
) -> Resmix_3860:
    cond = ((condition_3845 == False) and (condition_3857 == True) and (channel_3842 is not None) and (channel_3859_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3842), json.loads(channel_3859_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3860(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3862(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3862(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3845: typing.Union[bool, None],
    channel_3860: typing.Union[str, None],
    channel_3842: typing.Union[str, None]
) -> ResMerge_ch_versions_3862:
    cond = ((condition_3845 == False))

    if cond:
        res = { 'res': channel_3860 or channel_3842 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3862(
        res=res.get('res')
    )


class ResMerge_ch_versions_3864(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3864(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3854: typing.Union[str, None],
    channel_3862: typing.Union[str, None]
) -> ResMerge_ch_versions_3864:
    cond = True

    if cond:
        res = { 'res': channel_3854 or channel_3862 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3864(
        res=res.get('res')
    )


class ResifEmpty_3865(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_3865(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3864: typing.Union[str, None]
) -> ResifEmpty_3865:
    cond = ((channel_3864 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3864)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/prepare_genome/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'PREPARE_GENOME'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":null}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_3865(
        res=out_channels.get("res")
    )


class Resmix_3866(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3866(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3575: typing.Union[str, None],
    channel_3865: typing.Union[str, None]
) -> Resmix_3866:
    cond = ((channel_3575 is not None) and (channel_3865 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3575), json.loads(channel_3865)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3866(
        res=out_channels.get("res")
    )


class Resfirst_3880(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_3880(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3878_1: typing.Union[str, None]
) -> Resfirst_3880:
    cond = ((channel_3878_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3878_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_3880(
        res=out_channels.get("res")
    )


class ResifEmpty_3881(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_3881(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3880: typing.Union[str, None]
) -> ResifEmpty_3881:
    cond = ((channel_3880 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3880)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":null}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_3881(
        res=out_channels.get("res")
    )


class Resmix_3882(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3882(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3866: typing.Union[str, None],
    channel_3881: typing.Union[str, None]
) -> Resmix_3882:
    cond = ((channel_3866 is not None) and (channel_3881 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3866), json.loads(channel_3881)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3882(
        res=out_channels.get("res")
    )


class ResChannel_empty___3897(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3897(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3897:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3897(
        res=out_channels.get("res")
    )


class Resfirst_3904(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_3904(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3902: typing.Union[bool, None],
    channel_3903_2: typing.Union[str, None]
) -> Resfirst_3904:
    cond = ((condition_3890 == True) and (condition_3902 == True) and (channel_3903_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3903_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_3904(
        res=out_channels.get("res")
    )


class Resmix_3905(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3905(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3902: typing.Union[bool, None],
    channel_3897: typing.Union[str, None],
    channel_3904: typing.Union[str, None]
) -> Resmix_3905:
    cond = ((condition_3890 == True) and (condition_3902 == True) and (channel_3897 is not None) and (channel_3904 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3897), json.loads(channel_3904)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3905(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3908(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3908(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3905: typing.Union[str, None],
    channel_3897: typing.Union[str, None]
) -> ResMerge_ch_versions_3908:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3905 or channel_3897 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3908(
        res=res.get('res')
    )


class Resfirst_3915(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_3915(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3914_2: typing.Union[str, None]
) -> Resfirst_3915:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (channel_3914_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3914_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_3915(
        res=out_channels.get("res")
    )


class Resmix_3916(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3916(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3913: typing.Union[bool, None],
    channel_3908: typing.Union[str, None],
    channel_3915: typing.Union[str, None]
) -> Resmix_3916:
    cond = ((condition_3890 == True) and (condition_3913 == True) and (channel_3908 is not None) and (channel_3915 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3908), json.loads(channel_3915)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3916(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3924(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3924(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3916: typing.Union[str, None],
    channel_3908: typing.Union[str, None]
) -> ResMerge_ch_versions_3924:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3916 or channel_3908 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3924(
        res=res.get('res')
    )


class Resfirst_3934(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_3934(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3933_5: typing.Union[str, None]
) -> Resfirst_3934:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3933_5 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3933_5)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_3934(
        res=out_channels.get("res")
    )


class Resmix_3935(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3935(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3924: typing.Union[str, None],
    channel_3934: typing.Union[str, None]
) -> Resmix_3935:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3924 is not None) and (channel_3934 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3924), json.loads(channel_3934)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3935(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3947(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3947(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3935: typing.Union[str, None],
    channel_3924: typing.Union[str, None]
) -> ResMerge_ch_versions_3947:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3935 or channel_3924 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3947(
        res=res.get('res')
    )


class ResifEmpty_3948(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_3948(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3947: typing.Union[str, None]
) -> ResifEmpty_3948:
    cond = ((condition_3890 == True) and (channel_3947 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3947)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":null}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_3948(
        res=out_channels.get("res")
    )


class Resmix_3949(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3949(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3882: typing.Union[str, None],
    channel_3948: typing.Union[str, None]
) -> Resmix_3949:
    cond = ((condition_3890 == True) and (channel_3882 is not None) and (channel_3948 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3882), json.loads(channel_3948)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3949(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3955(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3955(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3949: typing.Union[str, None],
    channel_3882: typing.Union[str, None]
) -> ResMerge_ch_versions_3955:
    cond = True

    if cond:
        res = { 'res': channel_3949 or channel_3882 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3955(
        res=res.get('res')
    )


class ResChannel_empty___3968(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3968(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3968:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3968(
        res=out_channels.get("res")
    )


class Resfirst_3975(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_3975(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3973: typing.Union[bool, None],
    channel_3974_2: typing.Union[str, None]
) -> Resfirst_3975:
    cond = ((condition_3958 == True) and (condition_3973 == True) and (channel_3974_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3974_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_3975(
        res=out_channels.get("res")
    )


class Resmix_3976(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3976(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3973: typing.Union[bool, None],
    channel_3968: typing.Union[str, None],
    channel_3975: typing.Union[str, None]
) -> Resmix_3976:
    cond = ((condition_3958 == True) and (condition_3973 == True) and (channel_3968 is not None) and (channel_3975 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3968), json.loads(channel_3975)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3976(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3979(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3979(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3976: typing.Union[str, None],
    channel_3968: typing.Union[str, None]
) -> ResMerge_ch_versions_3979:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_3976 or channel_3968 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3979(
        res=res.get('res')
    )


class Resfirst_3986(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_3986(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3985_2: typing.Union[str, None]
) -> Resfirst_3986:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (channel_3985_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3985_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_3986(
        res=out_channels.get("res")
    )


class Resmix_3987(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_3987(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_3984: typing.Union[bool, None],
    channel_3979: typing.Union[str, None],
    channel_3986: typing.Union[str, None]
) -> Resmix_3987:
    cond = ((condition_3958 == True) and (condition_3984 == True) and (channel_3979 is not None) and (channel_3986 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3979), json.loads(channel_3986)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_3987(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_3995(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_3995(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3987: typing.Union[str, None],
    channel_3979: typing.Union[str, None]
) -> ResMerge_ch_versions_3995:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_3987 or channel_3979 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_3995(
        res=res.get('res')
    )


class Resfirst_4008(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4008(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4007_4: typing.Union[str, None]
) -> Resfirst_4008:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4007_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4007_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4008(
        res=out_channels.get("res")
    )


class Resmix_4009(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4009(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_3995: typing.Union[str, None],
    channel_4008: typing.Union[str, None]
) -> Resmix_4009:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_3995 is not None) and (channel_4008 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3995), json.loads(channel_4008)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4009(
        res=out_channels.get("res")
    )


class Resfirst_4019(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4019(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    condition_4017: typing.Union[bool, None],
    channel_4018_2: typing.Union[str, None]
) -> Resfirst_4019:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (condition_4017 == True) and (channel_4018_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4018_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4019(
        res=out_channels.get("res")
    )


class Resmix_4020(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4020(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    condition_4017: typing.Union[bool, None],
    channel_4009: typing.Union[str, None],
    channel_4019: typing.Union[str, None]
) -> Resmix_4020:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (condition_4017 == True) and (channel_4009 is not None) and (channel_4019 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4009), json.loads(channel_4019)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4020(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4023(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4023(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4020: typing.Union[str, None],
    channel_4009: typing.Union[str, None]
) -> ResMerge_ch_versions_4023:
    cond = ((condition_3958 == True) and (condition_4006 == True))

    if cond:
        res = { 'res': channel_4020 or channel_4009 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4023(
        res=res.get('res')
    )


class ResMerge_ch_versions_4029(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4029(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4023: typing.Union[str, None],
    channel_3995: typing.Union[str, None]
) -> ResMerge_ch_versions_4029:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4023 or channel_3995 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4029(
        res=res.get('res')
    )


class ResifEmpty_4034(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4034(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4029: typing.Union[str, None]
) -> ResifEmpty_4034:
    cond = ((condition_3958 == True) and (channel_4029 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4029)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":null}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4034(
        res=out_channels.get("res")
    )


class Resmix_4035(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4035(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3955: typing.Union[str, None],
    channel_4034: typing.Union[str, None]
) -> Resmix_4035:
    cond = ((condition_3958 == True) and (channel_3955 is not None) and (channel_4034 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3955), json.loads(channel_4034)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4035(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4041(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4041(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4035: typing.Union[str, None],
    channel_3955: typing.Union[str, None]
) -> ResMerge_ch_versions_4041:
    cond = True

    if cond:
        res = { 'res': channel_4035 or channel_3955 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4041(
        res=res.get('res')
    )


class Resfirst_4049(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4049(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4047: typing.Union[bool, None],
    channel_4048_4: typing.Union[str, None]
) -> Resfirst_4049:
    cond = ((condition_4047 == True) and (channel_4048_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4048_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4049(
        res=out_channels.get("res")
    )


class Resmix_4050(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4050(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4047: typing.Union[bool, None],
    channel_4041: typing.Union[str, None],
    channel_4049: typing.Union[str, None]
) -> Resmix_4050:
    cond = ((condition_4047 == True) and (channel_4041 is not None) and (channel_4049 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4041), json.loads(channel_4049)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4050(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4052(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4052(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4050: typing.Union[str, None],
    channel_4041: typing.Union[str, None]
) -> ResMerge_ch_versions_4052:
    cond = True

    if cond:
        res = { 'res': channel_4050 or channel_4041 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4052(
        res=res.get('res')
    )


class Resfirst_4060(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4060(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4055: typing.Union[bool, None],
    channel_4059_2: typing.Union[str, None]
) -> Resfirst_4060:
    cond = ((condition_4055 == True) and (channel_4059_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4059_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4060(
        res=out_channels.get("res")
    )


class Resmix_4061(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4061(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4055: typing.Union[bool, None],
    channel_4052: typing.Union[str, None],
    channel_4060: typing.Union[str, None]
) -> Resmix_4061:
    cond = ((condition_4055 == True) and (channel_4052 is not None) and (channel_4060 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4052), json.loads(channel_4060)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4061(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4064(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4064(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4061: typing.Union[str, None],
    channel_4052: typing.Union[str, None]
) -> ResMerge_ch_versions_4064:
    cond = True

    if cond:
        res = { 'res': channel_4061 or channel_4052 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4064(
        res=res.get('res')
    )


class ResChannel_empty___4073(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4073(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4073:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4073(
        res=out_channels.get("res")
    )


class Resmix_4077(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4077(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4075: typing.Union[bool, None],
    channel_4073: typing.Union[str, None],
    channel_4076_1: typing.Union[str, None]
) -> Resmix_4077:
    cond = ((condition_4075 == True) and (channel_4073 is not None) and (channel_4076_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4073), json.loads(channel_4076_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4077(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4079(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4079(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4077: typing.Union[str, None],
    channel_4073: typing.Union[str, None]
) -> ResMerge_ch_versions_4079:
    cond = True

    if cond:
        res = { 'res': channel_4077 or channel_4073 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4079(
        res=res.get('res')
    )


class Resfirst_4081(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4081(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4080_1: typing.Union[str, None]
) -> Resfirst_4081:
    cond = ((channel_4080_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4080_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4081(
        res=out_channels.get("res")
    )


class Resmix_4082(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4082(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4079: typing.Union[str, None],
    channel_4081: typing.Union[str, None]
) -> Resmix_4082:
    cond = ((channel_4079 is not None) and (channel_4081 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4079), json.loads(channel_4081)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4082(
        res=out_channels.get("res")
    )


class Resfirst_4086(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4086(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4085_2: typing.Union[str, None]
) -> Resfirst_4086:
    cond = ((channel_4085_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4085_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4086(
        res=out_channels.get("res")
    )


class Resmix_4087(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4087(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4082: typing.Union[str, None],
    channel_4086: typing.Union[str, None]
) -> Resmix_4087:
    cond = ((channel_4082 is not None) and (channel_4086 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4082), json.loads(channel_4086)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_subsample_fq_salmon/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_SUBSAMPLE_FQ_SALMON'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4087(
        res=out_channels.get("res")
    )


class Resmix_4088(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4088(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4064: typing.Union[str, None],
    channel_4087: typing.Union[str, None]
) -> Resmix_4088:
    cond = ((channel_4064 is not None) and (channel_4087 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4064), json.loads(channel_4087)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4088(
        res=out_channels.get("res")
    )


class ResChannel_empty___4111(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4111(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4111:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4111(
        res=out_channels.get("res")
    )


class Resfirst_4123(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4123(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4121: typing.Union[bool, None],
    channel_4122_4: typing.Union[str, None]
) -> Resfirst_4123:
    cond = ((condition_4104 == True) and (condition_4121 == True) and (channel_4122_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4122_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4123(
        res=out_channels.get("res")
    )


class Resmix_4124(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4124(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4121: typing.Union[bool, None],
    channel_4111: typing.Union[str, None],
    channel_4123: typing.Union[str, None]
) -> Resmix_4124:
    cond = ((condition_4104 == True) and (condition_4121 == True) and (channel_4111 is not None) and (channel_4123 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4111), json.loads(channel_4123)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4124(
        res=out_channels.get("res")
    )


class Resfirst_4126(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4126(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4121: typing.Union[bool, None],
    channel_4125_3: typing.Union[str, None]
) -> Resfirst_4126:
    cond = ((condition_4104 == True) and (condition_4121 == False) and (channel_4125_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4125_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4126(
        res=out_channels.get("res")
    )


class Resmix_4127(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4127(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4121: typing.Union[bool, None],
    channel_4111: typing.Union[str, None],
    channel_4126: typing.Union[str, None]
) -> Resmix_4127:
    cond = ((condition_4104 == True) and (condition_4121 == False) and (channel_4111 is not None) and (channel_4126 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4111), json.loads(channel_4126)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4127(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4136(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4136(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4124: typing.Union[str, None],
    channel_4127: typing.Union[str, None]
) -> ResMerge_ch_versions_4136:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4124 or channel_4127 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4136(
        res=res.get('res')
    )


class ResChannel_empty___4137(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4137(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4137:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4137(
        res=out_channels.get("res")
    )


class Resfirst_4139(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4139(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4138_2: typing.Union[str, None]
) -> Resfirst_4139:
    cond = ((condition_4104 == True) and (channel_4138_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4138_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4139(
        res=out_channels.get("res")
    )


class Resmix_4140(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4140(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4137: typing.Union[str, None],
    channel_4139: typing.Union[str, None]
) -> Resmix_4140:
    cond = ((condition_4104 == True) and (channel_4137 is not None) and (channel_4139 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4137), json.loads(channel_4139)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4140(
        res=out_channels.get("res")
    )


class Resfirst_4142(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4142(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4141_3: typing.Union[str, None]
) -> Resfirst_4142:
    cond = ((condition_4104 == True) and (channel_4141_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4141_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4142(
        res=out_channels.get("res")
    )


class Resmix_4143(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4143(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4140: typing.Union[str, None],
    channel_4142: typing.Union[str, None]
) -> Resmix_4143:
    cond = ((condition_4104 == True) and (channel_4140 is not None) and (channel_4142 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4140), json.loads(channel_4142)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4143(
        res=out_channels.get("res")
    )


class ResChannel_empty___4147(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4147(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4147:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4147(
        res=out_channels.get("res")
    )


class Resjoin_4144(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4144(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4138_0: typing.Union[str, None],
    channel_4141_0: typing.Union[str, None]
) -> Resjoin_4144:
    cond = ((condition_4104 == True) and (channel_4138_0 is not None) and (channel_4141_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4138_0), json.loads(channel_4141_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4144(
        res=out_channels.get("res")
    )


class Resjoin_4145(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4145(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4144: typing.Union[str, None],
    channel_4141_1: typing.Union[str, None]
) -> Resjoin_4145:
    cond = ((condition_4104 == True) and (channel_4144 is not None) and (channel_4141_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4144), json.loads(channel_4141_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4145(
        res=out_channels.get("res")
    )


class Resmap_4146(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4146(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4145: typing.Union[str, None]
) -> Resmap_4146:
    cond = ((condition_4104 == True) and (channel_4145 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4145)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4146(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4148_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4146: str


class Res_4148_pre(NamedTuple):
    default: typing.List[Dataclass_4148_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4148_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4146: typing.Union[str, None]
) -> Res_4148_pre:
    cond = ((condition_4104 == True) and (channel_4146 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4148_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4146': channel_4146})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4148_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4148_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4148_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4148_post(
    default: List[Dataclass_4148_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4148_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4148_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4148_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4148_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4148_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4148_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4146)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4148(
    default: Dataclass_4148_pre
) -> Dataclass_4148_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4146)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4148_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4149(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4149(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4147: typing.Union[str, None],
    channel_4148_1: typing.Union[str, None]
) -> Resmix_4149:
    cond = ((condition_4104 == True) and (channel_4147 is not None) and (channel_4148_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4147), json.loads(channel_4148_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4149(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4150_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4146: str


class Res_4150_pre(NamedTuple):
    default: typing.List[Dataclass_4150_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4150_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4146: typing.Union[str, None]
) -> Res_4150_pre:
    cond = ((condition_4104 == True) and (channel_4146 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4150_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4146': channel_4146})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4150_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4150_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4150_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4150_post(
    default: List[Dataclass_4150_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4150_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4150_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4150_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4150_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4150_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4150_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4146)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4150(
    default: Dataclass_4150_pre
) -> Dataclass_4150_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4146)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4150_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4151(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4151(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4149: typing.Union[str, None],
    channel_4150_1: typing.Union[str, None]
) -> Resmix_4151:
    cond = ((condition_4104 == True) and (channel_4149 is not None) and (channel_4150_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4149), json.loads(channel_4150_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4151(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4152_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4146: str


class Res_4152_pre(NamedTuple):
    default: typing.List[Dataclass_4152_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4152_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4146: typing.Union[str, None]
) -> Res_4152_pre:
    cond = ((condition_4104 == True) and (channel_4146 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4152_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4146': channel_4146})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4152_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4152_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4152_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4152_post(
    default: List[Dataclass_4152_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4152_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4152_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4152_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4152_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4152_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4152_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4146)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4152(
    default: Dataclass_4152_pre
) -> Dataclass_4152_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4146)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4152_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4153(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4153(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4151: typing.Union[str, None],
    channel_4152_1: typing.Union[str, None]
) -> Resmix_4153:
    cond = ((condition_4104 == True) and (channel_4151 is not None) and (channel_4152_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4151), json.loads(channel_4152_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4153(
        res=out_channels.get("res")
    )


class Resmix_4154(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4154(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4143: typing.Union[str, None],
    channel_4153: typing.Union[str, None]
) -> Resmix_4154:
    cond = ((condition_4104 == True) and (channel_4143 is not None) and (channel_4153 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4143), json.loads(channel_4153)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4154(
        res=out_channels.get("res")
    )


class Resmix_4155(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4155(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4136: typing.Union[str, None],
    channel_4154: typing.Union[str, None]
) -> Resmix_4155:
    cond = ((condition_4104 == True) and (channel_4136 is not None) and (channel_4154 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4136), json.loads(channel_4154)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/align_star/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'ALIGN_STAR'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4155(
        res=out_channels.get("res")
    )


class Resmix_4159(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4159(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4088: typing.Union[str, None],
    channel_4155: typing.Union[str, None]
) -> Resmix_4159:
    cond = ((condition_4104 == True) and (channel_4088 is not None) and (channel_4155 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4088), json.loads(channel_4155)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4159(
        res=out_channels.get("res")
    )


class Resmix_4186(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4186(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4159: typing.Union[str, None],
    channel_4182: typing.Union[str, None]
) -> Resmix_4186:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4159 is not None) and (channel_4182 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4159), json.loads(channel_4182)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4186(
        res=out_channels.get("res")
    )


class Resfirst_4230(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4230(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4229_2: typing.Union[str, None]
) -> Resfirst_4230:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4229_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4229_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4230(
        res=out_channels.get("res")
    )


class Resmix_4231(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4231(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4161: typing.Union[bool, None],
    channel_4186: typing.Union[str, None],
    channel_4230: typing.Union[str, None]
) -> Resmix_4231:
    cond = ((condition_4104 == True) and (condition_4161 == True) and (channel_4186 is not None) and (channel_4230 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4186), json.loads(channel_4230)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4231(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4235(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4235(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4231: typing.Union[str, None],
    channel_4159: typing.Union[str, None]
) -> ResMerge_ch_versions_4235:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4231 or channel_4159 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4235(
        res=res.get('res')
    )


class ResChannel_empty___4245(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4245(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None]
) -> ResChannel_empty___4245:
    cond = ((condition_4104 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4245(
        res=out_channels.get("res")
    )


class Resfirst_4250(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4250(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4248: typing.Union[bool, None],
    channel_4249_2: typing.Union[str, None]
) -> Resfirst_4250:
    cond = ((condition_4104 == True) and (condition_4248 == True) and (channel_4249_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4249_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4250(
        res=out_channels.get("res")
    )


class Resmix_4251(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4251(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4248: typing.Union[bool, None],
    channel_4245: typing.Union[str, None],
    channel_4250: typing.Union[str, None]
) -> Resmix_4251:
    cond = ((condition_4104 == True) and (condition_4248 == True) and (channel_4245 is not None) and (channel_4250 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4245), json.loads(channel_4250)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4251(
        res=out_channels.get("res")
    )


class Resfirst_4253(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4253(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4248: typing.Union[bool, None],
    channel_4252_3: typing.Union[str, None]
) -> Resfirst_4253:
    cond = ((condition_4104 == True) and (condition_4248 == False) and (channel_4252_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4252_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4253(
        res=out_channels.get("res")
    )


class Resmix_4254(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4254(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4248: typing.Union[bool, None],
    channel_4245: typing.Union[str, None],
    channel_4253: typing.Union[str, None]
) -> Resmix_4254:
    cond = ((condition_4104 == True) and (condition_4248 == False) and (channel_4245 is not None) and (channel_4253 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4245), json.loads(channel_4253)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4254(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4257(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4257(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4251: typing.Union[str, None],
    channel_4254: typing.Union[str, None]
) -> ResMerge_ch_versions_4257:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4251 or channel_4254 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4257(
        res=res.get('res')
    )


class Resmix_4260(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4260(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4257: typing.Union[str, None],
    channel_4259_1: typing.Union[str, None]
) -> Resmix_4260:
    cond = ((condition_4104 == True) and (channel_4257 is not None) and (channel_4259_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4257), json.loads(channel_4259_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4260(
        res=out_channels.get("res")
    )


class Resmix_4264(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4264(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4260: typing.Union[str, None],
    channel_4263_8: typing.Union[str, None]
) -> Resmix_4264:
    cond = ((condition_4104 == True) and (channel_4260 is not None) and (channel_4263_8 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4260), json.loads(channel_4263_8)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4264(
        res=out_channels.get("res")
    )


class Rescollect_4265(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4265(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4259_0: typing.Union[str, None]
) -> Rescollect_4265:
    cond = ((condition_4104 == True) and (channel_4259_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4259_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4265(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4266_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4263_1: str
    channel_4263_0: str
    channel_4265: str


class Res_4266_pre(NamedTuple):
    default: typing.List[Dataclass_4266_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_GENE_4266_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4263_1: typing.Union[str, None],
    channel_4263_0: typing.Union[str, None],
    channel_4265: typing.Union[str, None]
) -> Res_4266_pre:
    cond = ((condition_4104 == True) and (channel_4263_1 is not None) and (channel_4263_0 is not None) and (channel_4265 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4266_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4263_1': channel_4263_1, 'channel_4263_0': channel_4263_0, 'channel_4265': channel_4265})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4266_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_GENE_4266_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4266_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_GENE_4266_post(
    default: List[Dataclass_4266_post],
    is_skipped: bool,
) -> Respost_adapter_SE_GENE_4266_post:
    return get_mapper_outputs(Respost_adapter_SE_GENE_4266_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4266_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4266_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4266_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4266_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_1),json.loads(default.channel_4263_0),json.loads(default.channel_4265)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_GENE_4266(
    default: Dataclass_4266_pre
) -> Dataclass_4266_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_1),json.loads(default.channel_4263_0),json.loads(default.channel_4265)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4266_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4267(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4267(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4264: typing.Union[str, None],
    channel_4266_1: typing.Union[str, None]
) -> Resmix_4267:
    cond = ((condition_4104 == True) and (channel_4264 is not None) and (channel_4266_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4264), json.loads(channel_4266_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4267(
        res=out_channels.get("res")
    )


class Resmix_4274(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4274(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4235: typing.Union[str, None],
    channel_4267: typing.Union[str, None]
) -> Resmix_4274:
    cond = ((condition_4104 == True) and (channel_4235 is not None) and (channel_4267 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4235), json.loads(channel_4267)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4274(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4280_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4263_2: str


class Res_4280_pre(NamedTuple):
    default: typing.List[Dataclass_4280_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_DESEQ2_QC_STAR_SALMON_4280_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4279: typing.Union[bool, None],
    channel_4263_2: typing.Union[str, None]
) -> Res_4280_pre:
    cond = ((condition_4104 == True) and (condition_4279 == True) and (channel_4263_2 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4280_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4263_2': channel_4263_2})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4280_pre(default=result, is_skipped = not cond)

class Respost_adapter_DESEQ2_QC_STAR_SALMON_4280_post(NamedTuple):
    pdf: typing.Union[str, None]
    rdata: typing.Union[str, None]
    pca_txt: typing.Union[str, None]
    pca_multiqc: typing.Union[str, None]
    dists_txt: typing.Union[str, None]
    dists_multiqc: typing.Union[str, None]
    log: typing.Union[str, None]
    size_factors: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4280_post:
    pdf: str
    rdata: str
    pca_txt: str
    pca_multiqc: str
    dists_txt: str
    dists_multiqc: str
    log: str
    size_factors: str
    versions: str

@task(cache=True)
def post_adapter_DESEQ2_QC_STAR_SALMON_4280_post(
    default: List[Dataclass_4280_post],
    is_skipped: bool,
) -> Respost_adapter_DESEQ2_QC_STAR_SALMON_4280_post:
    return get_mapper_outputs(Respost_adapter_DESEQ2_QC_STAR_SALMON_4280_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4280_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4280_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4280_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4280_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_2)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DESEQ2_QC_STAR_SALMON","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_pca_header_multiqc"},{"VariableExpression":"ch_clustering_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rdata\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"size_factors\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def DESEQ2_QC_STAR_SALMON_4280(
    default: Dataclass_4280_pre
) -> Dataclass_4280_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4263_2)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DESEQ2_QC_STAR_SALMON","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_pca_header_multiqc"},{"VariableExpression":"ch_clustering_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rdata\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"size_factors\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_STAR_SALMON\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4280_post(
        pdf=out_channels.get(f"pdf"),
        rdata=out_channels.get(f"rdata"),
        pca_txt=out_channels.get(f"pca_txt"),
        pca_multiqc=out_channels.get(f"pca_multiqc"),
        dists_txt=out_channels.get(f"dists_txt"),
        dists_multiqc=out_channels.get(f"dists_multiqc"),
        log=out_channels.get(f"log"),
        size_factors=out_channels.get(f"size_factors"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4281(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4281(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    condition_4279: typing.Union[bool, None],
    channel_4274: typing.Union[str, None],
    channel_4280_8: typing.Union[str, None]
) -> Resmix_4281:
    cond = ((condition_4104 == True) and (condition_4279 == True) and (channel_4274 is not None) and (channel_4280_8 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4274), json.loads(channel_4280_8)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4281(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4284(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4284(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4281: typing.Union[str, None],
    channel_4274: typing.Union[str, None]
) -> ResMerge_ch_versions_4284:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4281 or channel_4274 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4284(
        res=res.get('res')
    )


class ResMerge_ch_versions_4290(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4290(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4284: typing.Union[str, None],
    channel_4088: typing.Union[str, None]
) -> ResMerge_ch_versions_4290:
    cond = True

    if cond:
        res = { 'res': channel_4284 or channel_4088 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4290(
        res=res.get('res')
    )


class ResChannel_empty___4301(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4301(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None]
) -> ResChannel_empty___4301:
    cond = ((condition_4299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4301(
        res=out_channels.get("res")
    )


class Resfirst_4303(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4303(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4302_4: typing.Union[str, None]
) -> Resfirst_4303:
    cond = ((condition_4299 == True) and (channel_4302_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4302_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4303(
        res=out_channels.get("res")
    )


class Resmix_4304(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4304(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4301: typing.Union[str, None],
    channel_4303: typing.Union[str, None]
) -> Resmix_4304:
    cond = ((condition_4299 == True) and (channel_4301 is not None) and (channel_4303 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4301), json.loads(channel_4303)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4304(
        res=out_channels.get("res")
    )


class ResChannel_empty___4305(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4305(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None]
) -> ResChannel_empty___4305:
    cond = ((condition_4299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4305(
        res=out_channels.get("res")
    )


class Resfirst_4307(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4307(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4306_2: typing.Union[str, None]
) -> Resfirst_4307:
    cond = ((condition_4299 == True) and (channel_4306_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4306_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4307(
        res=out_channels.get("res")
    )


class Resmix_4308(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4308(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4305: typing.Union[str, None],
    channel_4307: typing.Union[str, None]
) -> Resmix_4308:
    cond = ((condition_4299 == True) and (channel_4305 is not None) and (channel_4307 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4305), json.loads(channel_4307)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4308(
        res=out_channels.get("res")
    )


class Resfirst_4310(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4310(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4309_3: typing.Union[str, None]
) -> Resfirst_4310:
    cond = ((condition_4299 == True) and (channel_4309_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4309_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4310(
        res=out_channels.get("res")
    )


class Resmix_4311(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4311(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4308: typing.Union[str, None],
    channel_4310: typing.Union[str, None]
) -> Resmix_4311:
    cond = ((condition_4299 == True) and (channel_4308 is not None) and (channel_4310 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4308), json.loads(channel_4310)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4311(
        res=out_channels.get("res")
    )


class ResChannel_empty___4315(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4315(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None]
) -> ResChannel_empty___4315:
    cond = ((condition_4299 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4315(
        res=out_channels.get("res")
    )


class Resjoin_4312(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4312(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4306_0: typing.Union[str, None],
    channel_4309_0: typing.Union[str, None]
) -> Resjoin_4312:
    cond = ((condition_4299 == True) and (channel_4306_0 is not None) and (channel_4309_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4306_0), json.loads(channel_4309_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4312(
        res=out_channels.get("res")
    )


class Resjoin_4313(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4313(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4312: typing.Union[str, None],
    channel_4309_1: typing.Union[str, None]
) -> Resjoin_4313:
    cond = ((condition_4299 == True) and (channel_4312 is not None) and (channel_4309_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4312), json.loads(channel_4309_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4313(
        res=out_channels.get("res")
    )


class Resmap_4314(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4314(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4313: typing.Union[str, None]
) -> Resmap_4314:
    cond = ((condition_4299 == True) and (channel_4313 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4313)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4314(
        res=out_channels.get("res")
    )


class Resmap_4300(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4300(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_4300:
    cond = ((condition_4299 == True) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4300(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4316_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4314: str
    channel_4300: str


class Res_4316_pre(NamedTuple):
    default: typing.List[Dataclass_4316_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4316_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4314: typing.Union[str, None],
    channel_4300: typing.Union[str, None]
) -> Res_4316_pre:
    cond = ((condition_4299 == True) and (channel_4314 is not None) and (channel_4300 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4316_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4314': channel_4314, 'channel_4300': channel_4300})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4316_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4316_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4316_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4316_post(
    default: List[Dataclass_4316_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4316_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4316_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4316_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4316_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4316_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4316_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4314),json.loads(default.channel_4300)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4316(
    default: Dataclass_4316_pre
) -> Dataclass_4316_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4314),json.loads(default.channel_4300)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4316_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4317(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4317(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4315: typing.Union[str, None],
    channel_4316_1: typing.Union[str, None]
) -> Resmix_4317:
    cond = ((condition_4299 == True) and (channel_4315 is not None) and (channel_4316_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4315), json.loads(channel_4316_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4317(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4318_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4314: str


class Res_4318_pre(NamedTuple):
    default: typing.List[Dataclass_4318_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4318_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4314: typing.Union[str, None]
) -> Res_4318_pre:
    cond = ((condition_4299 == True) and (channel_4314 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4318_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4314': channel_4314})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4318_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4318_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4318_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4318_post(
    default: List[Dataclass_4318_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4318_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4318_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4318_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4318_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4318_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4318_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4314)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4318(
    default: Dataclass_4318_pre
) -> Dataclass_4318_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4314)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4318_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4319(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4319(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4317: typing.Union[str, None],
    channel_4318_1: typing.Union[str, None]
) -> Resmix_4319:
    cond = ((condition_4299 == True) and (channel_4317 is not None) and (channel_4318_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4317), json.loads(channel_4318_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4319(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4320_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4314: str


class Res_4320_pre(NamedTuple):
    default: typing.List[Dataclass_4320_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4320_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4314: typing.Union[str, None]
) -> Res_4320_pre:
    cond = ((condition_4299 == True) and (channel_4314 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4320_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4314': channel_4314})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4320_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4320_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4320_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4320_post(
    default: List[Dataclass_4320_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4320_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4320_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4320_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4320_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4320_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4320_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4314)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4320(
    default: Dataclass_4320_pre
) -> Dataclass_4320_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4314)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4320_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4321(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4321(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4319: typing.Union[str, None],
    channel_4320_1: typing.Union[str, None]
) -> Resmix_4321:
    cond = ((condition_4299 == True) and (channel_4319 is not None) and (channel_4320_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4319), json.loads(channel_4320_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4321(
        res=out_channels.get("res")
    )


class Resmix_4322(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4322(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4311: typing.Union[str, None],
    channel_4321: typing.Union[str, None]
) -> Resmix_4322:
    cond = ((condition_4299 == True) and (channel_4311 is not None) and (channel_4321 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4311), json.loads(channel_4321)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4322(
        res=out_channels.get("res")
    )


class Resmix_4323(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4323(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4304: typing.Union[str, None],
    channel_4322: typing.Union[str, None]
) -> Resmix_4323:
    cond = ((condition_4299 == True) and (channel_4304 is not None) and (channel_4322 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4304), json.loads(channel_4322)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4323(
        res=out_channels.get("res")
    )


class Rescollect_4324(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4324(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4302_0: typing.Union[str, None]
) -> Rescollect_4324:
    cond = ((condition_4299 == True) and (channel_4302_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4302_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4324(
        res=out_channels.get("res")
    )


class Rescollect_4325(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4325(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4302_1: typing.Union[str, None]
) -> Rescollect_4325:
    cond = ((condition_4299 == True) and (channel_4302_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4302_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4325(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4326_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4324: str
    channel_4325: str


class Res_4326_pre(NamedTuple):
    default: typing.List[Dataclass_4326_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEM_MERGE_COUNTS_4326_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4324: typing.Union[str, None],
    channel_4325: typing.Union[str, None]
) -> Res_4326_pre:
    cond = ((condition_4299 == True) and (channel_4324 is not None) and (channel_4325 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4326_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4324': channel_4324, 'channel_4325': channel_4325})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4326_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEM_MERGE_COUNTS_4326_post(NamedTuple):
    counts_gene: typing.Union[str, None]
    tpm_gene: typing.Union[str, None]
    counts_transcript: typing.Union[str, None]
    tpm_transcript: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4326_post:
    counts_gene: str
    tpm_gene: str
    counts_transcript: str
    tpm_transcript: str
    versions: str

@task(cache=True)
def post_adapter_RSEM_MERGE_COUNTS_4326_post(
    default: List[Dataclass_4326_post],
    is_skipped: bool,
) -> Respost_adapter_RSEM_MERGE_COUNTS_4326_post:
    return get_mapper_outputs(Respost_adapter_RSEM_MERGE_COUNTS_4326_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4326_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4326_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4326_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4326_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4324),json.loads(default.channel_4325)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_rsem/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_RSEM'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEM_MERGE_COUNTS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEM_MERGE_COUNTS_4326(
    default: Dataclass_4326_pre
) -> Dataclass_4326_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4324),json.loads(default.channel_4325)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_rsem/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_RSEM'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEM_MERGE_COUNTS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_gene\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tpm_transcript\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEM_MERGE_COUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4326_post(
        counts_gene=out_channels.get(f"counts_gene"),
        tpm_gene=out_channels.get(f"tpm_gene"),
        counts_transcript=out_channels.get(f"counts_transcript"),
        tpm_transcript=out_channels.get(f"tpm_transcript"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4327(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4327(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4323: typing.Union[str, None],
    channel_4326_4: typing.Union[str, None]
) -> Resmix_4327:
    cond = ((condition_4299 == True) and (channel_4323 is not None) and (channel_4326_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4323), json.loads(channel_4326_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_rsem/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_RSEM'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4327(
        res=out_channels.get("res")
    )


class Resmix_4331(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4331(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4290: typing.Union[str, None],
    channel_4327: typing.Union[str, None]
) -> Resmix_4331:
    cond = ((condition_4299 == True) and (channel_4290 is not None) and (channel_4327 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4290), json.loads(channel_4327)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4331(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4337_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4326_0: str


class Res_4337_pre(NamedTuple):
    default: typing.List[Dataclass_4337_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_DESEQ2_QC_RSEM_4337_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    condition_4336: typing.Union[bool, None],
    channel_4326_0: typing.Union[str, None]
) -> Res_4337_pre:
    cond = ((condition_4299 == True) and (condition_4336 == True) and (channel_4326_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4337_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4326_0': channel_4326_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4337_pre(default=result, is_skipped = not cond)

class Respost_adapter_DESEQ2_QC_RSEM_4337_post(NamedTuple):
    pdf: typing.Union[str, None]
    rdata: typing.Union[str, None]
    pca_txt: typing.Union[str, None]
    pca_multiqc: typing.Union[str, None]
    dists_txt: typing.Union[str, None]
    dists_multiqc: typing.Union[str, None]
    log: typing.Union[str, None]
    size_factors: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4337_post:
    pdf: str
    rdata: str
    pca_txt: str
    pca_multiqc: str
    dists_txt: str
    dists_multiqc: str
    log: str
    size_factors: str
    versions: str

@task(cache=True)
def post_adapter_DESEQ2_QC_RSEM_4337_post(
    default: List[Dataclass_4337_post],
    is_skipped: bool,
) -> Respost_adapter_DESEQ2_QC_RSEM_4337_post:
    return get_mapper_outputs(Respost_adapter_DESEQ2_QC_RSEM_4337_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4337_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4337_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4337_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4337_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4326_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DESEQ2_QC_RSEM","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_pca_header_multiqc"},{"VariableExpression":"ch_clustering_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rdata\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"size_factors\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def DESEQ2_QC_RSEM_4337(
    default: Dataclass_4337_pre
) -> Dataclass_4337_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4326_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DESEQ2_QC_RSEM","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_pca_header_multiqc"},{"VariableExpression":"ch_clustering_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rdata\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"size_factors\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_RSEM\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4337_post(
        pdf=out_channels.get(f"pdf"),
        rdata=out_channels.get(f"rdata"),
        pca_txt=out_channels.get(f"pca_txt"),
        pca_multiqc=out_channels.get(f"pca_multiqc"),
        dists_txt=out_channels.get(f"dists_txt"),
        dists_multiqc=out_channels.get(f"dists_multiqc"),
        log=out_channels.get(f"log"),
        size_factors=out_channels.get(f"size_factors"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4338(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4338(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    condition_4336: typing.Union[bool, None],
    channel_4331: typing.Union[str, None],
    channel_4337_8: typing.Union[str, None]
) -> Resmix_4338:
    cond = ((condition_4299 == True) and (condition_4336 == True) and (channel_4331 is not None) and (channel_4337_8 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4331), json.loads(channel_4337_8)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4338(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4341(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4341(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4338: typing.Union[str, None],
    channel_4331: typing.Union[str, None]
) -> ResMerge_ch_versions_4341:
    cond = ((condition_4299 == True))

    if cond:
        res = { 'res': channel_4338 or channel_4331 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4341(
        res=res.get('res')
    )


class ResMerge_ch_versions_4351(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4351(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4341: typing.Union[str, None],
    channel_4290: typing.Union[str, None]
) -> ResMerge_ch_versions_4351:
    cond = True

    if cond:
        res = { 'res': channel_4341 or channel_4290 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4351(
        res=res.get('res')
    )


class ResChannel_empty___4361(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4361(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None]
) -> ResChannel_empty___4361:
    cond = ((condition_4357 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_align_hisat2/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_ALIGN_HISAT2'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4361(
        res=out_channels.get("res")
    )


class Resfirst_4363(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4363(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4362_3: typing.Union[str, None]
) -> Resfirst_4363:
    cond = ((condition_4357 == True) and (channel_4362_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4362_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_align_hisat2/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_ALIGN_HISAT2'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4363(
        res=out_channels.get("res")
    )


class Resmix_4364(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4364(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4361: typing.Union[str, None],
    channel_4363: typing.Union[str, None]
) -> Resmix_4364:
    cond = ((condition_4357 == True) and (channel_4361 is not None) and (channel_4363 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4361), json.loads(channel_4363)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_align_hisat2/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_ALIGN_HISAT2'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4364(
        res=out_channels.get("res")
    )


class ResChannel_empty___4365(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4365(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None]
) -> ResChannel_empty___4365:
    cond = ((condition_4357 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4365(
        res=out_channels.get("res")
    )


class Resfirst_4367(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4367(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4366_2: typing.Union[str, None]
) -> Resfirst_4367:
    cond = ((condition_4357 == True) and (channel_4366_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4366_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4367(
        res=out_channels.get("res")
    )


class Resmix_4368(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4368(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4365: typing.Union[str, None],
    channel_4367: typing.Union[str, None]
) -> Resmix_4368:
    cond = ((condition_4357 == True) and (channel_4365 is not None) and (channel_4367 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4365), json.loads(channel_4367)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4368(
        res=out_channels.get("res")
    )


class Resfirst_4370(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4370(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4369_3: typing.Union[str, None]
) -> Resfirst_4370:
    cond = ((condition_4357 == True) and (channel_4369_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4369_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4370(
        res=out_channels.get("res")
    )


class Resmix_4371(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4371(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4368: typing.Union[str, None],
    channel_4370: typing.Union[str, None]
) -> Resmix_4371:
    cond = ((condition_4357 == True) and (channel_4368 is not None) and (channel_4370 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4368), json.loads(channel_4370)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4371(
        res=out_channels.get("res")
    )


class ResChannel_empty___4375(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4375(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None]
) -> ResChannel_empty___4375:
    cond = ((condition_4357 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4375(
        res=out_channels.get("res")
    )


class Resjoin_4372(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4372(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4366_0: typing.Union[str, None],
    channel_4369_0: typing.Union[str, None]
) -> Resjoin_4372:
    cond = ((condition_4357 == True) and (channel_4366_0 is not None) and (channel_4369_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4366_0), json.loads(channel_4369_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4372(
        res=out_channels.get("res")
    )


class Resjoin_4373(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4373(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4372: typing.Union[str, None],
    channel_4369_1: typing.Union[str, None]
) -> Resjoin_4373:
    cond = ((condition_4357 == True) and (channel_4372 is not None) and (channel_4369_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4372), json.loads(channel_4369_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4373(
        res=out_channels.get("res")
    )


class Resmap_4374(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4374(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4373: typing.Union[str, None]
) -> Resmap_4374:
    cond = ((condition_4357 == True) and (channel_4373 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4373)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4374(
        res=out_channels.get("res")
    )


class Resmap_4360(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4360(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_3658: typing.Union[str, None]
) -> Resmap_4360:
    cond = ((condition_4357 == True) and (channel_3658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4360(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4376_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4374: str
    channel_4360: str


class Res_4376_pre(NamedTuple):
    default: typing.List[Dataclass_4376_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4376_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4374: typing.Union[str, None],
    channel_4360: typing.Union[str, None]
) -> Res_4376_pre:
    cond = ((condition_4357 == True) and (channel_4374 is not None) and (channel_4360 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4376_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4374': channel_4374, 'channel_4360': channel_4360})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4376_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4376_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4376_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4376_post(
    default: List[Dataclass_4376_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4376_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4376_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4376_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4376_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4376_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4376_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4374),json.loads(default.channel_4360)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4376(
    default: Dataclass_4376_pre
) -> Dataclass_4376_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4374),json.loads(default.channel_4360)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4376_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4377(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4377(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4375: typing.Union[str, None],
    channel_4376_1: typing.Union[str, None]
) -> Resmix_4377:
    cond = ((condition_4357 == True) and (channel_4375 is not None) and (channel_4376_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4375), json.loads(channel_4376_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4377(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4378_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4374: str


class Res_4378_pre(NamedTuple):
    default: typing.List[Dataclass_4378_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4378_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4374: typing.Union[str, None]
) -> Res_4378_pre:
    cond = ((condition_4357 == True) and (channel_4374 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4378_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4374': channel_4374})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4378_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4378_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4378_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4378_post(
    default: List[Dataclass_4378_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4378_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4378_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4378_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4378_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4378_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4378_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4374)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4378(
    default: Dataclass_4378_pre
) -> Dataclass_4378_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4374)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4378_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4379(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4379(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4377: typing.Union[str, None],
    channel_4378_1: typing.Union[str, None]
) -> Resmix_4379:
    cond = ((condition_4357 == True) and (channel_4377 is not None) and (channel_4378_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4377), json.loads(channel_4378_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4379(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4380_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4374: str


class Res_4380_pre(NamedTuple):
    default: typing.List[Dataclass_4380_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4380_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4374: typing.Union[str, None]
) -> Res_4380_pre:
    cond = ((condition_4357 == True) and (channel_4374 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4380_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4374': channel_4374})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4380_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4380_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4380_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4380_post(
    default: List[Dataclass_4380_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4380_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4380_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4380_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4380_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4380_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4380_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4374)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4380(
    default: Dataclass_4380_pre
) -> Dataclass_4380_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4374)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4380_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4381(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4381(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4379: typing.Union[str, None],
    channel_4380_1: typing.Union[str, None]
) -> Resmix_4381:
    cond = ((condition_4357 == True) and (channel_4379 is not None) and (channel_4380_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4379), json.loads(channel_4380_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4381(
        res=out_channels.get("res")
    )


class Resmix_4382(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4382(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4371: typing.Union[str, None],
    channel_4381: typing.Union[str, None]
) -> Resmix_4382:
    cond = ((condition_4357 == True) and (channel_4371 is not None) and (channel_4381 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4371), json.loads(channel_4381)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_sort_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_SORT_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4382(
        res=out_channels.get("res")
    )


class Resmix_4383(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4383(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4364: typing.Union[str, None],
    channel_4382: typing.Union[str, None]
) -> Resmix_4383:
    cond = ((condition_4357 == True) and (channel_4364 is not None) and (channel_4382 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4364), json.loads(channel_4382)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_align_hisat2/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_ALIGN_HISAT2'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4383(
        res=out_channels.get("res")
    )


class Resmix_4387(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4387(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4351: typing.Union[str, None],
    channel_4383: typing.Union[str, None]
) -> Resmix_4387:
    cond = ((condition_4357 == True) and (channel_4351 is not None) and (channel_4383 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4351), json.loads(channel_4383)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4387(
        res=out_channels.get("res")
    )


class Resmix_4414(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4414(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    condition_4389: typing.Union[bool, None],
    channel_4387: typing.Union[str, None],
    channel_4410: typing.Union[str, None]
) -> Resmix_4414:
    cond = ((condition_4357 == True) and (condition_4389 == True) and (channel_4387 is not None) and (channel_4410 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4387), json.loads(channel_4410)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4414(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4421(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4421(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4414: typing.Union[str, None],
    channel_4387: typing.Union[str, None]
) -> ResMerge_ch_versions_4421:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4414 or channel_4387 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4421(
        res=res.get('res')
    )


class ResMerge_ch_versions_4429(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4429(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4421: typing.Union[str, None],
    channel_4351: typing.Union[str, None]
) -> ResMerge_ch_versions_4429:
    cond = True

    if cond:
        res = { 'res': channel_4421 or channel_4351 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4429(
        res=res.get('res')
    )


@dataclass
class Dataclass_4455_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4444: str


class Res_4455_pre(NamedTuple):
    default: typing.List[Dataclass_4455_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_PRESEQ_LCEXTRAP_4455_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4454: typing.Union[bool, None],
    channel_4444: typing.Union[str, None]
) -> Res_4455_pre:
    cond = ((condition_4454 == True) and (channel_4444 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4455_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4444': channel_4444})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4455_pre(default=result, is_skipped = not cond)

class Respost_adapter_PRESEQ_LCEXTRAP_4455_post(NamedTuple):
    lc_extrap: typing.Union[str, None]
    log: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4455_post:
    lc_extrap: str
    log: str
    versions: str

@task(cache=True)
def post_adapter_PRESEQ_LCEXTRAP_4455_post(
    default: List[Dataclass_4455_post],
    is_skipped: bool,
) -> Respost_adapter_PRESEQ_LCEXTRAP_4455_post:
    return get_mapper_outputs(Respost_adapter_PRESEQ_LCEXTRAP_4455_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4455_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4455_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4455_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4455_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4444)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PRESEQ_LCEXTRAP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lc_extrap\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRESEQ_LCEXTRAP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRESEQ_LCEXTRAP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRESEQ_LCEXTRAP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def PRESEQ_LCEXTRAP_4455(
    default: Dataclass_4455_pre
) -> Dataclass_4455_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4444)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"PRESEQ_LCEXTRAP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"lc_extrap\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRESEQ_LCEXTRAP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRESEQ_LCEXTRAP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"PRESEQ_LCEXTRAP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4455_post(
        lc_extrap=out_channels.get(f"lc_extrap"),
        log=out_channels.get(f"log"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4456(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4456(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4454: typing.Union[bool, None],
    channel_4455_2: typing.Union[str, None]
) -> Resfirst_4456:
    cond = ((condition_4454 == True) and (channel_4455_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4455_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4456(
        res=out_channels.get("res")
    )


class Resmix_4457(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4457(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4454: typing.Union[bool, None],
    channel_4429: typing.Union[str, None],
    channel_4456: typing.Union[str, None]
) -> Resmix_4457:
    cond = ((condition_4454 == True) and (channel_4429 is not None) and (channel_4456 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4429), json.loads(channel_4456)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4457(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4459(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4459(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4457: typing.Union[str, None],
    channel_4429: typing.Union[str, None]
) -> ResMerge_ch_versions_4459:
    cond = True

    if cond:
        res = { 'res': channel_4457 or channel_4429 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4459(
        res=res.get('res')
    )


class ResChannel_empty___4470(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4470(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None]
) -> ResChannel_empty___4470:
    cond = ((condition_4467 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4470(
        res=out_channels.get("res")
    )


class Resfirst_4472(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4472(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4471_3: typing.Union[str, None]
) -> Resfirst_4472:
    cond = ((condition_4467 == True) and (channel_4471_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4471_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4472(
        res=out_channels.get("res")
    )


class Resmix_4473(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4473(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4470: typing.Union[str, None],
    channel_4472: typing.Union[str, None]
) -> Resmix_4473:
    cond = ((condition_4467 == True) and (channel_4470 is not None) and (channel_4472 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4470), json.loads(channel_4472)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4473(
        res=out_channels.get("res")
    )


class Resfirst_4475(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4475(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4474_3: typing.Union[str, None]
) -> Resfirst_4475:
    cond = ((condition_4467 == True) and (channel_4474_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4474_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4475(
        res=out_channels.get("res")
    )


class Resmix_4476(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4476(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4473: typing.Union[str, None],
    channel_4475: typing.Union[str, None]
) -> Resmix_4476:
    cond = ((condition_4467 == True) and (channel_4473 is not None) and (channel_4475 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4473), json.loads(channel_4475)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4476(
        res=out_channels.get("res")
    )


class ResChannel_empty___4480(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4480(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None]
) -> ResChannel_empty___4480:
    cond = ((condition_4467 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4480(
        res=out_channels.get("res")
    )


class Resjoin_4477(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4477(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4471_0: typing.Union[str, None],
    channel_4474_0: typing.Union[str, None]
) -> Resjoin_4477:
    cond = ((condition_4467 == True) and (channel_4471_0 is not None) and (channel_4474_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4471_0), json.loads(channel_4474_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4477(
        res=out_channels.get("res")
    )


class Resjoin_4478(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def join_4478(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4477: typing.Union[str, None],
    channel_4474_1: typing.Union[str, None]
) -> Resjoin_4478:
    cond = ((condition_4467 == True) and (channel_4477 is not None) and (channel_4474_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4477), json.loads(channel_4474_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"by"},"valueExpression":{"ListExpression":[{"ConstantExpression":0}]}}},{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"remainder"},"valueExpression":{"ConstantExpression":true}}}]},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resjoin_4478(
        res=out_channels.get("res")
    )


class Resmap_4479(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4479(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4478: typing.Union[str, None]
) -> Resmap_4479:
    cond = ((condition_4467 == True) and (channel_4478 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4478)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"IfStatement":{"booleanExpression":{"BooleanExpression":{"VariableExpression":"bai"}},"ifBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"bai"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"bam"},{"VariableExpression":"csi"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","bam","bai","csi"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4479(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4481_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4479: str
    channel_4468: str


class Res_4481_pre(NamedTuple):
    default: typing.List[Dataclass_4481_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_STATS_4481_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4479: typing.Union[str, None],
    channel_4468: typing.Union[str, None]
) -> Res_4481_pre:
    cond = ((condition_4467 == True) and (channel_4479 is not None) and (channel_4468 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4481_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4479': channel_4479, 'channel_4468': channel_4468})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4481_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_STATS_4481_post(NamedTuple):
    stats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4481_post:
    stats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_STATS_4481_post(
    default: List[Dataclass_4481_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_STATS_4481_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_STATS_4481_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4481_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4481_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4481_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4481_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4479),json.loads(default.channel_4468)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_STATS_4481(
    default: Dataclass_4481_pre
) -> Dataclass_4481_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4479),json.loads(default.channel_4468)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_STATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"stats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_STATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4481_post(
        stats=out_channels.get(f"stats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4482(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4482(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4480: typing.Union[str, None],
    channel_4481_1: typing.Union[str, None]
) -> Resmix_4482:
    cond = ((condition_4467 == True) and (channel_4480 is not None) and (channel_4481_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4480), json.loads(channel_4481_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4482(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4483_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4479: str


class Res_4483_pre(NamedTuple):
    default: typing.List[Dataclass_4483_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_FLAGSTAT_4483_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4479: typing.Union[str, None]
) -> Res_4483_pre:
    cond = ((condition_4467 == True) and (channel_4479 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4483_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4479': channel_4479})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4483_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_FLAGSTAT_4483_post(NamedTuple):
    flagstat: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4483_post:
    flagstat: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_FLAGSTAT_4483_post(
    default: List[Dataclass_4483_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_FLAGSTAT_4483_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_FLAGSTAT_4483_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4483_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4483_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4483_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4483_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4479)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_FLAGSTAT_4483(
    default: Dataclass_4483_pre
) -> Dataclass_4483_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4479)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_FLAGSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"flagstat\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_FLAGSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4483_post(
        flagstat=out_channels.get(f"flagstat"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4484(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4484(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4482: typing.Union[str, None],
    channel_4483_1: typing.Union[str, None]
) -> Resmix_4484:
    cond = ((condition_4467 == True) and (channel_4482 is not None) and (channel_4483_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4482), json.loads(channel_4483_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4484(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4485_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4479: str


class Res_4485_pre(NamedTuple):
    default: typing.List[Dataclass_4485_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SAMTOOLS_IDXSTATS_4485_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4479: typing.Union[str, None]
) -> Res_4485_pre:
    cond = ((condition_4467 == True) and (channel_4479 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4485_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4479': channel_4479})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4485_pre(default=result, is_skipped = not cond)

class Respost_adapter_SAMTOOLS_IDXSTATS_4485_post(NamedTuple):
    idxstats: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4485_post:
    idxstats: str
    versions: str

@task(cache=True)
def post_adapter_SAMTOOLS_IDXSTATS_4485_post(
    default: List[Dataclass_4485_post],
    is_skipped: bool,
) -> Respost_adapter_SAMTOOLS_IDXSTATS_4485_post:
    return get_mapper_outputs(Respost_adapter_SAMTOOLS_IDXSTATS_4485_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4485_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4485_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4485_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4485_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4479)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SAMTOOLS_IDXSTATS_4485(
    default: Dataclass_4485_pre
) -> Dataclass_4485_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4479)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_stats_samtools/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_STATS_SAMTOOLS'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SAMTOOLS_IDXSTATS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"idxstats\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SAMTOOLS_IDXSTATS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4485_post(
        idxstats=out_channels.get(f"idxstats"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4486(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4486(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4484: typing.Union[str, None],
    channel_4485_1: typing.Union[str, None]
) -> Resmix_4486:
    cond = ((condition_4467 == True) and (channel_4484 is not None) and (channel_4485_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4484), json.loads(channel_4485_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_stats_samtools/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_STATS_SAMTOOLS'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4486(
        res=out_channels.get("res")
    )


class Resmix_4487(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4487(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4476: typing.Union[str, None],
    channel_4486: typing.Union[str, None]
) -> Resmix_4487:
    cond = ((condition_4467 == True) and (channel_4476 is not None) and (channel_4486 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4476), json.loads(channel_4486)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_markduplicates_picard/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_MARKDUPLICATES_PICARD'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4487(
        res=out_channels.get("res")
    )


class Resmix_4491(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4491(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4467: typing.Union[bool, None],
    channel_4459: typing.Union[str, None],
    channel_4487: typing.Union[str, None]
) -> Resmix_4491:
    cond = ((condition_4467 == True) and (channel_4459 is not None) and (channel_4487 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4459), json.loads(channel_4487)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4491(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4498(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4498(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4491: typing.Union[str, None],
    channel_4459: typing.Union[str, None]
) -> ResMerge_ch_versions_4498:
    cond = True

    if cond:
        res = { 'res': channel_4491 or channel_4459 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4498(
        res=res.get('res')
    )


@dataclass
class Dataclass_4504_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4492: str
    channel_3656: str


class Res_4504_pre(NamedTuple):
    default: typing.List[Dataclass_4504_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_STRINGTIE_STRINGTIE_4504_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4503: typing.Union[bool, None],
    channel_4492: typing.Union[str, None],
    channel_3656: typing.Union[str, None]
) -> Res_4504_pre:
    cond = ((condition_4503 == True) and (channel_4492 is not None) and (channel_3656 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4504_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4492': channel_4492, 'channel_3656': channel_3656})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4504_pre(default=result, is_skipped = not cond)

class Respost_adapter_STRINGTIE_STRINGTIE_4504_post(NamedTuple):
    transcript_gtf: typing.Union[str, None]
    abundance: typing.Union[str, None]
    coverage_gtf: typing.Union[str, None]
    ballgown: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4504_post:
    transcript_gtf: str
    abundance: str
    coverage_gtf: str
    ballgown: str
    versions: str

@task(cache=True)
def post_adapter_STRINGTIE_STRINGTIE_4504_post(
    default: List[Dataclass_4504_post],
    is_skipped: bool,
) -> Respost_adapter_STRINGTIE_STRINGTIE_4504_post:
    return get_mapper_outputs(Respost_adapter_STRINGTIE_STRINGTIE_4504_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4504_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4504_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4504_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4504_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492),json.loads(default.channel_3656)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STRINGTIE_STRINGTIE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"transcript_gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"abundance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"coverage_gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"ballgown\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def STRINGTIE_STRINGTIE_4504(
    default: Dataclass_4504_pre
) -> Dataclass_4504_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492),json.loads(default.channel_3656)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"STRINGTIE_STRINGTIE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"transcript_gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"abundance\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"coverage_gtf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"ballgown\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"STRINGTIE_STRINGTIE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4504_post(
        transcript_gtf=out_channels.get(f"transcript_gtf"),
        abundance=out_channels.get(f"abundance"),
        coverage_gtf=out_channels.get(f"coverage_gtf"),
        ballgown=out_channels.get(f"ballgown"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4505(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4505(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4503: typing.Union[bool, None],
    channel_4504_4: typing.Union[str, None]
) -> Resfirst_4505:
    cond = ((condition_4503 == True) and (channel_4504_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4504_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4505(
        res=out_channels.get("res")
    )


class Resmix_4506(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4506(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4503: typing.Union[bool, None],
    channel_4498: typing.Union[str, None],
    channel_4505: typing.Union[str, None]
) -> Resmix_4506:
    cond = ((condition_4503 == True) and (channel_4498 is not None) and (channel_4505 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4498), json.loads(channel_4505)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4506(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4507(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4507(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4506: typing.Union[str, None],
    channel_4498: typing.Union[str, None]
) -> ResMerge_ch_versions_4507:
    cond = True

    if cond:
        res = { 'res': channel_4506 or channel_4498 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4507(
        res=res.get('res')
    )


class Rescombine_4518(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_4518(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4492: typing.Union[str, None],
    channel_3656: typing.Union[str, None]
) -> Rescombine_4518:
    cond = ((condition_4516 == True) and (channel_4492 is not None) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4492), json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescombine_4518(
        res=out_channels.get("res")
    )


class Resmap_4517(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4517(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Resmap_4517:
    cond = ((condition_4516 == True) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"biotypeInGtf","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"it"},{"VariableExpression":"biotype"},{"PropertyExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.Nextflow"}},"property":"log"}}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":["log"]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4517(
        res=out_channels.get("res")
    )


class Rescombine_4519(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def combine_4519(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4518: typing.Union[str, None],
    channel_4517: typing.Union[str, None]
) -> Rescombine_4519:
    cond = ((condition_4516 == True) and (channel_4518 is not None) and (channel_4517 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4518), json.loads(channel_4517)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"combine","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescombine_4519(
        res=out_channels.get("res")
    )


class Resfilter_4520(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def filter_4520(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4519: typing.Union[str, None]
) -> Resfilter_4520:
    cond = ((condition_4516 == True) and (channel_4519 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4519)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"filter","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":-1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfilter_4520(
        res=out_channels.get("res")
    )


class Resmap_4521(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4521(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4520: typing.Union[str, None]
) -> Resmap_4521:
    cond = ((condition_4516 == True) and (channel_4520 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4520)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"RangeExpression":{"from":{"ConstantExpression":0},"to":{"BinaryExpression":{"leftExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"it"},"method":"size","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"operation":"-","rightExpression":{"ConstantExpression":1}}},"inclusive":false}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4521(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4522_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4521: str


class Res_4522_pre(NamedTuple):
    default: typing.List[Dataclass_4522_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SUBREAD_FEATURECOUNTS_4522_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4521: typing.Union[str, None]
) -> Res_4522_pre:
    cond = ((condition_4516 == True) and (channel_4521 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4522_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4521': channel_4521})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4522_pre(default=result, is_skipped = not cond)

class Respost_adapter_SUBREAD_FEATURECOUNTS_4522_post(NamedTuple):
    counts: typing.Union[str, None]
    summary: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4522_post:
    counts: str
    summary: str
    versions: str

@task(cache=True)
def post_adapter_SUBREAD_FEATURECOUNTS_4522_post(
    default: List[Dataclass_4522_post],
    is_skipped: bool,
) -> Respost_adapter_SUBREAD_FEATURECOUNTS_4522_post:
    return get_mapper_outputs(Respost_adapter_SUBREAD_FEATURECOUNTS_4522_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4522_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4522_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4522_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4522_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4521)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SUBREAD_FEATURECOUNTS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SUBREAD_FEATURECOUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SUBREAD_FEATURECOUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SUBREAD_FEATURECOUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SUBREAD_FEATURECOUNTS_4522(
    default: Dataclass_4522_pre
) -> Dataclass_4522_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4521)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SUBREAD_FEATURECOUNTS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"counts\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SUBREAD_FEATURECOUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"summary\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SUBREAD_FEATURECOUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SUBREAD_FEATURECOUNTS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4522_post(
        counts=out_channels.get(f"counts"),
        summary=out_channels.get(f"summary"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4523(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4523(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4522_2: typing.Union[str, None]
) -> Resfirst_4523:
    cond = ((condition_4516 == True) and (channel_4522_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4522_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4523(
        res=out_channels.get("res")
    )


class Resmix_4524(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4524(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4507: typing.Union[str, None],
    channel_4523: typing.Union[str, None]
) -> Resmix_4524:
    cond = ((condition_4516 == True) and (channel_4507 is not None) and (channel_4523 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4507), json.loads(channel_4523)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4524(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4525_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4522_0: str


class Res_4525_pre(NamedTuple):
    default: typing.List[Dataclass_4525_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_MULTIQC_CUSTOM_BIOTYPE_4525_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4522_0: typing.Union[str, None]
) -> Res_4525_pre:
    cond = ((condition_4516 == True) and (channel_4522_0 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4525_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4522_0': channel_4522_0})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4525_pre(default=result, is_skipped = not cond)

class Respost_adapter_MULTIQC_CUSTOM_BIOTYPE_4525_post(NamedTuple):
    tsv: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4525_post:
    tsv: str
    versions: str

@task(cache=True)
def post_adapter_MULTIQC_CUSTOM_BIOTYPE_4525_post(
    default: List[Dataclass_4525_post],
    is_skipped: bool,
) -> Respost_adapter_MULTIQC_CUSTOM_BIOTYPE_4525_post:
    return get_mapper_outputs(Respost_adapter_MULTIQC_CUSTOM_BIOTYPE_4525_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4525_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4525_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4525_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4525_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4522_0)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC_CUSTOM_BIOTYPE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_biotypes_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC_CUSTOM_BIOTYPE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC_CUSTOM_BIOTYPE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def MULTIQC_CUSTOM_BIOTYPE_4525(
    default: Dataclass_4525_pre
) -> Dataclass_4525_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4522_0)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC_CUSTOM_BIOTYPE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_biotypes_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"tsv\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC_CUSTOM_BIOTYPE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC_CUSTOM_BIOTYPE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4525_post(
        tsv=out_channels.get(f"tsv"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4526(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4526(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4525_1: typing.Union[str, None]
) -> Resfirst_4526:
    cond = ((condition_4516 == True) and (channel_4525_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4525_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4526(
        res=out_channels.get("res")
    )


class Resmix_4527(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4527(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4516: typing.Union[bool, None],
    channel_4524: typing.Union[str, None],
    channel_4526: typing.Union[str, None]
) -> Resmix_4527:
    cond = ((condition_4516 == True) and (channel_4524 is not None) and (channel_4526 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4524), json.loads(channel_4526)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4527(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4528(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4528(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4527: typing.Union[str, None],
    channel_4507: typing.Union[str, None]
) -> ResMerge_ch_versions_4528:
    cond = True

    if cond:
        res = { 'res': channel_4527 or channel_4507 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4528(
        res=res.get('res')
    )


class Resfirst_4536(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4536(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4535_2: typing.Union[str, None]
) -> Resfirst_4536:
    cond = ((condition_4534 == True) and (channel_4535_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4535_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4536(
        res=out_channels.get("res")
    )


class Resmix_4537(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4537(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4528: typing.Union[str, None],
    channel_4536: typing.Union[str, None]
) -> Resmix_4537:
    cond = ((condition_4534 == True) and (channel_4528 is not None) and (channel_4536 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4528), json.loads(channel_4536)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4537(
        res=out_channels.get("res")
    )


class ResChannel_empty___4538(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4538(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None]
) -> ResChannel_empty___4538:
    cond = ((condition_4534 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4538(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4539_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4535_0: str
    channel_3700: str


class Res_4539_pre(NamedTuple):
    default: typing.List[Dataclass_4539_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UCSC_BEDCLIP_4539_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4535_0: typing.Union[str, None],
    channel_3700: typing.Union[str, None]
) -> Res_4539_pre:
    cond = ((condition_4534 == True) and (channel_4535_0 is not None) and (channel_3700 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4539_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4535_0': channel_4535_0, 'channel_3700': channel_3700})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4539_pre(default=result, is_skipped = not cond)

class Respost_adapter_UCSC_BEDCLIP_4539_post(NamedTuple):
    bedgraph: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4539_post:
    bedgraph: str
    versions: str

@task(cache=True)
def post_adapter_UCSC_BEDCLIP_4539_post(
    default: List[Dataclass_4539_post],
    is_skipped: bool,
) -> Respost_adapter_UCSC_BEDCLIP_4539_post:
    return get_mapper_outputs(Respost_adapter_UCSC_BEDCLIP_4539_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4539_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4539_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4539_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4539_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4535_0),json.loads(default.channel_3700)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDCLIP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UCSC_BEDCLIP_4539(
    default: Dataclass_4539_pre
) -> Dataclass_4539_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4535_0),json.loads(default.channel_3700)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDCLIP","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bedgraph\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDCLIP\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4539_post(
        bedgraph=out_channels.get(f"bedgraph"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4540(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4540(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4539_1: typing.Union[str, None]
) -> Resfirst_4540:
    cond = ((condition_4534 == True) and (channel_4539_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4539_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4540(
        res=out_channels.get("res")
    )


class Resmix_4541(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4541(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4538: typing.Union[str, None],
    channel_4540: typing.Union[str, None]
) -> Resmix_4541:
    cond = ((condition_4534 == True) and (channel_4538 is not None) and (channel_4540 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4538), json.loads(channel_4540)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4541(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4542_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4539_0: str
    channel_3700: str


class Res_4542_pre(NamedTuple):
    default: typing.List[Dataclass_4542_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_UCSC_BEDGRAPHTOBIGWIG_4542_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4539_0: typing.Union[str, None],
    channel_3700: typing.Union[str, None]
) -> Res_4542_pre:
    cond = ((condition_4534 == True) and (channel_4539_0 is not None) and (channel_3700 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4542_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4539_0': channel_4539_0, 'channel_3700': channel_3700})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4542_pre(default=result, is_skipped = not cond)

class Respost_adapter_UCSC_BEDGRAPHTOBIGWIG_4542_post(NamedTuple):
    bigwig: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4542_post:
    bigwig: str
    versions: str

@task(cache=True)
def post_adapter_UCSC_BEDGRAPHTOBIGWIG_4542_post(
    default: List[Dataclass_4542_post],
    is_skipped: bool,
) -> Respost_adapter_UCSC_BEDGRAPHTOBIGWIG_4542_post:
    return get_mapper_outputs(Respost_adapter_UCSC_BEDGRAPHTOBIGWIG_4542_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4542_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4542_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4542_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4542_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4539_0),json.loads(default.channel_3700)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDGRAPHTOBIGWIG","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bigwig\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def UCSC_BEDGRAPHTOBIGWIG_4542(
    default: Dataclass_4542_pre
) -> Dataclass_4542_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4539_0),json.loads(default.channel_3700)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"UCSC_BEDGRAPHTOBIGWIG","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"bigwig\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"UCSC_BEDGRAPHTOBIGWIG\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4542_post(
        bigwig=out_channels.get(f"bigwig"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4543(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4543(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4542_1: typing.Union[str, None]
) -> Resfirst_4543:
    cond = ((condition_4534 == True) and (channel_4542_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4542_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4543(
        res=out_channels.get("res")
    )


class Resmix_4544(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4544(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4541: typing.Union[str, None],
    channel_4543: typing.Union[str, None]
) -> Resmix_4544:
    cond = ((condition_4534 == True) and (channel_4541 is not None) and (channel_4543 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4541), json.loads(channel_4543)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bedgraph_bedclip_bedgraphtobigwig/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BEDGRAPH_BEDCLIP_BEDGRAPHTOBIGWIG'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4544(
        res=out_channels.get("res")
    )


class Resmix_4545(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4545(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4534: typing.Union[bool, None],
    channel_4537: typing.Union[str, None],
    channel_4544: typing.Union[str, None]
) -> Resmix_4545:
    cond = ((condition_4534 == True) and (channel_4537 is not None) and (channel_4544 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4537), json.loads(channel_4544)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4545(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4553(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4553(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4545: typing.Union[str, None],
    channel_4528: typing.Union[str, None]
) -> ResMerge_ch_versions_4553:
    cond = True

    if cond:
        res = { 'res': channel_4545 or channel_4528 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4553(
        res=res.get('res')
    )


class Resmap_4573(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4573(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4572: typing.Union[bool, None],
    channel_3656: typing.Union[str, None]
) -> Resmap_4573:
    cond = ((condition_4569 == True) and (condition_4572 == True) and (channel_3656 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3656)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"MapExpression":[]},{"VariableExpression":"it"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4573(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4574_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4492: str
    channel_4573: str


class Res_4574_pre(NamedTuple):
    default: typing.List[Dataclass_4574_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_QUALIMAP_RNASEQ_4574_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4572: typing.Union[bool, None],
    channel_4492: typing.Union[str, None],
    channel_4573: typing.Union[str, None]
) -> Res_4574_pre:
    cond = ((condition_4569 == True) and (condition_4572 == True) and (channel_4492 is not None) and (channel_4573 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4574_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4492': channel_4492, 'channel_4573': channel_4573})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4574_pre(default=result, is_skipped = not cond)

class Respost_adapter_QUALIMAP_RNASEQ_4574_post(NamedTuple):
    results: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4574_post:
    results: str
    versions: str

@task(cache=True)
def post_adapter_QUALIMAP_RNASEQ_4574_post(
    default: List[Dataclass_4574_post],
    is_skipped: bool,
) -> Respost_adapter_QUALIMAP_RNASEQ_4574_post:
    return get_mapper_outputs(Respost_adapter_QUALIMAP_RNASEQ_4574_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4574_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4574_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4574_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4574_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492),json.loads(default.channel_4573)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"QUALIMAP_RNASEQ","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_RNASEQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_RNASEQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def QUALIMAP_RNASEQ_4574(
    default: Dataclass_4574_pre
) -> Dataclass_4574_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492),json.loads(default.channel_4573)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"QUALIMAP_RNASEQ","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"results\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_RNASEQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"QUALIMAP_RNASEQ\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4574_post(
        results=out_channels.get(f"results"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4575(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4575(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4572: typing.Union[bool, None],
    channel_4574_1: typing.Union[str, None]
) -> Resfirst_4575:
    cond = ((condition_4569 == True) and (condition_4572 == True) and (channel_4574_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4574_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4575(
        res=out_channels.get("res")
    )


class Resmix_4576(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4576(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4572: typing.Union[bool, None],
    channel_4553: typing.Union[str, None],
    channel_4575: typing.Union[str, None]
) -> Resmix_4576:
    cond = ((condition_4569 == True) and (condition_4572 == True) and (channel_4553 is not None) and (channel_4575 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4553), json.loads(channel_4575)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4576(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4578(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4578(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4576: typing.Union[str, None],
    channel_4553: typing.Union[str, None]
) -> ResMerge_ch_versions_4578:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4576 or channel_4553 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4578(
        res=res.get('res')
    )


@dataclass
class Dataclass_4582_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4492: str
    channel_3656: str


class Res_4582_pre(NamedTuple):
    default: typing.List[Dataclass_4582_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_DUPRADAR_4582_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4581: typing.Union[bool, None],
    channel_4492: typing.Union[str, None],
    channel_3656: typing.Union[str, None]
) -> Res_4582_pre:
    cond = ((condition_4569 == True) and (condition_4581 == True) and (channel_4492 is not None) and (channel_3656 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4582_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4492': channel_4492, 'channel_3656': channel_3656})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4582_pre(default=result, is_skipped = not cond)

class Respost_adapter_DUPRADAR_4582_post(NamedTuple):
    pdf: typing.Union[str, None]
    txt: typing.Union[str, None]
    multiqc: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4582_post:
    pdf: str
    txt: str
    multiqc: str
    versions: str

@task(cache=True)
def post_adapter_DUPRADAR_4582_post(
    default: List[Dataclass_4582_post],
    is_skipped: bool,
) -> Respost_adapter_DUPRADAR_4582_post:
    return get_mapper_outputs(Respost_adapter_DUPRADAR_4582_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4582_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4582_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4582_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4582_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492),json.loads(default.channel_3656)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DUPRADAR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def DUPRADAR_4582(
    default: Dataclass_4582_pre
) -> Dataclass_4582_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4492),json.loads(default.channel_3656)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DUPRADAR","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DUPRADAR\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4582_post(
        pdf=out_channels.get(f"pdf"),
        txt=out_channels.get(f"txt"),
        multiqc=out_channels.get(f"multiqc"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4583(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4583(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4581: typing.Union[bool, None],
    channel_4582_3: typing.Union[str, None]
) -> Resfirst_4583:
    cond = ((condition_4569 == True) and (condition_4581 == True) and (channel_4582_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4582_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4583(
        res=out_channels.get("res")
    )


class Resmix_4584(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4584(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4581: typing.Union[bool, None],
    channel_4578: typing.Union[str, None],
    channel_4583: typing.Union[str, None]
) -> Resmix_4584:
    cond = ((condition_4569 == True) and (condition_4581 == True) and (channel_4578 is not None) and (channel_4583 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4578), json.loads(channel_4583)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4584(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4586(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4586(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4584: typing.Union[str, None],
    channel_4578: typing.Union[str, None]
) -> ResMerge_ch_versions_4586:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4584 or channel_4578 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4586(
        res=res.get('res')
    )


class Res_tin_in_rseqc_modules__4688(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _tin_in_rseqc_modules__4688(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_tin_in_rseqc_modules__4688:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"tin"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_tin_in_rseqc_modules__4688(
        res=out_channels.get("res")
    )


class Res_tin_in_rseqc_modules__4689(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _tin_in_rseqc_modules__4689(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4688: typing.Union[str, None]
) -> Res_tin_in_rseqc_modules__4689:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4688 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4688)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_tin_in_rseqc_modules__4689(
        res=out_channels.get("res")
    )


class Resconditional__tin_in_rseqc_modules__4690(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__tin_in_rseqc_modules__4690(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4689: typing.Union[str, None]
) -> Resconditional__tin_in_rseqc_modules__4690:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4689 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4689)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__tin_in_rseqc_modules__4690(condition=res)


class Res_read_distribution_in_rseqc_modules__4664(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _read_distribution_in_rseqc_modules__4664(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_read_distribution_in_rseqc_modules__4664:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"read_distribution"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_read_distribution_in_rseqc_modules__4664(
        res=out_channels.get("res")
    )


class Res_read_distribution_in_rseqc_modules__4665(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _read_distribution_in_rseqc_modules__4665(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4664: typing.Union[str, None]
) -> Res_read_distribution_in_rseqc_modules__4665:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4664 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4664)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_read_distribution_in_rseqc_modules__4665(
        res=out_channels.get("res")
    )


class Resconditional__read_distribution_in_rseqc_modules__4666(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__read_distribution_in_rseqc_modules__4666(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4665: typing.Union[str, None]
) -> Resconditional__read_distribution_in_rseqc_modules__4666:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4665 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4665)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__read_distribution_in_rseqc_modules__4666(condition=res)


class Res_infer_experiment_in_rseqc_modules__4623(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _infer_experiment_in_rseqc_modules__4623(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_infer_experiment_in_rseqc_modules__4623:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"infer_experiment"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_infer_experiment_in_rseqc_modules__4623(
        res=out_channels.get("res")
    )


class Res_infer_experiment_in_rseqc_modules__4624(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _infer_experiment_in_rseqc_modules__4624(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4623: typing.Union[str, None]
) -> Res_infer_experiment_in_rseqc_modules__4624:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4623 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4623)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_infer_experiment_in_rseqc_modules__4624(
        res=out_channels.get("res")
    )


class Resconditional__infer_experiment_in_rseqc_modules__4625(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__infer_experiment_in_rseqc_modules__4625(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4624: typing.Union[str, None]
) -> Resconditional__infer_experiment_in_rseqc_modules__4625:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4624 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4624)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__infer_experiment_in_rseqc_modules__4625(condition=res)


class Res_bam_stat_in_rseqc_modules__4597(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _bam_stat_in_rseqc_modules__4597(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> Res_bam_stat_in_rseqc_modules__4597:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"binaryOp","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"bam_stat"},{"ConstantExpression":"in"},{"ConstantExpression":true}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_bam_stat_in_rseqc_modules__4597(
        res=out_channels.get("res")
    )


class Res_bam_stat_in_rseqc_modules__4598(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def _bam_stat_in_rseqc_modules__4598(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4597: typing.Union[str, None]
) -> Res_bam_stat_in_rseqc_modules__4598:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4597 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4597)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toBoolean","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Res_bam_stat_in_rseqc_modules__4598(
        res=out_channels.get("res")
    )


class Resconditional__bam_stat_in_rseqc_modules__4599(NamedTuple):
    condition: typing.Union[bool, None]

@task(cache=True)
def conditional__bam_stat_in_rseqc_modules__4599(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4598: typing.Union[str, None]
) -> Resconditional__bam_stat_in_rseqc_modules__4599:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4598 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4598)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"condition"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"condition\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'condition': None}

    res = out_channels.get("condition")

    if res is not None:
        res = get_boolean_value(res)

    return Resconditional__bam_stat_in_rseqc_modules__4599(condition=res)


class ResChannel_empty___4594(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4594(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4594:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4594(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4600_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str


class Res_4600_pre(NamedTuple):
    default: typing.List[Dataclass_4600_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_BAMSTAT_4600_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4599: typing.Union[bool, None],
    channel_4595: typing.Union[str, None]
) -> Res_4600_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4599 == True) and (channel_4595 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4600_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4600_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_BAMSTAT_4600_post(NamedTuple):
    txt: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4600_post:
    txt: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_BAMSTAT_4600_post(
    default: List[Dataclass_4600_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_BAMSTAT_4600_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_BAMSTAT_4600_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4600_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4600_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4600_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4600_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_BAMSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_BAMSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_BAMSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_BAMSTAT_4600(
    default: Dataclass_4600_pre
) -> Dataclass_4600_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_BAMSTAT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_BAMSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_BAMSTAT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4600_post(
        txt=out_channels.get(f"txt"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4601(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4601(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4599: typing.Union[bool, None],
    channel_4600_1: typing.Union[str, None]
) -> Resfirst_4601:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4599 == True) and (channel_4600_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4600_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4601(
        res=out_channels.get("res")
    )


class Resmix_4602(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4602(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4599: typing.Union[bool, None],
    channel_4594: typing.Union[str, None],
    channel_4601: typing.Union[str, None]
) -> Resmix_4602:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4599 == True) and (channel_4594 is not None) and (channel_4601 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4594), json.loads(channel_4601)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4602(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4604(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4604(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4602: typing.Union[str, None],
    channel_4594: typing.Union[str, None]
) -> ResMerge_ch_versions_4604:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4602 or channel_4594 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4604(
        res=res.get('res')
    )


class Resfirst_4614(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4614(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4612: typing.Union[bool, None],
    channel_4613_5: typing.Union[str, None]
) -> Resfirst_4614:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4612 == True) and (channel_4613_5 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4613_5)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4614(
        res=out_channels.get("res")
    )


class Resmix_4615(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4615(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4612: typing.Union[bool, None],
    channel_4604: typing.Union[str, None],
    channel_4614: typing.Union[str, None]
) -> Resmix_4615:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4612 == True) and (channel_4604 is not None) and (channel_4614 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4604), json.loads(channel_4614)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4615(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4621(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4621(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4615: typing.Union[str, None],
    channel_4604: typing.Union[str, None]
) -> ResMerge_ch_versions_4621:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4615 or channel_4604 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4621(
        res=res.get('res')
    )


@dataclass
class Dataclass_4626_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str
    channel_3673: str


class Res_4626_pre(NamedTuple):
    default: typing.List[Dataclass_4626_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_INFEREXPERIMENT_4626_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4625: typing.Union[bool, None],
    channel_4595: typing.Union[str, None],
    channel_3673: typing.Union[str, None]
) -> Res_4626_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4625 == True) and (channel_4595 is not None) and (channel_3673 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4626_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595, 'channel_3673': channel_3673})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4626_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_INFEREXPERIMENT_4626_post(NamedTuple):
    txt: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4626_post:
    txt: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_INFEREXPERIMENT_4626_post(
    default: List[Dataclass_4626_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_INFEREXPERIMENT_4626_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_INFEREXPERIMENT_4626_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4626_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4626_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4626_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4626_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_INFEREXPERIMENT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INFEREXPERIMENT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INFEREXPERIMENT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_INFEREXPERIMENT_4626(
    default: Dataclass_4626_pre
) -> Dataclass_4626_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_INFEREXPERIMENT","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INFEREXPERIMENT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_INFEREXPERIMENT\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4626_post(
        txt=out_channels.get(f"txt"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4627(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4627(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4625: typing.Union[bool, None],
    channel_4626_1: typing.Union[str, None]
) -> Resfirst_4627:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4625 == True) and (channel_4626_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4626_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4627(
        res=out_channels.get("res")
    )


class Resmix_4628(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4628(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4625: typing.Union[bool, None],
    channel_4621: typing.Union[str, None],
    channel_4627: typing.Union[str, None]
) -> Resmix_4628:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4625 == True) and (channel_4621 is not None) and (channel_4627 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4621), json.loads(channel_4627)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4628(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4630(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4630(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4628: typing.Union[str, None],
    channel_4621: typing.Union[str, None]
) -> ResMerge_ch_versions_4630:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4628 or channel_4621 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4630(
        res=res.get('res')
    )


class Resfirst_4642(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4642(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4640: typing.Union[bool, None],
    channel_4641_7: typing.Union[str, None]
) -> Resfirst_4642:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4640 == True) and (channel_4641_7 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4641_7)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4642(
        res=out_channels.get("res")
    )


class Resmix_4643(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4643(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4640: typing.Union[bool, None],
    channel_4630: typing.Union[str, None],
    channel_4642: typing.Union[str, None]
) -> Resmix_4643:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4640 == True) and (channel_4630 is not None) and (channel_4642 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4630), json.loads(channel_4642)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4643(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4651(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4651(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4643: typing.Union[str, None],
    channel_4630: typing.Union[str, None]
) -> ResMerge_ch_versions_4651:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4643 or channel_4630 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4651(
        res=res.get('res')
    )


class Resfirst_4658(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4658(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4656: typing.Union[bool, None],
    channel_4657_2: typing.Union[str, None]
) -> Resfirst_4658:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4656 == True) and (channel_4657_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4657_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4658(
        res=out_channels.get("res")
    )


class Resmix_4659(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4659(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4656: typing.Union[bool, None],
    channel_4651: typing.Union[str, None],
    channel_4658: typing.Union[str, None]
) -> Resmix_4659:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4656 == True) and (channel_4651 is not None) and (channel_4658 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4651), json.loads(channel_4658)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4659(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4662(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4662(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4659: typing.Union[str, None],
    channel_4651: typing.Union[str, None]
) -> ResMerge_ch_versions_4662:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4659 or channel_4651 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4662(
        res=res.get('res')
    )


@dataclass
class Dataclass_4667_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4595: str
    channel_3673: str


class Res_4667_pre(NamedTuple):
    default: typing.List[Dataclass_4667_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_READDISTRIBUTION_4667_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4666: typing.Union[bool, None],
    channel_4595: typing.Union[str, None],
    channel_3673: typing.Union[str, None]
) -> Res_4667_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4666 == True) and (channel_4595 is not None) and (channel_3673 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4667_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4595': channel_4595, 'channel_3673': channel_3673})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4667_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_READDISTRIBUTION_4667_post(NamedTuple):
    txt: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4667_post:
    txt: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_READDISTRIBUTION_4667_post(
    default: List[Dataclass_4667_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_READDISTRIBUTION_4667_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_READDISTRIBUTION_4667_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4667_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4667_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4667_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4667_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_READDISTRIBUTION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDISTRIBUTION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDISTRIBUTION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_READDISTRIBUTION_4667(
    default: Dataclass_4667_pre
) -> Dataclass_4667_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4595),json.loads(default.channel_3673)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_READDISTRIBUTION","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDISTRIBUTION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_READDISTRIBUTION\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4667_post(
        txt=out_channels.get(f"txt"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4668(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4668(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4666: typing.Union[bool, None],
    channel_4667_1: typing.Union[str, None]
) -> Resfirst_4668:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4666 == True) and (channel_4667_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4667_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4668(
        res=out_channels.get("res")
    )


class Resmix_4669(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4669(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4666: typing.Union[bool, None],
    channel_4662: typing.Union[str, None],
    channel_4668: typing.Union[str, None]
) -> Resmix_4669:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4666 == True) and (channel_4662 is not None) and (channel_4668 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4662), json.loads(channel_4668)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4669(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4671(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4671(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4669: typing.Union[str, None],
    channel_4662: typing.Union[str, None]
) -> ResMerge_ch_versions_4671:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4669 or channel_4662 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4671(
        res=res.get('res')
    )


class Resfirst_4680(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4680(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4678: typing.Union[bool, None],
    channel_4679_4: typing.Union[str, None]
) -> Resfirst_4680:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4678 == True) and (channel_4679_4 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4679_4)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4680(
        res=out_channels.get("res")
    )


class Resmix_4681(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4681(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4678: typing.Union[bool, None],
    channel_4671: typing.Union[str, None],
    channel_4680: typing.Union[str, None]
) -> Resmix_4681:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4678 == True) and (channel_4671 is not None) and (channel_4680 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4671), json.loads(channel_4680)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4681(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4686(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4686(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4681: typing.Union[str, None],
    channel_4671: typing.Union[str, None]
) -> ResMerge_ch_versions_4686:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4681 or channel_4671 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4686(
        res=res.get('res')
    )


@dataclass
class Dataclass_4691_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4593: str
    channel_3673: str


class Res_4691_pre(NamedTuple):
    default: typing.List[Dataclass_4691_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_RSEQC_TIN_4691_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4690: typing.Union[bool, None],
    channel_4593: typing.Union[str, None],
    channel_3673: typing.Union[str, None]
) -> Res_4691_pre:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4690 == True) and (channel_4593 is not None) and (channel_3673 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4691_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4593': channel_4593, 'channel_3673': channel_3673})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4691_pre(default=result, is_skipped = not cond)

class Respost_adapter_RSEQC_TIN_4691_post(NamedTuple):
    txt: typing.Union[str, None]
    xls: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4691_post:
    txt: str
    xls: str
    versions: str

@task(cache=True)
def post_adapter_RSEQC_TIN_4691_post(
    default: List[Dataclass_4691_post],
    is_skipped: bool,
) -> Respost_adapter_RSEQC_TIN_4691_post:
    return get_mapper_outputs(Respost_adapter_RSEQC_TIN_4691_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4691_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4691_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4691_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4691_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4593),json.loads(default.channel_3673)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_TIN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_TIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_TIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_TIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def RSEQC_TIN_4691(
    default: Dataclass_4691_pre
) -> Dataclass_4691_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4593),json.loads(default.channel_3673)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/nf-core/bam_rseqc/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','BAM_RSEQC'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"RSEQC_TIN","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_TIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"xls\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_TIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"RSEQC_TIN\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4691_post(
        txt=out_channels.get(f"txt"),
        xls=out_channels.get(f"xls"),
        versions=out_channels.get(f"versions")
    )


class Resfirst_4692(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4692(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4690: typing.Union[bool, None],
    channel_4691_2: typing.Union[str, None]
) -> Resfirst_4692:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4690 == True) and (channel_4691_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4691_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4692(
        res=out_channels.get("res")
    )


class Resmix_4693(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4693(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    condition_4690: typing.Union[bool, None],
    channel_4686: typing.Union[str, None],
    channel_4692: typing.Union[str, None]
) -> Resmix_4693:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (condition_4690 == True) and (channel_4686 is not None) and (channel_4692 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4686), json.loads(channel_4692)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4693(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4695(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4695(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4693: typing.Union[str, None],
    channel_4686: typing.Union[str, None]
) -> ResMerge_ch_versions_4695:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4693 or channel_4686 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4695(
        res=res.get('res')
    )


class Resmix_4696(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4696(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4586: typing.Union[str, None],
    channel_4695: typing.Union[str, None]
) -> Resmix_4696:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4586 is not None) and (channel_4695 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4586), json.loads(channel_4695)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4696(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4709(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4709(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4696: typing.Union[str, None],
    channel_4586: typing.Union[str, None]
) -> ResMerge_ch_versions_4709:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4696 or channel_4586 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4709(
        res=res.get('res')
    )


class ResMerge_ch_versions_4714(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4714(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4709: typing.Union[str, None],
    channel_4553: typing.Union[str, None]
) -> ResMerge_ch_versions_4714:
    cond = True

    if cond:
        res = { 'res': channel_4709 or channel_4553 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4714(
        res=res.get('res')
    )


class ResChannel_empty___4738(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4738(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None]
) -> ResChannel_empty___4738:
    cond = ((condition_4728 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4738(
        res=out_channels.get("res")
    )


class Resfirst_4743(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4743(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4741: typing.Union[bool, None],
    channel_4742_2: typing.Union[str, None]
) -> Resfirst_4743:
    cond = ((condition_4728 == True) and (condition_4741 == True) and (channel_4742_2 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4742_2)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4743(
        res=out_channels.get("res")
    )


class Resmix_4744(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4744(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4741: typing.Union[bool, None],
    channel_4738: typing.Union[str, None],
    channel_4743: typing.Union[str, None]
) -> Resmix_4744:
    cond = ((condition_4728 == True) and (condition_4741 == True) and (channel_4738 is not None) and (channel_4743 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4738), json.loads(channel_4743)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4744(
        res=out_channels.get("res")
    )


class Resfirst_4746(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def first_4746(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4741: typing.Union[bool, None],
    channel_4745_3: typing.Union[str, None]
) -> Resfirst_4746:
    cond = ((condition_4728 == True) and (condition_4741 == False) and (channel_4745_3 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4745_3)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"first","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resfirst_4746(
        res=out_channels.get("res")
    )


class Resmix_4747(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4747(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4741: typing.Union[bool, None],
    channel_4738: typing.Union[str, None],
    channel_4746: typing.Union[str, None]
) -> Resmix_4747:
    cond = ((condition_4728 == True) and (condition_4741 == False) and (channel_4738 is not None) and (channel_4746 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4738), json.loads(channel_4746)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4747(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4750(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4750(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4744: typing.Union[str, None],
    channel_4747: typing.Union[str, None]
) -> ResMerge_ch_versions_4750:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_4744 or channel_4747 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4750(
        res=res.get('res')
    )


class Resmix_4753(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4753(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4750: typing.Union[str, None],
    channel_4752_1: typing.Union[str, None]
) -> Resmix_4753:
    cond = ((condition_4728 == True) and (channel_4750 is not None) and (channel_4752_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4750), json.loads(channel_4752_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4753(
        res=out_channels.get("res")
    )


class Resmix_4757(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4757(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4753: typing.Union[str, None],
    channel_4756_8: typing.Union[str, None]
) -> Resmix_4757:
    cond = ((condition_4728 == True) and (channel_4753 is not None) and (channel_4756_8 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4753), json.loads(channel_4756_8)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4757(
        res=out_channels.get("res")
    )


class Rescollect_4758(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4758(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4752_0: typing.Union[str, None]
) -> Rescollect_4758:
    cond = ((condition_4728 == True) and (channel_4752_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4752_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4758(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4759_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4756_1: str
    channel_4756_0: str
    channel_4758: str


class Res_4759_pre(NamedTuple):
    default: typing.List[Dataclass_4759_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_SE_GENE_4759_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4756_1: typing.Union[str, None],
    channel_4756_0: typing.Union[str, None],
    channel_4758: typing.Union[str, None]
) -> Res_4759_pre:
    cond = ((condition_4728 == True) and (channel_4756_1 is not None) and (channel_4756_0 is not None) and (channel_4758 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4759_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4756_1': channel_4756_1, 'channel_4756_0': channel_4756_0, 'channel_4758': channel_4758})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4759_pre(default=result, is_skipped = not cond)

class Respost_adapter_SE_GENE_4759_post(NamedTuple):
    rds: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4759_post:
    rds: str
    versions: str

@task(cache=True)
def post_adapter_SE_GENE_4759_post(
    default: List[Dataclass_4759_post],
    is_skipped: bool,
) -> Respost_adapter_SE_GENE_4759_post:
    return get_mapper_outputs(Respost_adapter_SE_GENE_4759_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4759_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4759_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4759_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4759_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_1),json.loads(default.channel_4756_0),json.loads(default.channel_4758)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def SE_GENE_4759(
    default: Dataclass_4759_pre
) -> Dataclass_4759_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_1),json.loads(default.channel_4756_0),json.loads(default.channel_4758)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/subworkflows/local/quantify_pseudo/main.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','QUANTIFY_PSEUDO_ALIGNMENT'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"SE_GENE","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rds\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"SE_GENE\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4759_post(
        rds=out_channels.get(f"rds"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4760(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4760(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4757: typing.Union[str, None],
    channel_4759_1: typing.Union[str, None]
) -> Resmix_4760:
    cond = ((condition_4728 == True) and (channel_4757 is not None) and (channel_4759_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4757), json.loads(channel_4759_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/local/quantify_pseudo/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'QUANTIFY_PSEUDO_ALIGNMENT'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4760(
        res=out_channels.get("res")
    )


class Resmix_4767(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4767(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4714: typing.Union[str, None],
    channel_4760: typing.Union[str, None]
) -> Resmix_4767:
    cond = ((condition_4728 == True) and (channel_4714 is not None) and (channel_4760 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4714), json.loads(channel_4760)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4767(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4773_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4756_2: str


class Res_4773_pre(NamedTuple):
    default: typing.List[Dataclass_4773_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_DESEQ2_QC_PSEUDO_4773_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4772: typing.Union[bool, None],
    channel_4756_2: typing.Union[str, None]
) -> Res_4773_pre:
    cond = ((condition_4728 == True) and (condition_4772 == True) and (channel_4756_2 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4773_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4756_2': channel_4756_2})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4773_pre(default=result, is_skipped = not cond)

class Respost_adapter_DESEQ2_QC_PSEUDO_4773_post(NamedTuple):
    pdf: typing.Union[str, None]
    rdata: typing.Union[str, None]
    pca_txt: typing.Union[str, None]
    pca_multiqc: typing.Union[str, None]
    dists_txt: typing.Union[str, None]
    dists_multiqc: typing.Union[str, None]
    log: typing.Union[str, None]
    size_factors: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4773_post:
    pdf: str
    rdata: str
    pca_txt: str
    pca_multiqc: str
    dists_txt: str
    dists_multiqc: str
    log: str
    size_factors: str
    versions: str

@task(cache=True)
def post_adapter_DESEQ2_QC_PSEUDO_4773_post(
    default: List[Dataclass_4773_post],
    is_skipped: bool,
) -> Respost_adapter_DESEQ2_QC_PSEUDO_4773_post:
    return get_mapper_outputs(Respost_adapter_DESEQ2_QC_PSEUDO_4773_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4773_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4773_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4773_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4773_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_2)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DESEQ2_QC_PSEUDO","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_pca_header_multiqc"},{"VariableExpression":"ch_clustering_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rdata\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"size_factors\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def DESEQ2_QC_PSEUDO_4773(
    default: Dataclass_4773_pre
) -> Dataclass_4773_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4756_2)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"DESEQ2_QC_PSEUDO","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"VariableExpression":"ch_pca_header_multiqc"},{"VariableExpression":"ch_clustering_header_multiqc"}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pdf\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"rdata\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"pca_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_txt\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":4}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"dists_multiqc\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":5}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"_latch_placeholder_log\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":6}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"size_factors\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":7}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"DESEQ2_QC_PSEUDO\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":8}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4773_post(
        pdf=out_channels.get(f"pdf"),
        rdata=out_channels.get(f"rdata"),
        pca_txt=out_channels.get(f"pca_txt"),
        pca_multiqc=out_channels.get(f"pca_multiqc"),
        dists_txt=out_channels.get(f"dists_txt"),
        dists_multiqc=out_channels.get(f"dists_multiqc"),
        log=out_channels.get(f"log"),
        size_factors=out_channels.get(f"size_factors"),
        versions=out_channels.get(f"versions")
    )


class Resmix_4774(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def mix_4774(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    condition_4772: typing.Union[bool, None],
    channel_4767: typing.Union[str, None],
    channel_4773_8: typing.Union[str, None]
) -> Resmix_4774:
    cond = ((condition_4728 == True) and (condition_4772 == True) and (channel_4767 is not None) and (channel_4773_8 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4767), json.loads(channel_4773_8)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"mix","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmix_4774(
        res=out_channels.get("res")
    )


class ResMerge_ch_versions_4777(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4777(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4774: typing.Union[str, None],
    channel_4767: typing.Union[str, None]
) -> ResMerge_ch_versions_4777:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_4774 or channel_4767 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4777(
        res=res.get('res')
    )


class ResMerge_ch_versions_4781(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_versions_4781(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4777: typing.Union[str, None],
    channel_4714: typing.Union[str, None]
) -> ResMerge_ch_versions_4781:
    cond = True

    if cond:
        res = { 'res': channel_4777 or channel_4714 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_versions_4781(
        res=res.get('res')
    )


class Resunique_4782(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def unique_4782(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4781: typing.Union[str, None]
) -> Resunique_4782:
    cond = ((channel_4781 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4781)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"unique","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resunique_4782(
        res=out_channels.get("res")
    )


class RescollectFile_4783(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_4783(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4782: typing.Union[str, None]
) -> RescollectFile_4783:
    cond = ((channel_4782 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4782)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"collated_versions.yml"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_4783(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4784_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4783: str


class Res_4784_pre(NamedTuple):
    default: typing.List[Dataclass_4784_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_4784_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4783: typing.Union[str, None]
) -> Res_4784_pre:
    cond = ((channel_4783 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4784_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4783': channel_4783})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4784_pre(default=result, is_skipped = not cond)

class Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_4784_post(NamedTuple):
    yml: typing.Union[str, None]
    mqc_yml: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4784_post:
    yml: str
    mqc_yml: str
    versions: str

@task(cache=True)
def post_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_4784_post(
    default: List[Dataclass_4784_post],
    is_skipped: bool,
) -> Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_4784_post:
    return get_mapper_outputs(Respost_adapter_CUSTOM_DUMPSOFTWAREVERSIONS_4784_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4784_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4784_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4784_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4784_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4783)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_DUMPSOFTWAREVERSIONS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mqc_yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def CUSTOM_DUMPSOFTWAREVERSIONS_4784(
    default: Dataclass_4784_pre
) -> Dataclass_4784_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4783)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"CUSTOM_DUMPSOFTWAREVERSIONS","arguments":{"ArgumentListExpression":{"expressions":[{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"mqc_yml\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"CUSTOM_DUMPSOFTWAREVERSIONS\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4784_post(
        yml=out_channels.get(f"yml"),
        mqc_yml=out_channels.get(f"mqc_yml"),
        versions=out_channels.get(f"versions")
    )


class Rescollect_4794(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4794(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4784_1: typing.Union[str, None]
) -> Rescollect_4794:
    cond = ((condition_4787 == True) and (channel_4784_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4784_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4794(
        res=out_channels.get("res")
    )


class ResChannel_value_workflow_summary__4789(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_workflow_summary__4789(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None]
) -> ResChannel_value_workflow_summary__4789:
    cond = ((condition_4787 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"workflow_summary"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_workflow_summary__4789(
        res=out_channels.get("res")
    )


class RescollectFile_4795(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_4795(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4789: typing.Union[str, None]
) -> RescollectFile_4795:
    cond = ((condition_4787 == True) and (channel_4789 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4789)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"workflow_summary_mqc.yaml"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_4795(
        res=out_channels.get("res")
    )


class ResChannel_value_methods_description__4791(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_value_methods_description__4791(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None]
) -> ResChannel_value_methods_description__4791:
    cond = ((condition_4787 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"value","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"methods_description"}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_value_methods_description__4791(
        res=out_channels.get("res")
    )


class RescollectFile_4796(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_4796(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4791: typing.Union[str, None]
) -> RescollectFile_4796:
    cond = ((condition_4787 == True) and (channel_4791 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4791)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"methods_description_mqc.yaml"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_4796(
        res=out_channels.get("res")
    )


class Rescollect_4797(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4797(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None]
) -> Rescollect_4797:
    cond = ((condition_4787 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4797(
        res=out_channels.get("res")
    )


class ResifEmpty_4798(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4798(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4797: typing.Union[str, None]
) -> ResifEmpty_4798:
    cond = ((condition_4787 == True) and (channel_4797 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4797)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4798(
        res=out_channels.get("res")
    )


class Resmap_4014(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4014(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4011: typing.Union[str, None]
) -> Resmap_4014:
    cond = ((condition_3958 == True) and (condition_4006 == True) and (channel_4011 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4011)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"num_reads"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","reads","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4014(
        res=out_channels.get("res")
    )


class ResChannel_empty___4003(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4003(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___4003:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4003(
        res=out_channels.get("res")
    )


class ResMerge_trim_read_count_4026(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_read_count_4026(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4014: typing.Union[str, None],
    channel_4003: typing.Union[str, None]
) -> ResMerge_trim_read_count_4026:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4014 or channel_4003 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_read_count_4026(
        res=res.get('res')
    )


class Resmap_3940(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_3940(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    condition_3932: typing.Union[bool, None],
    channel_3937: typing.Union[str, None]
) -> Resmap_3940:
    cond = ((condition_3890 == True) and (condition_3932 == True) and (channel_3937 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_3937)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"ListExpression":[{"VariableExpression":"meta"},{"VariableExpression":"num_reads"}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","reads","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_3940(
        res=out_channels.get("res")
    )


class ResChannel_empty___3929(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3929(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3929:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3929(
        res=out_channels.get("res")
    )


class ResMerge_trim_read_count_3943(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_read_count_3943(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3940: typing.Union[str, None],
    channel_3929: typing.Union[str, None]
) -> ResMerge_trim_read_count_3943:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3940 or channel_3929 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_read_count_3943(
        res=res.get('res')
    )


class ResChannel_empty___3887(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3887(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3887:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3887(
        res=out_channels.get("res")
    )


class ResMerge_ch_trim_read_count_3954(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_trim_read_count_3954(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3943: typing.Union[str, None],
    channel_3887: typing.Union[str, None]
) -> ResMerge_ch_trim_read_count_3954:
    cond = True

    if cond:
        res = { 'res': channel_3943 or channel_3887 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_trim_read_count_3954(
        res=res.get('res')
    )


class ResMerge_ch_trim_read_count_4040(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_trim_read_count_4040(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4026: typing.Union[str, None],
    channel_3954: typing.Union[str, None]
) -> ResMerge_ch_trim_read_count_4040:
    cond = True

    if cond:
        res = { 'res': channel_4026 or channel_3954 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_trim_read_count_4040(
        res=res.get('res')
    )


class Resmap_4042(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4042(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4040: typing.Union[str, None]
) -> Resmap_4042:
    cond = ((channel_4040 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4040)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"pass_trimmed_reads"},"operation":"[","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}}},"operation":"=","rightExpression":{"ConstantExpression":true}}},"labels":[]}},{"IfStatement":{"booleanExpression":{"BooleanExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareLessThanEqual","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"num_reads"},{"MethodCallExpression":{"objectExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"params"},"property":"min_trimmed_reads"}},"method":"toFloat","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}}},"ifBlock":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"pass_trimmed_reads"},"operation":"[","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}}},"operation":"=","rightExpression":{"ConstantExpression":false}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"GStringExpression":{"verbatimText":"$meta.id\\t$num_reads","strings":[{"ConstantExpression":""},{"ConstantExpression":"\\t"},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}},{"VariableExpression":"num_reads"}]}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"ReturnStatement":{"ConstantExpression":null}},"labels":[]}}],"scope":{"declaredVariables":[],"referencedClassVariables":["compareLessThanEqual","params"]},"labels":[]}},"parameters":["meta","num_reads"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4042(
        res=out_channels.get("res")
    )


class Rescollect_4043(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4043(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4042: typing.Union[str, None]
) -> Rescollect_4043:
    cond = ((channel_4042 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4042)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4043(
        res=out_channels.get("res")
    )


class Resmap_4044(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4044(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4043: typing.Union[str, None]
) -> Resmap_4044:
    cond = ((channel_4043 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4043)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"header"},"operation":"=","rightExpression":{"ListExpression":[{"ConstantExpression":"Sample"},{"ConstantExpression":"Reads after trimming"}]}}},"labels":[]}},{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"multiqcTsvFromList","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"tsv_data"},{"VariableExpression":"header"}]}}}}}],"scope":{"declaredVariables":["header"],"referencedClassVariables":[]},"labels":[]}},"parameters":["tsv_data"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4044(
        res=out_channels.get("res")
    )


class RescollectFile_4799(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_4799(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4044: typing.Union[str, None]
) -> RescollectFile_4799:
    cond = ((condition_4787 == True) and (channel_4044 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4044)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"fail_trimmed_samples_mqc.tsv"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_4799(
        res=out_channels.get("res")
    )


class ResifEmpty_4800(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4800(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4799: typing.Union[str, None]
) -> ResifEmpty_4800:
    cond = ((condition_4787 == True) and (channel_4799 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4799)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4800(
        res=out_channels.get("res")
    )


class Resbranch_4441(NamedTuple):
    passed: typing.Union[str, None]
    fail: typing.Union[str, None]

@task(cache=True)
def branch_4441(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4436: typing.Union[str, None]
) -> Resbranch_4441:
    cond = ((condition_4435 == True) and (channel_4436 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4436)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"branch","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"VariableExpression":"pass"},"labels":["passed"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"pass_mapped_reads"},"operation":"[","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}}},"operation":"=","rightExpression":{"ConstantExpression":true}}},"labels":[]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"GStringExpression":{"verbatimText":"$meta.id\\t$mapped","strings":[{"ConstantExpression":""},{"ConstantExpression":"\\t"},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}},{"VariableExpression":"mapped"}]}}]},{"ConstantExpression":"passed"}]}}}}},{"ExpressionStatement":{"expression":{"NotExpression":{"VariableExpression":"pass"}},"labels":["fail"]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"pass_mapped_reads"},"operation":"[","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}}},"operation":"=","rightExpression":{"ConstantExpression":false}}},"labels":[]}},{"ReturnStatement":{"ConstructorCallExpression":{"type":"nextflow.script.TokenBranchChoice","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[{"GStringExpression":{"verbatimText":"$meta.id\\t$mapped","strings":[{"ConstantExpression":""},{"ConstantExpression":"\\t"},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}},{"VariableExpression":"mapped"}]}}]},{"ConstantExpression":"fail"}]}}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":["meta","mapped","pass"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"passed\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"passed\\"}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"fail\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"res\\"},\\"property\\":\\"fail\\"}}}},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'passed': None, 'fail': None}

    return Resbranch_4441(
        passed=out_channels.get("passed"),
        fail=out_channels.get("fail")
    )


class Rescollect_4442(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4442(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4441_1: typing.Union[str, None]
) -> Rescollect_4442:
    cond = ((condition_4435 == True) and (channel_4441_1 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4441_1)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4442(
        res=out_channels.get("res")
    )


class Resmap_4443(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4443(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4435: typing.Union[bool, None],
    channel_4442: typing.Union[str, None]
) -> Resmap_4443:
    cond = ((condition_4435 == True) and (channel_4442 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4442)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"header"},"operation":"=","rightExpression":{"ListExpression":[{"ConstantExpression":"Sample"},{"ConstantExpression":"STAR uniquely mapped reads (%)"}]}}},"labels":[]}},{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"multiqcTsvFromList","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"tsv_data"},{"VariableExpression":"header"}]}}}}}],"scope":{"declaredVariables":["header"],"referencedClassVariables":[]},"labels":[]}},"parameters":["tsv_data"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4443(
        res=out_channels.get("res")
    )


class ResChannel_empty___4430(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4430(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4430:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4430(
        res=out_channels.get("res")
    )


class ResMerge_ch_fail_mapping_multiqc_4446(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fail_mapping_multiqc_4446(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4443: typing.Union[str, None],
    channel_4430: typing.Union[str, None]
) -> ResMerge_ch_fail_mapping_multiqc_4446:
    cond = True

    if cond:
        res = { 'res': channel_4443 or channel_4430 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fail_mapping_multiqc_4446(
        res=res.get('res')
    )


class RescollectFile_4801(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_4801(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4446: typing.Union[str, None]
) -> RescollectFile_4801:
    cond = ((condition_4787 == True) and (channel_4446 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4446)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"fail_mapped_samples_mqc.tsv"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_4801(
        res=out_channels.get("res")
    )


class ResifEmpty_4802(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4802(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4801: typing.Union[str, None]
) -> ResifEmpty_4802:
    cond = ((condition_4787 == True) and (channel_4801 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4801)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4802(
        res=out_channels.get("res")
    )


class ResChannel_empty___4622(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4622(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4622:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4622(
        res=out_channels.get("res")
    )


class ResMerge_inferexperiment_txt_4629(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_inferexperiment_txt_4629(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4626_0: typing.Union[str, None],
    channel_4622: typing.Union[str, None]
) -> ResMerge_inferexperiment_txt_4629:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4626_0 or channel_4622 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_inferexperiment_txt_4629(
        res=res.get('res')
    )


class Resmap_4697(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4697(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4629: typing.Union[str, None]
) -> Resmap_4697:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4629 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4629)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"inferred_strand"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"getInferexperimentStrandedness","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"strand_log"},{"ConstantExpression":30}]}}}}}},"labels":[]}},{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"pass_strand_check"},"operation":"[","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}}},"operation":"=","rightExpression":{"ConstantExpression":true}}},"labels":[]}},{"IfStatement":{"booleanExpression":{"BooleanExpression":{"NotExpression":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"nextflow.ast.LangHelpers"}},"method":"compareEqual","arguments":{"ArgumentListExpression":{"expressions":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"strandedness"}},{"BinaryExpression":{"leftExpression":{"VariableExpression":"inferred_strand"},"operation":"[","rightExpression":{"ConstantExpression":0}}}]}}}}}},"ifBlock":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"pass_strand_check"},"operation":"[","rightExpression":{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}}}},"operation":"=","rightExpression":{"ConstantExpression":false}}},"labels":[]}},{"ReturnStatement":{"ListExpression":[{"GStringExpression":{"verbatimText":"$meta.id\\t$meta.strandedness\\t$inferred_strand.join(\\t)","strings":[{"ConstantExpression":""},{"ConstantExpression":"\\t"},{"ConstantExpression":"\\t"},{"ConstantExpression":""}],"values":[{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"id"}},{"PropertyExpression":{"objectExpression":{"VariableExpression":"meta"},"property":"strandedness"}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"inferred_strand"},"method":"join","arguments":{"ArgumentListExpression":{"expressions":[{"ConstantExpression":"\\t"}]}}}}]}}]}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"elseBlock":{"ReturnStatement":{"ConstantExpression":null}},"labels":[]}}],"scope":{"declaredVariables":["inferred_strand"],"referencedClassVariables":["compareEqual"]},"labels":[]}},"parameters":["meta","strand_log"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4697(
        res=out_channels.get("res")
    )


class Rescollect_4698(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4698(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4697: typing.Union[str, None]
) -> Rescollect_4698:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4697 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4697)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4698(
        res=out_channels.get("res")
    )


class Resmap_4699(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def map_4699(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4698: typing.Union[str, None]
) -> Resmap_4699:
    cond = ((condition_4569 == True) and (condition_4592 == True) and (channel_4698 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4698)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"map","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"header"},"operation":"=","rightExpression":{"ListExpression":[{"ConstantExpression":"Sample"},{"ConstantExpression":"Provided strandedness"},{"ConstantExpression":"Inferred strandedness"},{"ConstantExpression":"Sense (%)"},{"ConstantExpression":"Antisense (%)"},{"ConstantExpression":"Undetermined (%)"}]}}},"labels":[]}},{"ReturnStatement":{"MethodCallExpression":{"objectExpression":{"ClassExpression":{"type":"WorkflowRnaseq"}},"method":"multiqcTsvFromList","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"tsv_data"},{"VariableExpression":"header"}]}}}}}],"scope":{"declaredVariables":["header"],"referencedClassVariables":[]},"labels":[]}},"parameters":["tsv_data"]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Resmap_4699(
        res=out_channels.get("res")
    )


class ResChannel_empty___4563(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4563(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4563:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4563(
        res=out_channels.get("res")
    )


class ResMerge_ch_fail_strand_multiqc_4700(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fail_strand_multiqc_4700(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4699: typing.Union[str, None],
    channel_4563: typing.Union[str, None]
) -> ResMerge_ch_fail_strand_multiqc_4700:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4699 or channel_4563 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fail_strand_multiqc_4700(
        res=res.get('res')
    )


class ResMerge_ch_fail_strand_multiqc_4715(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fail_strand_multiqc_4715(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4700: typing.Union[str, None],
    channel_4563: typing.Union[str, None]
) -> ResMerge_ch_fail_strand_multiqc_4715:
    cond = True

    if cond:
        res = { 'res': channel_4700 or channel_4563 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fail_strand_multiqc_4715(
        res=res.get('res')
    )


class RescollectFile_4803(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collectFile_4803(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4715: typing.Union[str, None]
) -> RescollectFile_4803:
    cond = ((condition_4787 == True) and (channel_4715 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4715)]

        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collectFile","arguments":{"ArgumentListExpression":{"expressions":[{"MapExpression":[{"MapEntryExpression":{"keyExpression":{"ConstantExpression":"name"},"valueExpression":{"ConstantExpression":"fail_strand_check_mqc.tsv"}}}]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())

        upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RescollectFile_4803(
        res=out_channels.get("res")
    )


class ResifEmpty_4804(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4804(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4803: typing.Union[str, None]
) -> ResifEmpty_4804:
    cond = ((condition_4787 == True) and (channel_4803 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4803)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4804(
        res=out_channels.get("res")
    )


class ResChannel_empty___3970(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3970(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3970:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3970(
        res=out_channels.get("res")
    )


class ResMerge_fastqc_raw_zip_3977(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_raw_zip_3977(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_3974_1: typing.Union[str, None],
    channel_3970: typing.Union[str, None]
) -> ResMerge_fastqc_raw_zip_3977:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_3974_1 or channel_3970 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_raw_zip_3977(
        res=res.get('res')
    )


class ResChannel_empty___3899(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3899(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3899:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3899(
        res=out_channels.get("res")
    )


class ResMerge_fastqc_zip_3907(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_zip_3907(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3903_1: typing.Union[str, None],
    channel_3899: typing.Union[str, None]
) -> ResMerge_fastqc_zip_3907:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3903_1 or channel_3899 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_zip_3907(
        res=res.get('res')
    )


class ResChannel_empty___3884(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3884(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3884:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3884(
        res=out_channels.get("res")
    )


class ResMerge_ch_fastqc_raw_multiqc_3950(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fastqc_raw_multiqc_3950(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3907: typing.Union[str, None],
    channel_3884: typing.Union[str, None]
) -> ResMerge_ch_fastqc_raw_multiqc_3950:
    cond = True

    if cond:
        res = { 'res': channel_3907 or channel_3884 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fastqc_raw_multiqc_3950(
        res=res.get('res')
    )


class ResMerge_ch_fastqc_raw_multiqc_4036(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fastqc_raw_multiqc_4036(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3977: typing.Union[str, None],
    channel_3950: typing.Union[str, None]
) -> ResMerge_ch_fastqc_raw_multiqc_4036:
    cond = True

    if cond:
        res = { 'res': channel_3977 or channel_3950 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fastqc_raw_multiqc_4036(
        res=res.get('res')
    )


class Rescollect_4805(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4805(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4036: typing.Union[str, None]
) -> Rescollect_4805:
    cond = ((condition_4787 == True) and (channel_4036 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4036)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4805(
        res=out_channels.get("res")
    )


class ResifEmpty_4806(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4806(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4805: typing.Union[str, None]
) -> ResifEmpty_4806:
    cond = ((condition_4787 == True) and (channel_4805 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4805)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4806(
        res=out_channels.get("res")
    )


class ResChannel_empty___4002(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4002(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___4002:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4002(
        res=out_channels.get("res")
    )


class ResMerge_fastqc_trim_zip_4022(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_trim_zip_4022(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    condition_4006: typing.Union[bool, None],
    channel_4018_1: typing.Union[str, None],
    channel_4002: typing.Union[str, None]
) -> ResMerge_fastqc_trim_zip_4022:
    cond = ((condition_3958 == True) and (condition_4006 == True))

    if cond:
        res = { 'res': channel_4018_1 or channel_4002 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_trim_zip_4022(
        res=res.get('res')
    )


class ResMerge_fastqc_trim_zip_4027(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_fastqc_trim_zip_4027(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4022: typing.Union[str, None],
    channel_4002: typing.Union[str, None]
) -> ResMerge_fastqc_trim_zip_4027:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4022 or channel_4002 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_fastqc_trim_zip_4027(
        res=res.get('res')
    )


class ResChannel_empty___3927(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3927(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3927:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3927(
        res=out_channels.get("res")
    )


class ResMerge_trim_zip_3944(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_zip_3944(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3933_4: typing.Union[str, None],
    channel_3927: typing.Union[str, None]
) -> ResMerge_trim_zip_3944:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3933_4 or channel_3927 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_zip_3944(
        res=res.get('res')
    )


class ResChannel_empty___3885(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3885(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3885:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3885(
        res=out_channels.get("res")
    )


class ResMerge_ch_fastqc_trim_multiqc_3951(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fastqc_trim_multiqc_3951(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3944: typing.Union[str, None],
    channel_3885: typing.Union[str, None]
) -> ResMerge_ch_fastqc_trim_multiqc_3951:
    cond = True

    if cond:
        res = { 'res': channel_3944 or channel_3885 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fastqc_trim_multiqc_3951(
        res=res.get('res')
    )


class ResMerge_ch_fastqc_trim_multiqc_4037(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_fastqc_trim_multiqc_4037(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4027: typing.Union[str, None],
    channel_3951: typing.Union[str, None]
) -> ResMerge_ch_fastqc_trim_multiqc_4037:
    cond = True

    if cond:
        res = { 'res': channel_4027 or channel_3951 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_fastqc_trim_multiqc_4037(
        res=res.get('res')
    )


class Rescollect_4807(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4807(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4037: typing.Union[str, None]
) -> Rescollect_4807:
    cond = ((condition_4787 == True) and (channel_4037 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4037)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4807(
        res=out_channels.get("res")
    )


class ResifEmpty_4808(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4808(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4807: typing.Union[str, None]
) -> ResifEmpty_4808:
    cond = ((condition_4787 == True) and (channel_4807 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4807)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4808(
        res=out_channels.get("res")
    )


class ResChannel_empty___3996(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3996(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None]
) -> ResChannel_empty___3996:
    cond = ((condition_3958 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_fastp/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_FASTP'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3996(
        res=out_channels.get("res")
    )


class ResMerge_trim_json_4024(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_json_4024(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3958: typing.Union[bool, None],
    channel_4007_1: typing.Union[str, None],
    channel_3996: typing.Union[str, None]
) -> ResMerge_trim_json_4024:
    cond = ((condition_3958 == True))

    if cond:
        res = { 'res': channel_4007_1 or channel_3996 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_json_4024(
        res=res.get('res')
    )


class ResChannel_empty___3928(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3928(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None]
) -> ResChannel_empty___3928:
    cond = ((condition_3890 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/fastq_fastqc_umitools_trimgalore/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'FASTQ_FASTQC_UMITOOLS_TRIMGALORE'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3928(
        res=out_channels.get("res")
    )


class ResMerge_trim_log_3946(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_trim_log_3946(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_3890: typing.Union[bool, None],
    channel_3933_1: typing.Union[str, None],
    channel_3928: typing.Union[str, None]
) -> ResMerge_trim_log_3946:
    cond = ((condition_3890 == True))

    if cond:
        res = { 'res': channel_3933_1 or channel_3928 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_trim_log_3946(
        res=res.get('res')
    )


class ResChannel_empty___3886(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___3886(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___3886:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___3886(
        res=out_channels.get("res")
    )


class ResMerge_ch_trim_log_multiqc_3952(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_trim_log_multiqc_3952(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_3946: typing.Union[str, None],
    channel_3886: typing.Union[str, None]
) -> ResMerge_ch_trim_log_multiqc_3952:
    cond = True

    if cond:
        res = { 'res': channel_3946 or channel_3886 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_trim_log_multiqc_3952(
        res=res.get('res')
    )


class ResMerge_ch_trim_log_multiqc_4038(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_trim_log_multiqc_4038(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4024: typing.Union[str, None],
    channel_3952: typing.Union[str, None]
) -> ResMerge_ch_trim_log_multiqc_4038:
    cond = True

    if cond:
        res = { 'res': channel_4024 or channel_3952 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_trim_log_multiqc_4038(
        res=res.get('res')
    )


class Rescollect_4809(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4809(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4038: typing.Union[str, None]
) -> Rescollect_4809:
    cond = ((condition_4787 == True) and (channel_4038 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4038)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4809(
        res=out_channels.get("res")
    )


class ResifEmpty_4810(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4810(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4809: typing.Union[str, None]
) -> ResifEmpty_4810:
    cond = ((condition_4787 == True) and (channel_4809 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4809)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4810(
        res=out_channels.get("res")
    )


class ResChannel_empty___4053(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4053(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4053:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4053(
        res=out_channels.get("res")
    )


class ResMerge_ch_sortmerna_multiqc_4063(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_sortmerna_multiqc_4063(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4059_1: typing.Union[str, None],
    channel_4053: typing.Union[str, None]
) -> ResMerge_ch_sortmerna_multiqc_4063:
    cond = True

    if cond:
        res = { 'res': channel_4059_1 or channel_4053 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_sortmerna_multiqc_4063(
        res=res.get('res')
    )


class Rescollect_4811(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4811(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4063: typing.Union[str, None]
) -> Rescollect_4811:
    cond = ((condition_4787 == True) and (channel_4063 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4063)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4811(
        res=out_channels.get("res")
    )


class ResifEmpty_4812(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4812(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4811: typing.Union[str, None]
) -> ResifEmpty_4812:
    cond = ((condition_4787 == True) and (channel_4811 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4811)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4812(
        res=out_channels.get("res")
    )


class Rescollect_4813(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4813(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4350: typing.Union[str, None]
) -> Rescollect_4813:
    cond = ((condition_4787 == True) and (channel_4350 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4350)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4813(
        res=out_channels.get("res")
    )


class ResifEmpty_4814(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4814(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4813: typing.Union[str, None]
) -> ResifEmpty_4814:
    cond = ((condition_4787 == True) and (channel_4813 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4813)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4814(
        res=out_channels.get("res")
    )


class ResChannel_empty___4352(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4352(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4352:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4352(
        res=out_channels.get("res")
    )


class ResMerge_ch_hisat2_multiqc_4425(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_hisat2_multiqc_4425(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4362_1: typing.Union[str, None],
    channel_4352: typing.Union[str, None]
) -> ResMerge_ch_hisat2_multiqc_4425:
    cond = True

    if cond:
        res = { 'res': channel_4362_1 or channel_4352 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_hisat2_multiqc_4425(
        res=res.get('res')
    )


class Rescollect_4815(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4815(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4425: typing.Union[str, None]
) -> Rescollect_4815:
    cond = ((condition_4787 == True) and (channel_4425 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4425)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4815(
        res=out_channels.get("res")
    )


class ResifEmpty_4816(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4816(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4815: typing.Union[str, None]
) -> ResifEmpty_4816:
    cond = ((condition_4787 == True) and (channel_4815 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4815)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4816(
        res=out_channels.get("res")
    )


class ResChannel_empty___4294(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4294(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4294:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4294(
        res=out_channels.get("res")
    )


class ResMerge_ch_rsem_multiqc_4342(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_rsem_multiqc_4342(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4302_2: typing.Union[str, None],
    channel_4294: typing.Union[str, None]
) -> ResMerge_ch_rsem_multiqc_4342:
    cond = True

    if cond:
        res = { 'res': channel_4302_2 or channel_4294 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_rsem_multiqc_4342(
        res=res.get('res')
    )


class Rescollect_4817(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4817(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4342: typing.Union[str, None]
) -> Rescollect_4817:
    cond = ((condition_4787 == True) and (channel_4342 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4342)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4817(
        res=out_channels.get("res")
    )


class ResifEmpty_4818(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4818(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4817: typing.Union[str, None]
) -> ResifEmpty_4818:
    cond = ((condition_4787 == True) and (channel_4817 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4817)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4818(
        res=out_channels.get("res")
    )


class ResMerge_ch_pseudo_multiqc_4748(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudo_multiqc_4748(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4742_0: typing.Union[str, None],
    channel_4745_2: typing.Union[str, None]
) -> ResMerge_ch_pseudo_multiqc_4748:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_4742_0 or channel_4745_2 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudo_multiqc_4748(
        res=res.get('res')
    )


class ResChannel_empty___4722(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4722(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4722:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4722(
        res=out_channels.get("res")
    )


class ResMerge_ch_pseudo_multiqc_4779(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudo_multiqc_4779(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4748: typing.Union[str, None],
    channel_4722: typing.Union[str, None]
) -> ResMerge_ch_pseudo_multiqc_4779:
    cond = True

    if cond:
        res = { 'res': channel_4748 or channel_4722 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudo_multiqc_4779(
        res=res.get('res')
    )


class Rescollect_4819(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4819(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4779: typing.Union[str, None]
) -> Rescollect_4819:
    cond = ((condition_4787 == True) and (channel_4779 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4779)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4819(
        res=out_channels.get("res")
    )


class ResifEmpty_4820(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4820(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4819: typing.Union[str, None]
) -> ResifEmpty_4820:
    cond = ((condition_4787 == True) and (channel_4819 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4819)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4820(
        res=out_channels.get("res")
    )


class ResMerge_ch_samtools_stats_4418(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_stats_4418(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4404_0: typing.Union[str, None],
    channel_4376_0: typing.Union[str, None]
) -> ResMerge_ch_samtools_stats_4418:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4404_0 or channel_4376_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_stats_4418(
        res=res.get('res')
    )


class ResMerge_ch_samtools_stats_4238(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_stats_4238(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4176_0: typing.Union[str, None],
    channel_4148_0: typing.Union[str, None]
) -> ResMerge_ch_samtools_stats_4238:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4176_0 or channel_4148_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_stats_4238(
        res=res.get('res')
    )


class ResChannel_empty___4094(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4094(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4094:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4094(
        res=out_channels.get("res")
    )


class ResMerge_ch_samtools_stats_4293(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_stats_4293(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4238: typing.Union[str, None],
    channel_4094: typing.Union[str, None]
) -> ResMerge_ch_samtools_stats_4293:
    cond = True

    if cond:
        res = { 'res': channel_4238 or channel_4094 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_stats_4293(
        res=res.get('res')
    )


class ResMerge_ch_samtools_stats_4348(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_stats_4348(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4316_0: typing.Union[str, None],
    channel_4293: typing.Union[str, None]
) -> ResMerge_ch_samtools_stats_4348:
    cond = True

    if cond:
        res = { 'res': channel_4316_0 or channel_4293 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_stats_4348(
        res=res.get('res')
    )


class ResMerge_ch_samtools_stats_4426(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_stats_4426(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4418: typing.Union[str, None],
    channel_4348: typing.Union[str, None]
) -> ResMerge_ch_samtools_stats_4426:
    cond = True

    if cond:
        res = { 'res': channel_4418 or channel_4348 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_stats_4426(
        res=res.get('res')
    )


class ResMerge_ch_samtools_stats_4495(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_stats_4495(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4481_0: typing.Union[str, None],
    channel_4426: typing.Union[str, None]
) -> ResMerge_ch_samtools_stats_4495:
    cond = True

    if cond:
        res = { 'res': channel_4481_0 or channel_4426 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_stats_4495(
        res=res.get('res')
    )


class Rescollect_4821(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4821(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4495: typing.Union[str, None]
) -> Rescollect_4821:
    cond = ((condition_4787 == True) and (channel_4495 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4495)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4821(
        res=out_channels.get("res")
    )


class ResifEmpty_4822(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4822(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4821: typing.Union[str, None]
) -> ResifEmpty_4822:
    cond = ((condition_4787 == True) and (channel_4821 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4821)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4822(
        res=out_channels.get("res")
    )


class ResMerge_ch_samtools_flagstat_4420(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_flagstat_4420(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4406_0: typing.Union[str, None],
    channel_4378_0: typing.Union[str, None]
) -> ResMerge_ch_samtools_flagstat_4420:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4406_0 or channel_4378_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_flagstat_4420(
        res=res.get('res')
    )


class ResMerge_ch_samtools_flagstat_4234(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_flagstat_4234(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4178_0: typing.Union[str, None],
    channel_4150_0: typing.Union[str, None]
) -> ResMerge_ch_samtools_flagstat_4234:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4178_0 or channel_4150_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_flagstat_4234(
        res=res.get('res')
    )


class ResChannel_empty___4095(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4095(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4095:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4095(
        res=out_channels.get("res")
    )


class ResMerge_ch_samtools_flagstat_4288(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_flagstat_4288(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4234: typing.Union[str, None],
    channel_4095: typing.Union[str, None]
) -> ResMerge_ch_samtools_flagstat_4288:
    cond = True

    if cond:
        res = { 'res': channel_4234 or channel_4095 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_flagstat_4288(
        res=res.get('res')
    )


class ResMerge_ch_samtools_flagstat_4349(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_flagstat_4349(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4318_0: typing.Union[str, None],
    channel_4288: typing.Union[str, None]
) -> ResMerge_ch_samtools_flagstat_4349:
    cond = True

    if cond:
        res = { 'res': channel_4318_0 or channel_4288 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_flagstat_4349(
        res=res.get('res')
    )


class ResMerge_ch_samtools_flagstat_4428(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_flagstat_4428(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4420: typing.Union[str, None],
    channel_4349: typing.Union[str, None]
) -> ResMerge_ch_samtools_flagstat_4428:
    cond = True

    if cond:
        res = { 'res': channel_4420 or channel_4349 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_flagstat_4428(
        res=res.get('res')
    )


class ResMerge_ch_samtools_flagstat_4496(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_flagstat_4496(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4483_0: typing.Union[str, None],
    channel_4428: typing.Union[str, None]
) -> ResMerge_ch_samtools_flagstat_4496:
    cond = True

    if cond:
        res = { 'res': channel_4483_0 or channel_4428 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_flagstat_4496(
        res=res.get('res')
    )


class Rescollect_4823(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4823(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4496: typing.Union[str, None]
) -> Rescollect_4823:
    cond = ((condition_4787 == True) and (channel_4496 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4496)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4823(
        res=out_channels.get("res")
    )


class ResifEmpty_4824(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4824(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4823: typing.Union[str, None]
) -> ResifEmpty_4824:
    cond = ((condition_4787 == True) and (channel_4823 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4823)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4824(
        res=out_channels.get("res")
    )


class ResMerge_ch_samtools_idxstats_4417(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_idxstats_4417(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4357: typing.Union[bool, None],
    channel_4408_0: typing.Union[str, None],
    channel_4380_0: typing.Union[str, None]
) -> ResMerge_ch_samtools_idxstats_4417:
    cond = ((condition_4357 == True))

    if cond:
        res = { 'res': channel_4408_0 or channel_4380_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_idxstats_4417(
        res=res.get('res')
    )


class ResMerge_ch_samtools_idxstats_4237(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_idxstats_4237(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4180_0: typing.Union[str, None],
    channel_4152_0: typing.Union[str, None]
) -> ResMerge_ch_samtools_idxstats_4237:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4180_0 or channel_4152_0 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_idxstats_4237(
        res=res.get('res')
    )


class ResChannel_empty___4096(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4096(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4096:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4096(
        res=out_channels.get("res")
    )


class ResMerge_ch_samtools_idxstats_4292(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_idxstats_4292(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4237: typing.Union[str, None],
    channel_4096: typing.Union[str, None]
) -> ResMerge_ch_samtools_idxstats_4292:
    cond = True

    if cond:
        res = { 'res': channel_4237 or channel_4096 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_idxstats_4292(
        res=res.get('res')
    )


class ResMerge_ch_samtools_idxstats_4346(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_idxstats_4346(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4320_0: typing.Union[str, None],
    channel_4292: typing.Union[str, None]
) -> ResMerge_ch_samtools_idxstats_4346:
    cond = True

    if cond:
        res = { 'res': channel_4320_0 or channel_4292 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_idxstats_4346(
        res=res.get('res')
    )


class ResMerge_ch_samtools_idxstats_4424(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_idxstats_4424(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4417: typing.Union[str, None],
    channel_4346: typing.Union[str, None]
) -> ResMerge_ch_samtools_idxstats_4424:
    cond = True

    if cond:
        res = { 'res': channel_4417 or channel_4346 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_idxstats_4424(
        res=res.get('res')
    )


class ResMerge_ch_samtools_idxstats_4494(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_samtools_idxstats_4494(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4485_0: typing.Union[str, None],
    channel_4424: typing.Union[str, None]
) -> ResMerge_ch_samtools_idxstats_4494:
    cond = True

    if cond:
        res = { 'res': channel_4485_0 or channel_4424 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_samtools_idxstats_4494(
        res=res.get('res')
    )


class Rescollect_4825(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4825(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4494: typing.Union[str, None]
) -> Rescollect_4825:
    cond = ((condition_4787 == True) and (channel_4494 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4494)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4825(
        res=out_channels.get("res")
    )


class ResifEmpty_4826(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4826(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4825: typing.Union[str, None]
) -> ResifEmpty_4826:
    cond = ((condition_4787 == True) and (channel_4825 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4825)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4826(
        res=out_channels.get("res")
    )


class ResChannel_empty___4460(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4460(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4460:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4460(
        res=out_channels.get("res")
    )


class ResMerge_ch_markduplicates_multiqc_4497(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_markduplicates_multiqc_4497(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4471_2: typing.Union[str, None],
    channel_4460: typing.Union[str, None]
) -> ResMerge_ch_markduplicates_multiqc_4497:
    cond = True

    if cond:
        res = { 'res': channel_4471_2 or channel_4460 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_markduplicates_multiqc_4497(
        res=res.get('res')
    )


class Rescollect_4827(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4827(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4497: typing.Union[str, None]
) -> Rescollect_4827:
    cond = ((condition_4787 == True) and (channel_4497 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4497)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4827(
        res=out_channels.get("res")
    )


class ResifEmpty_4828(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4828(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4827: typing.Union[str, None]
) -> ResifEmpty_4828:
    cond = ((condition_4787 == True) and (channel_4827 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4827)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4828(
        res=out_channels.get("res")
    )


class ResChannel_empty___4508(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4508(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4508:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4508(
        res=out_channels.get("res")
    )


class ResMerge_ch_featurecounts_multiqc_4529(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_featurecounts_multiqc_4529(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4525_0: typing.Union[str, None],
    channel_4508: typing.Union[str, None]
) -> ResMerge_ch_featurecounts_multiqc_4529:
    cond = True

    if cond:
        res = { 'res': channel_4525_0 or channel_4508 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_featurecounts_multiqc_4529(
        res=res.get('res')
    )


class Rescollect_4829(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4829(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4529: typing.Union[str, None]
) -> Rescollect_4829:
    cond = ((condition_4787 == True) and (channel_4529 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4529)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4829(
        res=out_channels.get("res")
    )


class ResifEmpty_4830(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4830(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4829: typing.Union[str, None]
) -> ResifEmpty_4830:
    cond = ((condition_4787 == True) and (channel_4829 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4829)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4830(
        res=out_channels.get("res")
    )


class ResChannel_empty___4098(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4098(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4098:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4098(
        res=out_channels.get("res")
    )


class ResMerge_ch_aligner_pca_multiqc_4283(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_pca_multiqc_4283(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4280_3: typing.Union[str, None],
    channel_4098: typing.Union[str, None]
) -> ResMerge_ch_aligner_pca_multiqc_4283:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4280_3 or channel_4098 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_pca_multiqc_4283(
        res=res.get('res')
    )


class ResMerge_ch_aligner_pca_multiqc_4287(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_pca_multiqc_4287(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4283: typing.Union[str, None],
    channel_4098: typing.Union[str, None]
) -> ResMerge_ch_aligner_pca_multiqc_4287:
    cond = True

    if cond:
        res = { 'res': channel_4283 or channel_4098 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_pca_multiqc_4287(
        res=res.get('res')
    )


class ResMerge_ch_aligner_pca_multiqc_4340(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_pca_multiqc_4340(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4337_3: typing.Union[str, None],
    channel_4287: typing.Union[str, None]
) -> ResMerge_ch_aligner_pca_multiqc_4340:
    cond = ((condition_4299 == True))

    if cond:
        res = { 'res': channel_4337_3 or channel_4287 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_pca_multiqc_4340(
        res=res.get('res')
    )


class ResMerge_ch_aligner_pca_multiqc_4347(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_pca_multiqc_4347(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4340: typing.Union[str, None],
    channel_4287: typing.Union[str, None]
) -> ResMerge_ch_aligner_pca_multiqc_4347:
    cond = True

    if cond:
        res = { 'res': channel_4340 or channel_4287 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_pca_multiqc_4347(
        res=res.get('res')
    )


class Rescollect_4831(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4831(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4347: typing.Union[str, None]
) -> Rescollect_4831:
    cond = ((condition_4787 == True) and (channel_4347 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4347)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4831(
        res=out_channels.get("res")
    )


class ResifEmpty_4832(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4832(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4831: typing.Union[str, None]
) -> ResifEmpty_4832:
    cond = ((condition_4787 == True) and (channel_4831 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4831)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4832(
        res=out_channels.get("res")
    )


class ResChannel_empty___4099(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4099(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4099:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4099(
        res=out_channels.get("res")
    )


class ResMerge_ch_aligner_clustering_multiqc_4282(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_clustering_multiqc_4282(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4104: typing.Union[bool, None],
    channel_4280_5: typing.Union[str, None],
    channel_4099: typing.Union[str, None]
) -> ResMerge_ch_aligner_clustering_multiqc_4282:
    cond = ((condition_4104 == True))

    if cond:
        res = { 'res': channel_4280_5 or channel_4099 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_clustering_multiqc_4282(
        res=res.get('res')
    )


class ResMerge_ch_aligner_clustering_multiqc_4286(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_clustering_multiqc_4286(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4282: typing.Union[str, None],
    channel_4099: typing.Union[str, None]
) -> ResMerge_ch_aligner_clustering_multiqc_4286:
    cond = True

    if cond:
        res = { 'res': channel_4282 or channel_4099 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_clustering_multiqc_4286(
        res=res.get('res')
    )


class ResMerge_ch_aligner_clustering_multiqc_4339(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_clustering_multiqc_4339(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4299: typing.Union[bool, None],
    channel_4337_5: typing.Union[str, None],
    channel_4286: typing.Union[str, None]
) -> ResMerge_ch_aligner_clustering_multiqc_4339:
    cond = ((condition_4299 == True))

    if cond:
        res = { 'res': channel_4337_5 or channel_4286 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_clustering_multiqc_4339(
        res=res.get('res')
    )


class ResMerge_ch_aligner_clustering_multiqc_4345(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_aligner_clustering_multiqc_4345(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4339: typing.Union[str, None],
    channel_4286: typing.Union[str, None]
) -> ResMerge_ch_aligner_clustering_multiqc_4345:
    cond = True

    if cond:
        res = { 'res': channel_4339 or channel_4286 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_aligner_clustering_multiqc_4345(
        res=res.get('res')
    )


class Rescollect_4833(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4833(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4345: typing.Union[str, None]
) -> Rescollect_4833:
    cond = ((condition_4787 == True) and (channel_4345 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4345)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4833(
        res=out_channels.get("res")
    )


class ResifEmpty_4834(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4834(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4833: typing.Union[str, None]
) -> ResifEmpty_4834:
    cond = ((condition_4787 == True) and (channel_4833 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4833)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4834(
        res=out_channels.get("res")
    )


class ResChannel_empty___4723(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4723(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4723:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4723(
        res=out_channels.get("res")
    )


class ResMerge_ch_pseudoaligner_pca_multiqc_4776(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudoaligner_pca_multiqc_4776(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4773_3: typing.Union[str, None],
    channel_4723: typing.Union[str, None]
) -> ResMerge_ch_pseudoaligner_pca_multiqc_4776:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_4773_3 or channel_4723 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudoaligner_pca_multiqc_4776(
        res=res.get('res')
    )


class ResMerge_ch_pseudoaligner_pca_multiqc_4780(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudoaligner_pca_multiqc_4780(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4776: typing.Union[str, None],
    channel_4723: typing.Union[str, None]
) -> ResMerge_ch_pseudoaligner_pca_multiqc_4780:
    cond = True

    if cond:
        res = { 'res': channel_4776 or channel_4723 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudoaligner_pca_multiqc_4780(
        res=res.get('res')
    )


class Rescollect_4835(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4835(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4780: typing.Union[str, None]
) -> Rescollect_4835:
    cond = ((condition_4787 == True) and (channel_4780 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4780)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4835(
        res=out_channels.get("res")
    )


class ResifEmpty_4836(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4836(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4835: typing.Union[str, None]
) -> ResifEmpty_4836:
    cond = ((condition_4787 == True) and (channel_4835 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4835)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4836(
        res=out_channels.get("res")
    )


class ResChannel_empty___4724(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4724(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4724:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4724(
        res=out_channels.get("res")
    )


class ResMerge_ch_pseudoaligner_clustering_multiqc_4775(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudoaligner_clustering_multiqc_4775(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4728: typing.Union[bool, None],
    channel_4773_5: typing.Union[str, None],
    channel_4724: typing.Union[str, None]
) -> ResMerge_ch_pseudoaligner_clustering_multiqc_4775:
    cond = ((condition_4728 == True))

    if cond:
        res = { 'res': channel_4773_5 or channel_4724 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudoaligner_clustering_multiqc_4775(
        res=res.get('res')
    )


class ResMerge_ch_pseudoaligner_clustering_multiqc_4778(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_pseudoaligner_clustering_multiqc_4778(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4775: typing.Union[str, None],
    channel_4724: typing.Union[str, None]
) -> ResMerge_ch_pseudoaligner_clustering_multiqc_4778:
    cond = True

    if cond:
        res = { 'res': channel_4775 or channel_4724 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_pseudoaligner_clustering_multiqc_4778(
        res=res.get('res')
    )


class Rescollect_4837(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4837(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4778: typing.Union[str, None]
) -> Rescollect_4837:
    cond = ((condition_4787 == True) and (channel_4778 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4778)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4837(
        res=out_channels.get("res")
    )


class ResifEmpty_4838(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4838(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4837: typing.Union[str, None]
) -> ResifEmpty_4838:
    cond = ((condition_4787 == True) and (channel_4837 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4837)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4838(
        res=out_channels.get("res")
    )


class ResChannel_empty___4447(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4447(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4447:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4447(
        res=out_channels.get("res")
    )


class ResMerge_ch_preseq_multiqc_4458(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_preseq_multiqc_4458(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4455_0: typing.Union[str, None],
    channel_4447: typing.Union[str, None]
) -> ResMerge_ch_preseq_multiqc_4458:
    cond = True

    if cond:
        res = { 'res': channel_4455_0 or channel_4447 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_preseq_multiqc_4458(
        res=res.get('res')
    )


class Rescollect_4839(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4839(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4458: typing.Union[str, None]
) -> Rescollect_4839:
    cond = ((condition_4787 == True) and (channel_4458 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4458)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4839(
        res=out_channels.get("res")
    )


class ResifEmpty_4840(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4840(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4839: typing.Union[str, None]
) -> ResifEmpty_4840:
    cond = ((condition_4787 == True) and (channel_4839 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4839)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4840(
        res=out_channels.get("res")
    )


class ResChannel_empty___4554(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4554(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4554:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4554(
        res=out_channels.get("res")
    )


class ResMerge_ch_qualimap_multiqc_4577(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_qualimap_multiqc_4577(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4574_0: typing.Union[str, None],
    channel_4554: typing.Union[str, None]
) -> ResMerge_ch_qualimap_multiqc_4577:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4574_0 or channel_4554 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_qualimap_multiqc_4577(
        res=res.get('res')
    )


class ResMerge_ch_qualimap_multiqc_4719(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_qualimap_multiqc_4719(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4577: typing.Union[str, None],
    channel_4554: typing.Union[str, None]
) -> ResMerge_ch_qualimap_multiqc_4719:
    cond = True

    if cond:
        res = { 'res': channel_4577 or channel_4554 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_qualimap_multiqc_4719(
        res=res.get('res')
    )


class Rescollect_4841(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4841(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4719: typing.Union[str, None]
) -> Rescollect_4841:
    cond = ((condition_4787 == True) and (channel_4719 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4719)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4841(
        res=out_channels.get("res")
    )


class ResifEmpty_4842(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4842(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4841: typing.Union[str, None]
) -> ResifEmpty_4842:
    cond = ((condition_4787 == True) and (channel_4841 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4841)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4842(
        res=out_channels.get("res")
    )


class ResChannel_empty___4555(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4555(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4555:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4555(
        res=out_channels.get("res")
    )


class ResMerge_ch_dupradar_multiqc_4585(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_dupradar_multiqc_4585(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4582_2: typing.Union[str, None],
    channel_4555: typing.Union[str, None]
) -> ResMerge_ch_dupradar_multiqc_4585:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4582_2 or channel_4555 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_dupradar_multiqc_4585(
        res=res.get('res')
    )


class ResMerge_ch_dupradar_multiqc_4710(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_dupradar_multiqc_4710(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4585: typing.Union[str, None],
    channel_4555: typing.Union[str, None]
) -> ResMerge_ch_dupradar_multiqc_4710:
    cond = True

    if cond:
        res = { 'res': channel_4585 or channel_4555 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_dupradar_multiqc_4710(
        res=res.get('res')
    )


class Rescollect_4843(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4843(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4710: typing.Union[str, None]
) -> Rescollect_4843:
    cond = ((condition_4787 == True) and (channel_4710 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4710)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4843(
        res=out_channels.get("res")
    )


class ResifEmpty_4844(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4844(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4843: typing.Union[str, None]
) -> ResifEmpty_4844:
    cond = ((condition_4787 == True) and (channel_4843 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4843)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4844(
        res=out_channels.get("res")
    )


class ResChannel_empty___4596(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4596(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4596:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4596(
        res=out_channels.get("res")
    )


class ResMerge_bamstat_txt_4603(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_bamstat_txt_4603(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4600_0: typing.Union[str, None],
    channel_4596: typing.Union[str, None]
) -> ResMerge_bamstat_txt_4603:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4600_0 or channel_4596 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_bamstat_txt_4603(
        res=res.get('res')
    )


class ResChannel_empty___4556(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4556(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4556:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4556(
        res=out_channels.get("res")
    )


class ResMerge_ch_bamstat_multiqc_4707(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bamstat_multiqc_4707(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4603: typing.Union[str, None],
    channel_4556: typing.Union[str, None]
) -> ResMerge_ch_bamstat_multiqc_4707:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4603 or channel_4556 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bamstat_multiqc_4707(
        res=res.get('res')
    )


class ResMerge_ch_bamstat_multiqc_4720(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_bamstat_multiqc_4720(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4707: typing.Union[str, None],
    channel_4556: typing.Union[str, None]
) -> ResMerge_ch_bamstat_multiqc_4720:
    cond = True

    if cond:
        res = { 'res': channel_4707 or channel_4556 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_bamstat_multiqc_4720(
        res=res.get('res')
    )


class Rescollect_4845(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4845(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4720: typing.Union[str, None]
) -> Rescollect_4845:
    cond = ((condition_4787 == True) and (channel_4720 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4720)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4845(
        res=out_channels.get("res")
    )


class ResifEmpty_4846(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4846(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4845: typing.Union[str, None]
) -> ResifEmpty_4846:
    cond = ((condition_4787 == True) and (channel_4845 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4845)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4846(
        res=out_channels.get("res")
    )


class ResChannel_empty___4557(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4557(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4557:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4557(
        res=out_channels.get("res")
    )


class ResMerge_ch_inferexperiment_multiqc_4702(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_inferexperiment_multiqc_4702(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4629: typing.Union[str, None],
    channel_4557: typing.Union[str, None]
) -> ResMerge_ch_inferexperiment_multiqc_4702:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4629 or channel_4557 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_inferexperiment_multiqc_4702(
        res=res.get('res')
    )


class ResMerge_ch_inferexperiment_multiqc_4711(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_inferexperiment_multiqc_4711(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4702: typing.Union[str, None],
    channel_4557: typing.Union[str, None]
) -> ResMerge_ch_inferexperiment_multiqc_4711:
    cond = True

    if cond:
        res = { 'res': channel_4702 or channel_4557 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_inferexperiment_multiqc_4711(
        res=res.get('res')
    )


class Rescollect_4847(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4847(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4711: typing.Union[str, None]
) -> Rescollect_4847:
    cond = ((condition_4787 == True) and (channel_4711 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4711)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4847(
        res=out_channels.get("res")
    )


class ResifEmpty_4848(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4848(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4847: typing.Union[str, None]
) -> ResifEmpty_4848:
    cond = ((condition_4787 == True) and (channel_4847 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4847)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4848(
        res=out_channels.get("res")
    )


class ResChannel_empty___4606(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4606(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4606:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4606(
        res=out_channels.get("res")
    )


class ResMerge_innerdistance_freq_4619(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_innerdistance_freq_4619(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4613_1: typing.Union[str, None],
    channel_4606: typing.Union[str, None]
) -> ResMerge_innerdistance_freq_4619:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4613_1 or channel_4606 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_innerdistance_freq_4619(
        res=res.get('res')
    )


class ResChannel_empty___4558(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4558(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4558:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4558(
        res=out_channels.get("res")
    )


class ResMerge_ch_innerdistance_multiqc_4703(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_innerdistance_multiqc_4703(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4619: typing.Union[str, None],
    channel_4558: typing.Union[str, None]
) -> ResMerge_ch_innerdistance_multiqc_4703:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4619 or channel_4558 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_innerdistance_multiqc_4703(
        res=res.get('res')
    )


class ResMerge_ch_innerdistance_multiqc_4717(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_innerdistance_multiqc_4717(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4703: typing.Union[str, None],
    channel_4558: typing.Union[str, None]
) -> ResMerge_ch_innerdistance_multiqc_4717:
    cond = True

    if cond:
        res = { 'res': channel_4703 or channel_4558 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_innerdistance_multiqc_4717(
        res=res.get('res')
    )


class Rescollect_4849(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4849(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4717: typing.Union[str, None]
) -> Rescollect_4849:
    cond = ((condition_4787 == True) and (channel_4717 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4717)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4849(
        res=out_channels.get("res")
    )


class ResifEmpty_4850(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4850(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4849: typing.Union[str, None]
) -> ResifEmpty_4850:
    cond = ((condition_4787 == True) and (channel_4849 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4849)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4850(
        res=out_channels.get("res")
    )


class ResChannel_empty___4637(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4637(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4637:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4637(
        res=out_channels.get("res")
    )


class ResMerge_junctionannotation_log_4645(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionannotation_log_4645(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4641_2: typing.Union[str, None],
    channel_4637: typing.Union[str, None]
) -> ResMerge_junctionannotation_log_4645:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4641_2 or channel_4637 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionannotation_log_4645(
        res=res.get('res')
    )


class ResChannel_empty___4559(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4559(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4559:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4559(
        res=out_channels.get("res")
    )


class ResMerge_ch_junctionannotation_multiqc_4704(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_junctionannotation_multiqc_4704(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4645: typing.Union[str, None],
    channel_4559: typing.Union[str, None]
) -> ResMerge_ch_junctionannotation_multiqc_4704:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4645 or channel_4559 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_junctionannotation_multiqc_4704(
        res=res.get('res')
    )


class ResMerge_ch_junctionannotation_multiqc_4718(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_junctionannotation_multiqc_4718(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4704: typing.Union[str, None],
    channel_4559: typing.Union[str, None]
) -> ResMerge_ch_junctionannotation_multiqc_4718:
    cond = True

    if cond:
        res = { 'res': channel_4704 or channel_4559 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_junctionannotation_multiqc_4718(
        res=res.get('res')
    )


class Rescollect_4851(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4851(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4718: typing.Union[str, None]
) -> Rescollect_4851:
    cond = ((condition_4787 == True) and (channel_4718 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4718)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4851(
        res=out_channels.get("res")
    )


class ResifEmpty_4852(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4852(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4851: typing.Union[str, None]
) -> ResifEmpty_4852:
    cond = ((condition_4787 == True) and (channel_4851 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4851)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4852(
        res=out_channels.get("res")
    )


class ResChannel_empty___4653(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4653(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4653:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4653(
        res=out_channels.get("res")
    )


class ResMerge_junctionsaturation_rscript_4660(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_junctionsaturation_rscript_4660(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4657_1: typing.Union[str, None],
    channel_4653: typing.Union[str, None]
) -> ResMerge_junctionsaturation_rscript_4660:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4657_1 or channel_4653 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_junctionsaturation_rscript_4660(
        res=res.get('res')
    )


class ResChannel_empty___4560(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4560(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4560:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4560(
        res=out_channels.get("res")
    )


class ResMerge_ch_junctionsaturation_multiqc_4706(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_junctionsaturation_multiqc_4706(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4660: typing.Union[str, None],
    channel_4560: typing.Union[str, None]
) -> ResMerge_ch_junctionsaturation_multiqc_4706:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4660 or channel_4560 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_junctionsaturation_multiqc_4706(
        res=res.get('res')
    )


class ResMerge_ch_junctionsaturation_multiqc_4713(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_junctionsaturation_multiqc_4713(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4706: typing.Union[str, None],
    channel_4560: typing.Union[str, None]
) -> ResMerge_ch_junctionsaturation_multiqc_4713:
    cond = True

    if cond:
        res = { 'res': channel_4706 or channel_4560 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_junctionsaturation_multiqc_4713(
        res=res.get('res')
    )


class Rescollect_4853(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4853(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4713: typing.Union[str, None]
) -> Rescollect_4853:
    cond = ((condition_4787 == True) and (channel_4713 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4713)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4853(
        res=out_channels.get("res")
    )


class ResifEmpty_4854(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4854(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4853: typing.Union[str, None]
) -> ResifEmpty_4854:
    cond = ((condition_4787 == True) and (channel_4853 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4853)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4854(
        res=out_channels.get("res")
    )


class ResChannel_empty___4663(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4663(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4663:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4663(
        res=out_channels.get("res")
    )


class ResMerge_readdistribution_txt_4670(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_readdistribution_txt_4670(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4667_0: typing.Union[str, None],
    channel_4663: typing.Union[str, None]
) -> ResMerge_readdistribution_txt_4670:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4667_0 or channel_4663 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_readdistribution_txt_4670(
        res=res.get('res')
    )


class ResChannel_empty___4561(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4561(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4561:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4561(
        res=out_channels.get("res")
    )


class ResMerge_ch_readdistribution_multiqc_4705(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_readdistribution_multiqc_4705(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4670: typing.Union[str, None],
    channel_4561: typing.Union[str, None]
) -> ResMerge_ch_readdistribution_multiqc_4705:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4670 or channel_4561 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_readdistribution_multiqc_4705(
        res=res.get('res')
    )


class ResMerge_ch_readdistribution_multiqc_4712(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_readdistribution_multiqc_4712(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4705: typing.Union[str, None],
    channel_4561: typing.Union[str, None]
) -> ResMerge_ch_readdistribution_multiqc_4712:
    cond = True

    if cond:
        res = { 'res': channel_4705 or channel_4561 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_readdistribution_multiqc_4712(
        res=res.get('res')
    )


class Rescollect_4855(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4855(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4712: typing.Union[str, None]
) -> Rescollect_4855:
    cond = ((condition_4787 == True) and (channel_4712 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4712)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4855(
        res=out_channels.get("res")
    )


class ResifEmpty_4856(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4856(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4855: typing.Union[str, None]
) -> ResifEmpty_4856:
    cond = ((condition_4787 == True) and (channel_4855 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4855)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4856(
        res=out_channels.get("res")
    )


class ResChannel_empty___4673(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4673(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4673:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4673(
        res=out_channels.get("res")
    )


class ResMerge_readduplication_pos_xls_4684(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_readduplication_pos_xls_4684(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4679_1: typing.Union[str, None],
    channel_4673: typing.Union[str, None]
) -> ResMerge_readduplication_pos_xls_4684:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4679_1 or channel_4673 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_readduplication_pos_xls_4684(
        res=res.get('res')
    )


class ResChannel_empty___4562(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4562(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4562:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4562(
        res=out_channels.get("res")
    )


class ResMerge_ch_readduplication_multiqc_4708(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_readduplication_multiqc_4708(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4684: typing.Union[str, None],
    channel_4562: typing.Union[str, None]
) -> ResMerge_ch_readduplication_multiqc_4708:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4684 or channel_4562 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_readduplication_multiqc_4708(
        res=res.get('res')
    )


class ResMerge_ch_readduplication_multiqc_4721(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_readduplication_multiqc_4721(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4708: typing.Union[str, None],
    channel_4562: typing.Union[str, None]
) -> ResMerge_ch_readduplication_multiqc_4721:
    cond = True

    if cond:
        res = { 'res': channel_4708 or channel_4562 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_readduplication_multiqc_4721(
        res=res.get('res')
    )


class Rescollect_4857(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4857(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4721: typing.Union[str, None]
) -> Rescollect_4857:
    cond = ((condition_4787 == True) and (channel_4721 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4721)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4857(
        res=out_channels.get("res")
    )


class ResifEmpty_4858(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4858(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4857: typing.Union[str, None]
) -> ResifEmpty_4858:
    cond = ((condition_4787 == True) and (channel_4857 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4857)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4858(
        res=out_channels.get("res")
    )


class ResChannel_empty___4687(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4687(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None]
) -> ResChannel_empty___4687:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/subworkflows/nf-core/bam_rseqc/main.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'BAM_RSEQC'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4687(
        res=out_channels.get("res")
    )


class ResMerge_tin_txt_4694(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_tin_txt_4694(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    condition_4592: typing.Union[bool, None],
    channel_4691_0: typing.Union[str, None],
    channel_4687: typing.Union[str, None]
) -> ResMerge_tin_txt_4694:
    cond = ((condition_4569 == True) and (condition_4592 == True))

    if cond:
        res = { 'res': channel_4691_0 or channel_4687 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_tin_txt_4694(
        res=res.get('res')
    )


class ResChannel_empty___4564(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Channel_empty___4564(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None]
) -> ResChannel_empty___4564:
    cond = True

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = []



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"empty","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResChannel_empty___4564(
        res=out_channels.get("res")
    )


class ResMerge_ch_tin_multiqc_4701(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_tin_multiqc_4701(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4569: typing.Union[bool, None],
    channel_4694: typing.Union[str, None],
    channel_4564: typing.Union[str, None]
) -> ResMerge_ch_tin_multiqc_4701:
    cond = ((condition_4569 == True))

    if cond:
        res = { 'res': channel_4694 or channel_4564 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_tin_multiqc_4701(
        res=res.get('res')
    )


class ResMerge_ch_tin_multiqc_4716(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def Merge_ch_tin_multiqc_4716(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    channel_4701: typing.Union[str, None],
    channel_4564: typing.Union[str, None]
) -> ResMerge_ch_tin_multiqc_4716:
    cond = True

    if cond:
        res = { 'res': channel_4701 or channel_4564 }
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        res = {}

    return ResMerge_ch_tin_multiqc_4716(
        res=res.get('res')
    )


class Rescollect_4859(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def collect_4859(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4716: typing.Union[str, None]
) -> Rescollect_4859:
    cond = ((condition_4787 == True) and (channel_4716 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4716)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"collect","arguments":{"ArgumentListExpression":{"expressions":[{"ClosureExpression":{"code":{"BlockStatement":{"statements":[{"ReturnStatement":{"BinaryExpression":{"leftExpression":{"VariableExpression":"it"},"operation":"[","rightExpression":{"ConstantExpression":1}}}}],"scope":{"declaredVariables":[],"referencedClassVariables":[]},"labels":[]}},"parameters":[]}}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return Rescollect_4859(
        res=out_channels.get("res")
    )


class ResifEmpty_4860(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def ifEmpty_4860(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4859: typing.Union[str, None]
) -> ResifEmpty_4860:
    cond = ((condition_4787 == True) and (channel_4859 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4859)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"ifEmpty","arguments":{"ArgumentListExpression":{"expressions":[{"ListExpression":[]}]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return ResifEmpty_4860(
        res=out_channels.get("res")
    )


@dataclass
class Dataclass_4861_pre:
    wf_input: LatchFile
    wf_genome: str
    wf_aligner: str
    wf_outdir: str
    channel_4793: str
    channel_4794: str
    channel_4795: str
    channel_4796: str
    channel_4798: str
    channel_4800: str
    channel_4802: str
    channel_4804: str
    channel_4806: str
    channel_4808: str
    channel_4810: str
    channel_4812: str
    channel_4814: str
    channel_4816: str
    channel_4818: str
    channel_4820: str
    channel_4822: str
    channel_4824: str
    channel_4826: str
    channel_4828: str
    channel_4830: str
    channel_4832: str
    channel_4834: str
    channel_4836: str
    channel_4838: str
    channel_4840: str
    channel_4842: str
    channel_4844: str
    channel_4846: str
    channel_4848: str
    channel_4850: str
    channel_4852: str
    channel_4854: str
    channel_4856: str
    channel_4858: str
    channel_4860: str


class Res_4861_pre(NamedTuple):
    default: typing.List[Dataclass_4861_pre]
    is_skipped: bool

@task(cache=True)
def pre_adapter_MULTIQC_4861_pre(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4793: typing.Union[str, None],
    channel_4794: typing.Union[str, None],
    channel_4795: typing.Union[str, None],
    channel_4796: typing.Union[str, None],
    channel_4798: typing.Union[str, None],
    channel_4800: typing.Union[str, None],
    channel_4802: typing.Union[str, None],
    channel_4804: typing.Union[str, None],
    channel_4806: typing.Union[str, None],
    channel_4808: typing.Union[str, None],
    channel_4810: typing.Union[str, None],
    channel_4812: typing.Union[str, None],
    channel_4814: typing.Union[str, None],
    channel_4816: typing.Union[str, None],
    channel_4818: typing.Union[str, None],
    channel_4820: typing.Union[str, None],
    channel_4822: typing.Union[str, None],
    channel_4824: typing.Union[str, None],
    channel_4826: typing.Union[str, None],
    channel_4828: typing.Union[str, None],
    channel_4830: typing.Union[str, None],
    channel_4832: typing.Union[str, None],
    channel_4834: typing.Union[str, None],
    channel_4836: typing.Union[str, None],
    channel_4838: typing.Union[str, None],
    channel_4840: typing.Union[str, None],
    channel_4842: typing.Union[str, None],
    channel_4844: typing.Union[str, None],
    channel_4846: typing.Union[str, None],
    channel_4848: typing.Union[str, None],
    channel_4850: typing.Union[str, None],
    channel_4852: typing.Union[str, None],
    channel_4854: typing.Union[str, None],
    channel_4856: typing.Union[str, None],
    channel_4858: typing.Union[str, None],
    channel_4860: typing.Union[str, None]
) -> Res_4861_pre:
    cond = ((condition_4787 == True) and (channel_4793 is not None) and (channel_4794 is not None) and (channel_4795 is not None) and (channel_4796 is not None) and (channel_4798 is not None) and (channel_4800 is not None) and (channel_4802 is not None) and (channel_4804 is not None) and (channel_4806 is not None) and (channel_4808 is not None) and (channel_4810 is not None) and (channel_4812 is not None) and (channel_4814 is not None) and (channel_4816 is not None) and (channel_4818 is not None) and (channel_4820 is not None) and (channel_4822 is not None) and (channel_4824 is not None) and (channel_4826 is not None) and (channel_4828 is not None) and (channel_4830 is not None) and (channel_4832 is not None) and (channel_4834 is not None) and (channel_4836 is not None) and (channel_4838 is not None) and (channel_4840 is not None) and (channel_4842 is not None) and (channel_4844 is not None) and (channel_4846 is not None) and (channel_4848 is not None) and (channel_4850 is not None) and (channel_4852 is not None) and (channel_4854 is not None) and (channel_4856 is not None) and (channel_4858 is not None) and (channel_4860 is not None))

    if cond:
        result = get_mapper_inputs(Dataclass_4861_pre, {'wf_input': wf_input, 'wf_genome': wf_genome, 'wf_aligner': wf_aligner, 'wf_outdir': wf_outdir}, {'channel_4793': channel_4793, 'channel_4794': channel_4794, 'channel_4795': channel_4795, 'channel_4796': channel_4796, 'channel_4798': channel_4798, 'channel_4800': channel_4800, 'channel_4802': channel_4802, 'channel_4804': channel_4804, 'channel_4806': channel_4806, 'channel_4808': channel_4808, 'channel_4810': channel_4810, 'channel_4812': channel_4812, 'channel_4814': channel_4814, 'channel_4816': channel_4816, 'channel_4818': channel_4818, 'channel_4820': channel_4820, 'channel_4822': channel_4822, 'channel_4824': channel_4824, 'channel_4826': channel_4826, 'channel_4828': channel_4828, 'channel_4830': channel_4830, 'channel_4832': channel_4832, 'channel_4834': channel_4834, 'channel_4836': channel_4836, 'channel_4838': channel_4838, 'channel_4840': channel_4840, 'channel_4842': channel_4842, 'channel_4844': channel_4844, 'channel_4846': channel_4846, 'channel_4848': channel_4848, 'channel_4850': channel_4850, 'channel_4852': channel_4852, 'channel_4854': channel_4854, 'channel_4856': channel_4856, 'channel_4858': channel_4858, 'channel_4860': channel_4860})
    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        result = []

    return Res_4861_pre(default=result, is_skipped = not cond)

class Respost_adapter_MULTIQC_4861_post(NamedTuple):
    report: typing.Union[str, None]
    data: typing.Union[str, None]
    plots: typing.Union[str, None]
    versions: typing.Union[str, None]

@dataclass
class Dataclass_4861_post:
    report: str
    data: str
    plots: str
    versions: str

@task(cache=True)
def post_adapter_MULTIQC_4861_post(
    default: List[Dataclass_4861_post],
    is_skipped: bool,
) -> Respost_adapter_MULTIQC_4861_post:
    return get_mapper_outputs(Respost_adapter_MULTIQC_4861_post, default, is_skipped)


def _read_resources() -> Dict:
    try:
        with open(".latch/resources.json") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def allocate_cpu(default: Dataclass_4861_pre) -> int:
    res = _read_resources()
    return max(1, res['cpu_cores']) if res.get('cpu_cores') is not None else 16

def allocate_memory(default: Dataclass_4861_pre) -> int:
    res = _read_resources()
    return max(1, res['memory_bytes'] // 1024**3) if res.get('memory_bytes') is not None else 48

def allocate_disk(default: Dataclass_4861_pre) -> int:
    res = _read_resources()
    return max(1, res['disk_bytes'] // 1024**3) if res.get('disk_bytes') is not None else 500

def get_resources(default: Dataclass_4861_pre):
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not True:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4793),json.loads(default.channel_4794),json.loads(default.channel_4795),json.loads(default.channel_4796),json.loads(default.channel_4798),json.loads(default.channel_4800),json.loads(default.channel_4802),json.loads(default.channel_4804),json.loads(default.channel_4806),json.loads(default.channel_4808),json.loads(default.channel_4810),json.loads(default.channel_4812),json.loads(default.channel_4814),json.loads(default.channel_4816),json.loads(default.channel_4818),json.loads(default.channel_4820),json.loads(default.channel_4822),json.loads(default.channel_4824),json.loads(default.channel_4826),json.loads(default.channel_4828),json.loads(default.channel_4830),json.loads(default.channel_4832),json.loads(default.channel_4834),json.loads(default.channel_4836),json.loads(default.channel_4838),json.loads(default.channel_4840),json.loads(default.channel_4842),json.loads(default.channel_4844),json.loads(default.channel_4846),json.loads(default.channel_4848),json.loads(default.channel_4850),json.loads(default.channel_4852),json.loads(default.channel_4854),json.loads(default.channel_4856),json.loads(default.channel_4858),json.loads(default.channel_4860)]

    if not True:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"ch_multiqc_config"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"data\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"plots\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'True',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

@custom_task(cpu=allocate_cpu, memory=allocate_memory, storage_gib=allocate_disk, pre_execute=get_resources, cache=True)
def MULTIQC_4861(
    default: Dataclass_4861_pre
) -> Dataclass_4861_post:
    wf_paths = {}
    wf_input = default.wf_input
    if wf_input is not None:
        if not False:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name
        else:
            wf_paths["wf_input"] = Path("/root") / "wf_input"

    wf_genome = default.wf_genome
    wf_aligner = default.wf_aligner
    wf_outdir = default.wf_outdir

    channel_vals = [json.loads(default.channel_4793),json.loads(default.channel_4794),json.loads(default.channel_4795),json.loads(default.channel_4796),json.loads(default.channel_4798),json.loads(default.channel_4800),json.loads(default.channel_4802),json.loads(default.channel_4804),json.loads(default.channel_4806),json.loads(default.channel_4808),json.loads(default.channel_4810),json.loads(default.channel_4812),json.loads(default.channel_4814),json.loads(default.channel_4816),json.loads(default.channel_4818),json.loads(default.channel_4820),json.loads(default.channel_4822),json.loads(default.channel_4824),json.loads(default.channel_4826),json.loads(default.channel_4828),json.loads(default.channel_4830),json.loads(default.channel_4832),json.loads(default.channel_4834),json.loads(default.channel_4836),json.loads(default.channel_4838),json.loads(default.channel_4840),json.loads(default.channel_4842),json.loads(default.channel_4844),json.loads(default.channel_4846),json.loads(default.channel_4848),json.loads(default.channel_4850),json.loads(default.channel_4852),json.loads(default.channel_4854),json.loads(default.channel_4856),json.loads(default.channel_4858),json.loads(default.channel_4860)]

    if not False:
        download_files(channel_vals, LatchDir('latch://1721.account/your_output_directory'))

    try:
        subprocess.run(
            ['/root/nextflow','run','/root/workflows/rnaseq.nf','-lib','lib','--input',str(wf_paths['wf_input']),'--genome',str(wf_genome),'--aligner',str(wf_aligner),'--outdir',str(wf_outdir),'-entry','RNASEQ'],
            env={
                **os.environ,
                "LATCH_BIN_DIR_OVERRIDE": str(Path.cwd() / "bin"),
                "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"this"},"method":"MULTIQC","arguments":{"ArgumentListExpression":{"expressions":[{"VariableExpression":"ch_multiqc_config"},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}}]}}}},"labels":[]}}',
                "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"report\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":0}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"data\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":1}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"plots\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":2}}}}},\\"labels\\":[]}}", "{\\"ExpressionStatement\\":{\\"expression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"VariableExpression\\":\\"versions\\"},\\"operation\\":\\"=\\",\\"rightExpression\\":{\\"BinaryExpression\\":{\\"leftExpression\\":{\\"PropertyExpression\\":{\\"objectExpression\\":{\\"VariableExpression\\":\\"MULTIQC\\"},\\"property\\":\\"out\\"}},\\"operation\\":\\"[\\",\\"rightExpression\\":{\\"ConstantExpression\\":3}}}}},\\"labels\\":[]}}"]',
                "LATCH_PARAM_VALS": json.dumps(channel_vals),
                "LATCH_PRE_EXECUTE": 'False',
            },
            check=True,
        )
    except subprocess.CalledProcessError:
        log = Path("/root/.nextflow.log").read_text()
        print("\n\n\n\n\n" + log)
        raise

    out_channels = {}
    files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

    for file in files:
        out_channels[file.stem] = json.loads(file.read_text())

    print(out_channels)

    upload_files(out_channels, LatchDir('latch://1721.account/your_output_directory'))

    out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    return Dataclass_4861_post(
        report=out_channels.get(f"report"),
        data=out_channels.get(f"data"),
        plots=out_channels.get(f"plots"),
        versions=out_channels.get(f"versions")
    )


class RestoList_4862(NamedTuple):
    res: typing.Union[str, None]

@task(cache=True)
def toList_4862(
    wf_input: typing.Union[LatchFile, None],
    wf_genome: typing.Union[str, None],
    wf_aligner: typing.Union[str, None],
    wf_outdir: typing.Union[str, None],
    condition_4787: typing.Union[bool, None],
    channel_4861_0: typing.Union[str, None]
) -> RestoList_4862:
    cond = ((condition_4787 == True) and (channel_4861_0 is not None))

    if cond:
        wf_paths = {}
        if wf_input is not None:
            wf_input_p = Path(wf_input).resolve()
            check_exists_and_rename(wf_input_p, Path("/root") / wf_input_p.name)
            wf_paths["wf_input"] = Path("/root") / wf_input_p.name

        channel_vals = [json.loads(channel_4861_0)]



        try:
            subprocess.run(
                ['/root/nextflow', 'run', '/root/workflows/rnaseq.nf', '-lib', 'lib', '--input', str(wf_paths['wf_input']), '--genome', str(wf_genome), '--aligner', str(wf_aligner), '--outdir', str(wf_outdir), '-entry', 'RNASEQ'],
                env={
                    **os.environ,
                    "LATCH_CONFIG_DIR_OVERRIDE": str(Path.cwd()),
                    "LATCH_EXPRESSION": '{"ExpressionStatement":{"expression":{"BinaryExpression":{"leftExpression":{"VariableExpression":"res"},"operation":"=","rightExpression":{"MethodCallExpression":{"objectExpression":{"MethodCallExpression":{"objectExpression":{"VariableExpression":"Channel"},"method":"placeholder","arguments":{"ArgumentListExpression":{"expressions":[]}}}},"method":"toList","arguments":{"ArgumentListExpression":{"expressions":[]}}}}}},"labels":[]}}',
                    "LATCH_RETURN": '["{\\"ExpressionStatement\\":{\\"expression\\":{\\"VariableExpression\\":\\"res\\"},\\"labels\\":[]}}"]',
                    "LATCH_PARAM_VALS": json.dumps(channel_vals),
                },
                check=True,
            )
        except subprocess.CalledProcessError:
            log = Path("/root/.nextflow.log").read_text()
            print("\n\n\n\n\n" + log)
            raise

        out_channels = {}
        files = [Path(f) for f in glob.glob(".latch/task-outputs/*.json")]

        for file in files:
            out_channels[file.stem] = json.loads(file.read_text())



        out_channels = {k: json.dumps(v) for k, v in out_channels.items()}

    else:
        print("TASK SKIPPED")
        try:
            _override_task_status(status="SKIPPED")
        except Exception as e:
            print(f"Failed to override task status: {e}")
        out_channels = {'res': None}

    return RestoList_4862(
        res=out_channels.get("res")
    )
